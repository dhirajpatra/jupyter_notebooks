{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Algebra"
      ],
      "metadata": {
        "id": "afgHQLoVyy91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's dive into linear algebra with a focus on its applications in data science. We'll start with the basics and build up to more complex topics, making sure to use analogies and clear explanations along the way.\n",
        "\n",
        "### 1. Vectors and Scalars\n",
        "\n",
        "**Vectors** are like arrows that point in a certain direction and have a specific length. Imagine them as directions in space, like pointing north, south, east, or west. In data science, vectors are often used to represent data points.\n",
        "\n",
        "For example, a data point in a 2-dimensional space might be represented as a vector $$\n",
        "\\mathbf{v} = \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}\n",
        "$$This means the point is 3 units in the x-direction and 4 units in the y-direction.\n",
        "\n",
        "**Scalars** are just regular numbers. They can scale vectors, making them longer or shorter. Think of a scalar as a multiplier. If you multiply a vector $\\mathbf{v} = \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}$ by a scalar 2, you change the length of the vector but not its direction. For instance, multiplying $\\mathbf{v}$ by a scalar 2 gives you $\\begin{pmatrix} 6 \\\\ 8 \\end{pmatrix}$.\n",
        "\n",
        "\n",
        "### 2. Matrices\n",
        "\n",
        "**Matrices** are like grids of scalars that can transform vectors. Think of a matrix as a machine that takes a vector and outputs a new vector. A matrix can rotate, stretch, or shrink vectors.\n",
        "\n",
        "For example, a 2x2 matrix $\\mathbf{A} = \\begin{pmatrix} 1 & 2 \\\\ 3 & 0 \\end{pmatrix}$ can transform a vector $\\mathbf{v} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ by multiplying them:\n",
        "\n",
        "$$\\mathbf{A} \\mathbf{v} = \\begin{pmatrix} 1 & 2 \\\\ 3 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot 1 + 2 \\cdot 1 \\\\ 3 \\cdot 1 + 0 \\cdot 1 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix}$$\n",
        "\n",
        "\n",
        "### 3. Vector Operations\n",
        "\n",
        "**Addition**: Adding two vectors is like combining two directions. If you add $\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$ and $\\mathbf{v}_2 = \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}$, you get a new vector $\\mathbf{v}_3 = \\begin{pmatrix} 4 \\\\ 6 \\end{pmatrix}$.\n",
        "\n",
        "**Dot Product**: The dot product of two vectors is a way to measure how much they point in the same direction. It’s like asking how aligned two arrows are. For example, the dot product of $\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$ and $\\mathbf{v}_2 = \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}$ is:\n",
        "\n",
        "$$\n",
        "\\mathbf{v}_1 \\cdot \\mathbf{v}_2 = 1 \\cdot 3 + 2 \\cdot 4 = 3 + 8 = 11\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 4. Matrix Operations\n",
        "\n",
        "**Multiplication**: Multiplying matrices is like chaining transformations. If you have two matrices $\\mathbf{A}$ and $\\mathbf{B}$, multiplying them gives you a new matrix $\\mathbf{C}$ that combines both transformations. The multiplication rule involves summing the products of corresponding entries.\n",
        "\n",
        "\n",
        "For example:\n",
        "\n",
        "\n",
        "$$\n",
        "\\mathbf{A} = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}, \\quad \\mathbf{B} = \\begin{pmatrix} 2 & 0 \\\\ 1 & 2 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbf{C} = \\mathbf{A} \\mathbf{B} = \\begin{pmatrix} 1 \\cdot 2 + 2 \\cdot 1 & 1 \\cdot 0 + 2 \\cdot 2 \\\\ 3 \\cdot 2 + 4 \\cdot 1 & 3 \\cdot 0 + 4 \\cdot 2 \\end{pmatrix} = \\begin{pmatrix} 4 & 4 \\\\ 10 & 8 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "### 5. Eigenvalues and Eigenvectors\n",
        "\n",
        "**Eigenvalues** and **eigenvectors** are special because they tell us how a matrix $\\mathbf{A}$ transforms space in specific directions. An eigenvector of a matrix $\\mathbf{A}$ is a vector that doesn’t change direction when $\\mathbf{A}$ is applied to it; it only gets scaled by a number called an eigenvalue.\n",
        "\n",
        "For example, if $\\mathbf{A}$ is a matrix and $\\mathbf{v}$ is an eigenvector with eigenvalue $\\lambda$, then:\n",
        "$$\n",
        "\\mathbf{A} \\mathbf{v} = \\lambda \\mathbf{v}\n",
        "$$\n",
        "\n",
        "\n",
        "### 6. Applications in Data Science\n",
        "\n",
        "In data science, these concepts are used in many ways:\n",
        "\n",
        "- **Principal Component Analysis (PCA)**: PCA uses eigenvectors and eigenvalues to reduce the dimensionality of data, helping to highlight the most important features.\n",
        "- **Linear Regression**: Involves finding the best-fit line for data, often using matrix operations.\n",
        "- **Clustering**: Vectors represent data points, and distances between them (computed using dot products) help in identifying clusters.\n"
      ],
      "metadata": {
        "id": "6LpBjv6iCWaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Vector Spaces and Subspaces\n",
        "\n",
        "A **vector space** is a collection of vectors that can be added together and multiplied by scalars while still staying within the space. Imagine a vector space as a flat surface or a volume where any point (vector) on that surface can be reached by combining other vectors in the space.\n",
        "\n",
        "For example, in a 2-dimensional plane, any point can be reached using combinations of the basis vectors $\\mathbf{e}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $\\mathbf{e}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\n",
        "\n",
        "\n",
        "A **subspace** is just a smaller vector space within a larger one. It's like a smaller flat surface or volume within the larger space that still follows the same rules."
      ],
      "metadata": {
        "id": "DNwq-p51Gwqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Linear Independence\n",
        "\n",
        "Vectors are **linearly independent** if no vector in the set can be written as a combination of the others. Think of linearly independent vectors as directions that don’t overlap in any way. For example, in 2D, $\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $\\mathbf{v}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$ are linearly independent.\n",
        "\n",
        "If vectors are **linearly dependent**, it means at least one of them can be expressed as a combination of others. This is like having overlapping directions."
      ],
      "metadata": {
        "id": "NiRB3wq6G6ZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Basis and Dimension\n",
        "\n",
        "A **basis** of a vector space is a set of linearly independent vectors that span the entire space. It’s like having the minimal set of directions needed to reach any point in the space.\n",
        "\n",
        "The **dimension** of a vector space is the number of vectors in its basis. For example, the standard basis for $\\mathbb{R}^2$ is $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, so its dimension is 2.\n"
      ],
      "metadata": {
        "id": "63vUlhQ_HD0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Orthogonality\n",
        "\n",
        "Two vectors are **orthogonal** if their dot product is zero, meaning they are at right angles to each other. Orthogonal vectors are important because they represent directions that are completely independent.\n",
        "\n",
        "### 11. Projections\n",
        "\n",
        "A **projection** of one vector onto another is like casting a shadow of the vector in the direction of another vector. Mathematically, projecting $\\mathbf{v}$ onto $\\mathbf{u}$ gives a vector in the direction of $\\mathbf{u}$.\n",
        "\n",
        "The formula for the projection of $\\mathbf{v}$ onto $\\mathbf{u}$ is:\n",
        "\n",
        "$$\n",
        "\\text{proj}_{\\mathbf{u}}\\mathbf{v} = \\frac{\\mathbf{v} \\cdot \\mathbf{u}}{\\mathbf{u} \\cdot \\mathbf{u}} \\mathbf{u}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "FY0l4DD_HM_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAaQAAADZCAIAAADg5dPJAAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAABpKADAAQAAAABAAAA2QAAAADPdAoZAAArm0lEQVR4Ae2dB3gdxdX3rWLZlpssFyRb7t3Y2PRqWuDB9BII5Q02hISEkPCkvx/pJAESAgQI5H2AhBYIJYTuQDCmY8CmuGBscG9yk4tcZLlI+n5i8LDZmbt3793bdvfs4+d6dvbMmTP/M/vfMzO7o6KWlpY2cggCgoAgEHUEiqPeQGmfICAICAKtCAjZST8QBASBWCAgZBcLN0sjBQFBQMhO+oAgIAjEAgEhu1i4WRopCAgCQnbSBwQBQSAWCAjZxcLN0khBQBAQspM+IAgIArFAQMguFm6WRgoCgoCQnfQBQUAQiAUCQnaxcLM0UhAQBITspA8IAoJALBAojUUro9jIhoaG3bt3l5WVdejQQbevvr6edOfOnYuL8/AY27Jli95Xom3btuXl5dow/4mVK1cWFRX16dPHfxGrZHNzc21tLTj07t3bKiCZcUMgD7dE3CDOUnvvv//+ioqKSZMmaf3z5s0jZ+jQodznOtNn4qmnnvrb3/4GgfqUt4odfPDBGKCOjh07nnXWWQ8++GCqxvTt23ffffe16k+a6WzF9u3bUXXYYYclLSUCMUFAIruwOvrUU0/F9CeeeAKGUjHUyy+/TM4ll1xSWpqyW2+66aY333zz9NNPTy8cc4J47rnnVlZWrlix4plnnnn66af37NmDSU4B7/QVV1zhjFW9hV1Xna0gtERV165dXTJyGlsEUr4rYotUoTW8X79+xx577Kuvvjp9+nQSmPfcc8/xSzzFL8PJyZMnz5gxo1u3bsccc8z+++9PpjqmTZsGr0FqRx999OjRoxnoTZkyZe3atVylyIQJE6qrq0m/9dZbKK+rqxs5cuRXvvIV4jUyIdZHH32UgeGYMWMgsjPOOMMcb15zzTWjRo1C+Pbbb//ud7/7wgsvUNwsZdVPqfHjx8NTJDiCtKJ79+5Emk7etNa4a9euRx55pEePHmPHjqX5TU1NJ5988oABAz6rvw1h6QcffEAT0HbooYeOGzcuL/MDyhj5DYoA/UmOkCJw55134v6f/exn2L9582bSUA+RFKcTJ0509oyHH35YtfGGG25w5iNGPvewzoT4yPnTn/6kc0gMGTKESI18xYlHHHHEoEGDyJ89e7ZSq36HDRtG5ty5c9UpBMfpaaedZpZKpJ+CFCEcUxqCtIIJRFQxklWqEtWocKM5VVVVyKtj1apVlIIHTzjhBHLgPqYRSVx77bVKm/yGEYHWh6ccIUWAuXzuQCIv7FdhnSI+CIv8E088EZaZNWtWSUkJcRxzWEuWLCGfMeacOXPgKRW/LFy4kPjlqKOO4tKaNWtQtXjxYu5tGOeVV15Zt27dlVdeyaVvfetbXFK0xSm8xhzfpk2bnNApsiOge/bZZ++66y4MQ/IXv/iFq9TMmTMT6UcbRRTZBWyFk+w8WqTIjkoff/xxGnvppZeSvuOOO7DkvffeIw1Zq4Yfd9xxDPPBytlkSYcIASG7EDnLYqoKPRYtWnTVVVdxZzJuReh3v/sd6YsvvpjQj4MhJ6fM6HE/k0BSKVq6dClUyAIup4rsYCXSrCogdtlllymxTz75hFOGsZwq2mIo19jYqK46fxXZIawOxM4888wNGza4SnnoRxtlFdkFbIWT7DxqVGTHA0A1RD0zmOzjFMvVoPWQQw75+c9/7gpjnQ2XdCgQKN3bM+X/UCJwwQUXvPTSS4Rgjz322MCBAw844ACasX79en4JTJYtW0aCaTum57hvVX7Pnj1VU/v3768Srl9ucnLUQJWEmpWDFHjTRUmyWtquXTtXKX16yy23oLlLly5MmfESDPlETPzqUh769Wwd8gFboe0h4VGjEtMzj861HRhw6tSpLHrAgEyMQr48J2699VanZkmHCAF59SREzrKYesopp5DLfcgIlEVPFYkonjrnnHNe++wgrrn77rsJT9QbZ/Pnz1eKrr/+et5cYTLOpXfw4MHkcJ+rfDWag6o0E+mEq6A6ZfjMIsnxxx+vmE7L6FJJ9asiAVuh6yXhs0ZnEdIABcXfeOONRKYExcS2t912G9N5LjE5DQ0CoYg/xUgPBE466STV25gLU2ILFixgno7gi4kz7lUYkKCPgSdTbIwQEb7uuuuYayfBaqyahIKhOP3jH//Ii7g7duxgRYLTCy+88Oabb1ZRzz333INyNSAlfrTa41qg0DKuUh76KUK9ahgbsBXOYaxHjWoYy0hfWcvCKwaoYezzzz9PmoVslmtJs0jNVCPL07pdkggXAjJnFy5/Way99957uSdHjBjhnDvnpmUhknwOFgo0DzLg1cNYihC8KI0PPPCAWnBUq7G8n+x8WwVmZAyLpIu2XNb4JDtKJdLPJQxWZEc6SCucZOdRowfZgSdTdQoWZRXry6iSI6QIFGF36w0hR+QQ4B0UliCI7wjN1PBWNRHaYi6PQSVv6uk7mUu8abFt2zbGnmq8ScdYvXo1XMCibfA3jU10rfrhF2JSBowEoapIwFY467XW6BSwpiFNVr3BpKamxvnWnlVYMgsZASG7QvZO7Gy7+uqrf//73/OuMm8sx67x0uAsIyBkl2WARX0qCDDEJorkdRk+5EilnMgKAskRELJLjpFICAKCQAQQkFdPIuBEaYIgIAgkR0DILjlGIiEICAIRQEDILgJOlCYIAoJAcgSE7JJjJBKCgCAQAQSE7CLgRGmCICAIJEdAyC45RiIhCAgCEUBAyC4CTpQmCAKCQHIEhOySYyQSgoAgEAEEhOwi4ERpgiAgCCRHQMguOUYiIQgIAhFAQHYqjoATo9OEJyed47MxZ9//hE9JERMEFAJCdtITwoTA0ycPV+aeHSarxdaCQEA2AigIN4gRCgGPyE7TnAur+y643pUjp4KAFQGJ7KywSGZ+ELAOTmHAREyXHyul1nAiIJFdOP0WD6tVoJeU6SS4i0d3CNpKWY0NiqCUzxIC3kznJLhLHrk6SzaI2ighIGQXJW9GpC3QnGI6V3vOfL71z3XrQ/hOQyEJPwjInJ0flEQmRwi4OM45gIXannze74spOTJXqgkVAhLZhcpdkTbWm+lcTVdDVwnuXLDIqQcCQnYe4MilHCFgjludMZ3TCNdIlkvCd058JO2BgJCdBzhyKesImDRHlS6mc9KZ1aCkAtZSkhk3BGTOLm4eL5T2ugatyiz1nt3TjtVVIbJCcVj47RCyC78PQ9gCk+msrxP7Zzr/kiFES0zODAJCdpnBUbT4RMCkOQq6mE6YyyeYIpYSAkJ2KcElwukj4Ifm0tcuJQWBZAjI52LJEJLrmUDAZDpXNOe/Euf3EhID+sdNJCWykz6QXQQySHPKUAjOyXfZtV60RwgBIbsIObPAmmLSHAamHdAVWOPEnPAhIGQXPp8VvsVCc4XvoxhaKGQXQ6dnt8km00k0l13ERbs/BITs/OEkUj4QMGmOQsJ0PpATkVwgIGSXC5QjX4fQXORdHIEGCtlFwIn5bEJ+aY5lWXn7JJ/uD1XdshFAqNxVYMaaTMegNQfjViG4AusI4TBHIrtw+KnQrDRpDgtzQHOFhoPYEyIEhOxC5KyCMFVoriDcIEakjoCQXeqYxbiEyXQSzcW4O4Ss6UJ2IXNYvsw1aQ5LhOny5Q6pNw0EhOzSAC1eRQqc5mRBNl7dMUBrhewCgBf1ogVOc1GHX9qXYQTk1ZMMAxoZdSbTMWgtnHGrvH0SmZ6Ws4ZIZJczqENTkUlzmF44NBcaHMXQAkNAyK7AHJJXc4Tm8gq/VJ5dBITssotviLSbTCfRXIjcJ6YmRUDILilE0RcwaY42C9NF3/Exa6GQXcwc/t/NjQbNydsn/+1VObMjIGRnxyXyuRGgOfljFJHvpZltoJBdZvEMhzaT6WTQGg7PiZUBEBCyCwBeCIuaNEcjhOlC6EkxOWUEhOxShiykBYTmQuo4MTtTCAjZZQrJgtZjMl0cork3Fs6o37F1cI9+I6uHtLS0TJ77SpuWNvvXjOrTrWrH7sap86fhs6OHHtKlfaeCdp4YlyEEhOwyBGShqjFpDkvjwHQ0c/nm2ikL3zmgeiRkV7dt4+MfTSGzqaUZslu6YdXjc6eUl7Y/ed9jCtV1YleGERCyyzCgqGtubv5k8pMk+h1xdMfuPUmsmf3hpmWLu/Tu2+fAQzJfXwKNsaI569sno6uGQXYL6pYR1i3ftBqcitoULd6wgsSSz37HVQ8vKS5JgJ9kRw0BIbsseLS5ef7jD6G35/BRiuzWzpm5+MVna448NjdkFx+a8377ZNg+A0uKirfubli/beOyjatKi0rGVg2bt34J3LeobjkO2q/38Cy4X1QWKAJCdgXqmLTNMpkuJoNWE7EObduP6DFw7vpFSzesWLJx5cBufYbvM+j91fPWbq1bsKGV7EZVDzVLSU5UERCyi45nTZqjbbFlOuXX/aqHQXaL6lYs2rjy2EEHD6ysIX/6stlbdm0fUtlXliai0/t9tETIzgdIBS8iNJfIRa2x2+zn314+q2FP46DufftV9mbaburCd5AfVz0iUSnJjyQCQnZZcGtxkVLa0tysErsatmehms9VmkwX82jOCXVNRVVFu86bd24lc0D3mnalZQMqqpdsruV0397DnJKSjjwCslNx5l1cXFxS3qsKvZuXL+V3d2Pjxk/nZr6aNm2gOWE6b2CLiorGVbeSWtd2nXp06kZiSI9+/HYp69i/srd3WbkaMQSKWJmKWJMKoTnv3P7H1TPexpIeo/ZrqFvHP15IYTX24Muvyoh5JsehNp4BHS+daEhlr3YNhSRMBCSyMzHJQM6YCy/p1Kcviuo+nt25pt/gk07PgNLPVCSK5uLJdEAiBJeprhV5PTJnlxUX83rdidfd2li/uU1RUfsuXaljvwsmBa/JDOhiy3HBwRQNcUNAyC6LHm/ftSJT2k2aQ7MwXabgFT1xQEDIrtC9LDRX6B4S+0KCgJBdQTvKZDqJ5graYWJcASMgZFegzjFpDkOF6QrUW2JWGBAQsis4LwnNpe0S694naWuTgplC4KYHHtWqfjjxfJ3OcULILseAe1UnNOeFTuJr3nufJC4nV/KAgCK+vFCekF0e/G2t0mQ6GbRagZLMCCCgY71csp6QXf57jklz2CRMl3/HiAUZQkAzmuY4rTiXgZ6QnYY9DwmhuTyALlXmDwHFeokoD7s0LWbDRvlcLBuo+tJpMh3RnAR0vrAToTAjkFVG8wBGIjsPcLJ1yaQ5ahKaywjcsiCbERgzq8QM5TKr36c2ITufQGVGTGguMzgaWmRB1oAkPxkFwmvWxgvZWWHJfKbQXOYxFY35RiAItTGYdRbPwdhWyC4X/cVkOhm05gJ3qSNzCDiJKQ2tJpc5FZpX06giaREhu6QQBRIwaQ51wnSBMJXC2UfAyUSp1pYb5krVKuSF7NIAzVcRoTlfMIlQvhEIwmvYnh61OStNT0MasAnZpQFa8iIm00k0lxy1FCX4+xJmiUkP/z8zU3I0Ak6W0Zk+E5liJacNmdLppwlCdn5QSkHGpDkKC9OlgGBiUSu7meLy9onCxMkpJkpJc3JJQ0mNyYiAkF1GYGxVIjSXMSj3KvLJbnvFY/1/EGrLJa857cxlvXQOIbsM3CFCcxkAMV0Vzj+P5/xLY+nqC0E5J1+kYW6OKSaRhbk3Q8gukS/85ptMJ4NWv9ilJedkt7QUhKxQEGrLPaEUMrhCdul7x6Q5dAnTpQ9o4pLxIbjIU1se+VfILvEdlviK0FxibOSKXwSC8Bp15JE1/LawwOSE7FJ2iMl0Es2lDGL8CgShNuG1jPQXIbsUYDRpjsLCdCkgmK4oy7IpjWTz+/ZJEF4DIaG2dLtJknJCdkkAUpeF5nzBlGkhCC6lt0/ysvdJEGoTXst0l/HSJ2TnhQ7XhOaSABSny0F4DZyE2vLbWYTsvPA3mU4GrV54RetaEGoTXivAviBkZ3eKSXPICdPZwcpJbqrTdikZFYTXqEioLSW08yUsZOdGXmjOjUhez1OdtvNjbBBqE17zg3BhygjZ/ZdfTKaTaO6/AArbSRBeo61CbWFzuJe9qa3oe2kK+TWT5miQMF0heFUvyCZ9+wRqm1M2U9k8Zte4lIwXXksJrjAKC9nJemuh91sr2b1x76Xa7uklE3TaZ0KozSdQURKLNdlJNBeKrqzJ7sb7H9EGH9L0gk6rhAflCbW5sIrnaXzJzmQ6GbQWyD3gZ6LNJDtl/PhL7y2QVogZhYZAHMnOpDm8IkyXl67ph9c8DEtEebpIIXPfJ0uWb9yypXPHjqOHDFQGz1mweFtDQ1WP7gP7VOsmSCJTCMRrNVZoLlP9Jj09QagtwVD0fGWJcwovPdtyX6px565ps+a2LSkdObB/SUnxnqaml9/9YE9z09nHjc+9MXGoMUZkZzKdRHPZ6+JBeA2rElBb9uzNg+ahA/pOnf7B7qY9tevW963eZ+Wa9TBdh7J2/ftU5cGaGFQZC7IzaQ7PCtNlsHsHobY0eC2McZyJdnn7doP6VC1atXpp7RrIbumqWmRGDOxXUlxsCktOcAQiTnZCc8G7iEtDEF5DVarUFg1ec2GoT0cOHgDZLV61evyBYxetXE3+yEH99VVJZBaByJKd0FxGOkoQakuV1zA4CLWptQinhkJenVDeGVTTmzm7us31y2vXbN62raJTp+qe3TPiOFFiIhBNsjOZTgatpu9dOUF4DVWpUpuTlVyW+Dm1EplTp1XAj+ZcyrQtLR0+oOajRUtfea/1w49Rgwfksva41RU1sjNpDo8K05ndOgi1pcpr1O6kIdMY75xQ0JZ3EzyushQL2RHcITNyYD8PSbkUEIHokJ3QnEdXiAO1Ofk0RPxYU9WrY4cO23fsqO7RvaJLZw8nyqWACESE7Eymi200F4TX6EypRm1OikmjL4aIldJonZ8ixcXF3zrvDD+SIhMQgdCTnUlzIBIfpgtCbanyGsAGobas8prTsKxWFPB+k+J5RCDEZBc3mgvCa/SwVKnNSR9pdFBhnDRAkyJZRSCUZBcHmgtCbanyGj0sCLUVFK8VlDFZvXVFeaoIhI/sTKYL+6A1CK/h7zhTW6rdXeTjjECYdj0xaQ7PhY7pglBbjnkNeCVQijM7RKzt4YjsQkpzQXiNfpZjahNei9i9Lc1xIRACsjOZrjCjuSDUlgav4cjITLS5OqWcCgLZQKCgyc6kOSAoBKYLwms0IQ1qE17LRu8XnbFCoEDJrqBoLgi1pcFr9D+htljdhNLY3CBQcGSXd5rLMbUF4TW6iEy05eY+kVoigEBhkZ3JdFkdtAbhNXyfRtQWhNqE1yJwv0kT8ohAoZCdSXOAklmmC0JtafAa9gu15bFnS9WCgAuB/JNdNmguCK8BUBrUJrzm6lhyKggUGgJ5JjuT6dKI5oJQWxq8hguF2gqtH4s9gkBSBPJGdibNYWtSpgvCa+hPg9qC8Bo15muibfnMybt3buk16PDOPQdghhyCgCCQB7LzT3NBqC0NXqM3BKG2fPGatROvW/Tmji1rOvUYLGRnxUcyY4hATsnOg+aC8Bpuizm1mR23Zsype3Y1dOpeY16SHEEgngjkbiMAJ9Mt/tLnf8g9DdBzz2sYme2oraW5efms56io98jj69d+unHlnLIOXfcZNr5Dp8//1tTymc+1tDT3HnV8/epPN676aNiRExHeUb92zYI3GzatLG7brlNl/+oRx5WWtVeQrvn0jd07Gyr7julY0Vvl6F9dV6+hRyr9G1bM2Va3pGO3mh4DDtBikhAEIoZA1iO7L0K2tAgu99SWbV6zdqCWNs3LZz7Jpfo18+vXzFMytR+/OGbC/3bu0fqHRJdxtaV557YNaxe+XlxSBtltXDV3/su3N+1pVMJ1S95du+D10RN+3L5jJTkr5/ybYWxZeTcL2e2tq6J6hCK7TavmrJ43peegw4XsFJjyG0kEskt2rdGcb47LPa/h0bxQm0dPaqivHXbU5Tu3b1z50eSm3TsWv/vQ2FN/quVhusq++3fs1re5affCt+6D6bpWjew37kxIcNmHT8Buy95/YvjRX9fykhAEBAGNQHbJTldjJnJPbYXGayYm5Aw65KJegw4h0bZD54XT7t2ybkHT7p0lbdsp4T6jJgw6tHUGYNOqj3duryMx5PCJ5RVVJJihWzz9oXWLpg09clJxSVslz+/Ctx9CybjTf8kfdpn3yv+1tLSMOPZyfVUSgkB8EMg62Q2a+qhCM+lrJSbokVkbNZuWKKdTZV91qcs+Q1Ri5/ZNis447VI1TGU2bFlLom2HrvpS188vtTRurSuvqFZi/HbuNWT1/Je21i0p71pVt3TGgIO+oi9JQhCIFQLZJTv/BBeE13BYKKI2Px2rublJie3avlkl2rbrqAvqdGlZa+aendt03Ldzr3xpWbmWJ9Gj39iFJWWbV33E0LhNm5aerWFjsRJgpUIl9uzc7iwiaUEgkghkl+wSQRaE2iLDa1ZwNix7v1NlTXNz8/ol0xGA3RjPmpKdu7cGgC3NTRtWzGLYy0ItBckpK68sK+/qlC9p2757/4M2rpjVcesGJvjU8kX7Tj0bt63ftnF5Re8RTbsbGec6i0haEIgkAlknuyC8BuLRpjazSy2f+dTm2rm7G7ey2sDVPqNPNWXIYaDac9AR6xdP++S1/1u74A0WKHZsWU1+/wPOMeV7DT587pSbGreuHXjIRepqeWU/yG7JjIc3rJi5a1vdzu0bzFKSIwhEDIGsk51/vOLGa1Zk+h9wXu28F3fvqOdq9cgT+4w+0SpG5tAjJhaXlPK6yebajzhlUWLAwRdWDT3SlK/oPbK0fefm3Y09+n/+Gt3gQy9srK9tqF+9Zc28yppxlf0OqP34P2ZByREEooRA1l8qThTZCbU5u1Fz85637v8GOQecdS1RGzTUrrxSvyHslHSl9+xqRLiYibouvZyLsO/962piw+HHXKHWdl2l1Omuhvo2RUVlHbpYr0qmIBAxBLIe2QmppdpjioqKzDeBEymBELv0HOi6unbRdEapZJZ3aX0rJdHhmt1LJCb5gkA0EPh8YS4ajZFWKASWvPsAaxe8mNJRvo2VPiEI7EUg68PYvRXJ/14IsJxat/QDJLr12be0rIOXqI9raxa8xcC2omq4DFF9oCUicUFAyC4unpZ2CgIxR0CGsTHvANJ8QSAuCAjZxcXT0k5BIOYICNnFvANI8wWBuCAgZBcXT0s7BYGYIyBkF/MOIM0XBOKCgJBdXDwt7RQEYo6AkF3MO4A0XxCICwJCdnHxtLRTEIg5AkJ2Me8A0nxBIC4ICNnFxdPSTkEg5gjEheweeuihW265JavO3rx5829/+9vsVbF7924/ypXYihUrbrrpJpf8ypUrPUBYtmzZX//6V1cR79P33nvve9/73oYNX+z96VG7t6r0rtKi2267LaWyykJvKFJSqIVNNPSlHCSy0aIcmJ3LKmJBdg0NDVddddVPfvITOkT2wKWWv//971nS39TUVFZWRhXe+rXYxo0b//Wvf7mE2TyqpKTElalP169f/8wzz+hTP4kLL7xw//3379y5sxL2rt2PwjRk+Htp/ktpC72h8K/QKelCw3kpB+lstCgHZueyiliQ3YsvvnjSSSddfPHFTz7Z+oeoXceePXumTZv2/vvvNzY2fvrpp+oqd8Vrr7326KOPLly4UMtbM3ft2vX222+/8847ZuT14YcfEu5RnNiHx77Sg8J169aRRtusWbP+/e9/r1q1Sl3itK6u9Q8kclCEU5XmF1X8vvvuu/x5CqsZSlKLIUPOpk2bnn/+eVqnGKGiouL4448nf+vWrR999FF9ff1//vMfrqJTFde/4KChUJlmpR9//DHBYFXVF1vmedeu9MycOfO5557TTdY1YgzI0OrJkyfPnj1b5UPupPnFF+SYNnTr1u3EE7/YzNlUjnNffvllakQ/GrSFELSCwqo2KT6mJSYaPDyeeOKJRYsWUQW1k54/fz5pfZhKvOt99dVXUUJ/QwMAauVKoXYup8gg/MILL2zZskVXpxJU6up13vKu4qE+jQXZ3XfffRdddNG55557zz33mN4677zz/vCHP9x6661f+tKXSCNAh/jyl7/8/e9/f8mSJWeddRaUlygTmkDtN7/5TQaAqqxT/5133qnolUH0wQcfrO63yy67bO3a1j+E+J3vfOfaa6+dM2cOt6u6manojjvuUBr+8pe/0Ju1tjfffJM03LRz507TNlMMw5YvX37GGWdMnToVeTXWg00uueQShBcvXkzm+eefT72nnnqqa2xLLTSqQ4cvdpqyAvLKK69AJS+99JKON7WR1tqpF0i/9rWv8ewZNGjQ008/rc0m8cEHHwD1V7/6VZ4KF1xwgYqRIVNyDjvssH/+859WG2jR17/+daXHVE6Rs88++6677sKwoUOHQhDaQqhcQWFV642PtYiJBjQHyG+88Qbm1dbWkp4yZYpuslWJd70ggxL11HzwwQdJg79WqJ3LM/vAAw9866236D9HHnmk9o6SNHudt7zWH4UEz/xoHwxdu3btumPHDrxeXl7Ow9/Z3k8++eS0007j5iTzz3/+83777UfiqaeeOvroo+lJpHlid+zYkajNmkmkAIvRcZGE2rijSOiD3nbppZdyyi13zDHHwAuEWn379kUee37zm98oyccee0yJEV3CAhjDgSqewFqV6tbbt2+3mmGK0UxGrMSJXHr99dePO+44EmQedNBBKsGgmNCDNHx37LHHkpgxY8bpp59OpDlu3DhAI0cfiSpt164dLdJi2khr7dx+AwYMUKgi0KdPH5VWxYm/iLaUNmjiiCOOIB/wuccQJm21gUuHH344V63KwZ+GK+88/PDD9957r9NCBUUitSY+ys5ElpDvQoN4H+OplEuqITxySKsjjXqhMxQyL4wG8FEN36vvC+fyeMOhdCEu8ZDgmadlrL3OQ14XjEYi69uy5/2B8Pjjj8MvKmLq168fp2PHjtVWEcVwPzDfQQ5d5O677yYB6UyYMEFNbw0fPpw7ZPXq1dZMOgoEUVzcGiBDZzfeeKPWTGL8+PHf/va3icUWLFjwy1/+khsSVeeccw7y7du3J3qC7+bNmzd9+vRDDz0Ueea/iKfgOOyBYWFepzaVtppBA03JMWPGdO/enfwePXqYk5WjR48mn6uMQ/WgkvuTsIu5J5jIqdB/pbqUWTtkSqN++MMfKhkqZWKxZ8+euggRHGMxTmF8YhyiIdLDhg1T/rLaoMtalUOF+FR5h2gRYYhPF1GJRGqt+HgUsbrAVZfzNI16Bw8eTB9jXpVglskHHq5OhTp91FFHtW3bdt999yX0I1h2GmbtdR7yWmc0EhEfxvJEok8wW8ctzcEYCjpzTq5xvxEuKV+q2RDSvXr1UiEAaaZRuEWrq6utmaWlpVobkq4+AZuMGDECeoVPeRQziiHIYvYQMZ7SEBwH/MgIWhWE47CQCSYOEi5t6tRqhlXSOQ41BQhDzEy4hlAXUuYZ4Lzqv1Jdyqyd1o0aNYohvzoIdoi4tTwJvXiCR5jWJLYik2BcyXjbYFUO12s/MnlKjOOszlutFR/vIi7lMA45qnuYc2eJmuNRL9omTpwIrTOGJX3mmWe6alSn4MYTi/mTmpoaZNQ0pbpk7XUe8lb94c2MONnRM5iS+NGPfvQ/nx2EFbhWTaMonzGWoVuoZQS9lnryySeTqYZUDAQIwSA1a+Ypp5zCeITRIqMGEmY/YNbsmmuuYVBMrMScHdqYRkGMBzshIcQHjTIlrwsy4MUMejMBoM4kwc3ML3eO1QwtqcV0TkqJkSNH9u/fn+nCb3zjG87707tSXYV37Qy7QJ5HDrXwjGEyTtGBLs60l4oxGUojowJPfdXbBqtyvMPMIHXxzLv66qu57U0LvdXq2p0Jn0UYs1Pq/vvvxwbmE50aSPtU4ipFnyHnpz/9Kf1kn332cV1Vp8z8MmJgRMJDha7L00uLWXudh7wuGI1ExIexzNQQ86uBDA4jMWnSpEceeUSvxHE/MGLilPuBMYKKRxgvEIvxYGQsA5ERZ1HWmsnMGgMliIxRgwrZXN0CzT/4wQ8YoJFPXXPnzu3SpfVPFzJMJqajxxMPsnjCCgnLZ6gaOHAg2gh5XANJLGd0yS1NfzVt05VqMaaKdGaqiRNOOAFLfv3rX998882qrLXtplrv2pnc5GEDuYMGgdsDDzygqEfrIe5Tg03WZPWDR1/1tsGqfMiQISAM6RBfM6xmcta00Futrt2Z8FmEuJK3nW644QaGnD/+8Y/VFJ7W41OJllcJRv2sg/HI5NntuqRPaTILXzAskzZkXnfddfqStdd5yOuCEUlEY+ox7VZwXy1dupSpHA4m4HgYalXckPAg+TqHhDWTeAQ9TjGfaV79Vfq3bdvG1J4qxVCFWM+qgWhL5VvN0EW0mM7JSMK7Ul2Fd+3Ey8QazBhoeZVggYJoBTSYXlST6y4BdeqygWBNLWWoq1blBNQ8UZzaTAtdap3CidI+i+BZRuUBlSQqnigfeJkmTtQnzV7nLZ+oltDltwmdxZk1mBVJHvs8KmE6Bpu8mpRZ/Slp4z7n5RjWJRiuplQwAsKK7FJqCEH3lVdeybMhpVIiHFsEIj6MTRp+MzHEAgJLB4Qb119/PWFC0iLZE+ABS3yHMUwRZq+WwtTMCiwzDCnZxuIDzycGpymVEuHYIiB/SjG2rpeGCwLxQiDiq7Hxcqa0VhAQBBIjIGSXGBu5IggIAhFCIPpkp97qtG55lD0/qkpT0p+Gna5aWN9wfeVqNSCNipQeXo5hGYdf5zeeuor0EE57X6xExqTROheMukVZSqTd5CzZEx+1ESc7XmXgLWK+iuXNUnPLoyy5WVfqX78u4t9OXUTXwmtr+iMEnelK6FL+K9IaeP+eZRw+XHW+p6qvpqGQsrjGfKVO6/RIWI1Jo3W6iEddmb2UdpMza0YMtUWc7NS3MuyMRJ/Gu7yH5dzySPmbLyh5bVh/H6o7Aa/vcgOrUxJ6wyVTnmVB6z5CvC9GvXxpz0vq3JxKFX3duW2RykxqJ3pcO/PoItSilPjZ5EeXSgMQPtTvtPegRtaOCa9c+wiZCJuWq7LmvlgmVlirPm7hlTHXHlkuYzIIo/fWTLy1hyuxJ6WtqKxN5nU/3alI642tXN1JNc3sdVb8lbCJJG8aemzqhR/ZNAGFFOdGIK12plLaIvMbcbLTW/rACOaWR3jR3BdIu5aNodgdSJ3ygS09wCpPx+JtWOs+QtbtmJzbFum6ktpp7syji+jPP7kJ1bZFHpv26FJpAML3SZ99YVzFVxDWKqwIm5ZTNZ8x8f62c18sYOTDddzh3FYL2BPtkeU0JrMwem/NlN5WVNYms83UFVdcoYwnWGbPZ9JmdyLT7KVW/JUqK5JBNo9SaqPwG+03DBUR8Ao7D0ZzyyPrvkAaEK7yuRin9FT23uDDdau8xz5C1m18nNsW6bq87bTuzKOLaCW0UW1bxMwa33thNpd4X9q5yY8ulQYguiISZhVWhVbLidfMfbGsWIFtoj2ynMbotHfrrMboIlqJ99ZM6W1FZW0yH27z/Z+ql51v+AqQtNmdrL3OxF/bb0US7zCf49rUSxdRw45Em0dpsbAnYvTyaqqbDvEJJyzJFkw8RfkmkU/T2Z7E3KSIbgSz8NEljz7XPkIMhM2tohDT2xZZn5amndadeaxlVabPTXvMiqwbJTl3YdKVmlUw0jcVWi3nRjX3xbJi5bFHlrYkUcKnMYmKe+SnsRWVtcnWKszuZO11Jv5amxVJrnpsWsWHun42j9JVhDQRI7Lz2HRIOY+BlXPTIfjr8ssvZwcO5jvYXhgZVgDUJkVOeb735rsllcMEE5Mv+ht+tvFhDktdQonaKoqPFvW2ReqS69e0kwcvm0ERo2EGMcI//vEPVxHXqdq0h5ERczFs8vPss8+yU55LhlOzImsDzYLkmFUAl6nQarl1XywrVkg698hi80tmBqwbLphG+jTGLOi9NRPyehUo0VZUptOtTXZWrTavJsfsTlanmPhrF1uR5FGUdPMoepf35lFOg8OYjvicHR0FryR6t8C6L5DTi0wt4X7IRe0dZpX32EeI/STMraKc+nXa206e1eZ+UB5FPDbt8SiFMdYGaiOdCY8qnGJWy0GMoRZPCAbaJJR8IqwS7ZHlrEWnvVtnNcYs4r01E3WlsRWVtcmwEuMGtQimN6k3u5PVKR74J0JSo2RNWDePYkTPw9sqH8bMiJOd3tKHoajpHr0vEONQdnBjOlx1fS3JHkEscTJkqKysJNMqr/cRIvhiPcu5j1Dv3r3VdkwMfPjwVs1Aa+XOhLedjIWZzKYT8ykoozMmcQjZdBGmopyqSCPJB7/8IQJWTlgPgS+0gC6VHiBaj0cVWoaE1XK9LxYzjMymK3m95ZELK/bIIhYmEzGIgG3a1B5Zzlp02rt1VmN0EQ2j2poJkEGPcbRWrhNqKyou/epXv2K7Op2vEtaGWJvMHsL0FjZiYgipN+8zu5O113ngbzXAZaR5qjaPIixwbh5FG11/d8ksGKacsE86+rGfp5OHGIMORnzwlIeM85JV3mMfIZ97AVGFt53mzjweRWiOxyY/3hVZG+hEQKW9q3DKWy237ovlHyunflfau3VWY8wiibZmSm8rKmWhtclEuFCMqwlmdzKd4o1/RpB0WRX2U9kIIExPJrE17wgwhuUPM6n3kPJujBiQEgIRH8amhIUICwJJEUhjK6qkOkUgNwhIZJcbnKUWQUAQyDMCEtnl2QFSvSAgCOQGASG73OAstQgCgkCeERCyy7MDpHpBQBDIDQJCdrnBWWoRBASBPCMgZJdnB0j1goAgkBsEhOxyg7PUIggIAnlGQMguzw6Q6gUBQSA3CAjZ5QZnqUUQEATyjICQXZ4dINULAoJAbhAQsssNzlKLICAI5BkBIbs8O0CqFwQEgdwgIGSXG5ylFkFAEMgzAkJ2eXaAVC8ICAK5QeD/A8P8W3VJv2+/AAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "OQRjFwfJqSj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Singular Value Decomposition (SVD)\n",
        "\n",
        "SVD is a mathematical technique that factors a matrix into three simpler matrices. This decomposition reveals important properties of the original matrix and has numerous applications, especially in data science. Here's how it works:\n",
        "\n",
        "**1. Matrix Decomposition:**\n",
        "\n",
        "SVD decomposes a matrix $\\mathbf{A}$ into three other matrices:\n",
        "$$\n",
        "\\mathbf{A} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^T\n",
        "$$\n",
        "- **$\\mathbf{U}$**: An orthogonal matrix whose columns are called left singular vectors.\n",
        "- **$\\mathbf{\\Sigma}$**: A diagonal matrix with non-negative numbers called singular values on the diagonal.\n",
        "- **$\\mathbf{V}^T$**: An orthogonal matrix whose rows are called right singular vectors.\n",
        "\n",
        "**Analogy:** Imagine a complex transformation like a dance routine. SVD breaks it down into simpler moves:\n",
        "- **$\\mathbf{U}$**: The initial positioning and movements of dancers.\n",
        "- **$\\mathbf{\\Sigma}$**: The magnitude of each movement (how big or small each dance move is).\n",
        "- **$\\mathbf{V}^T$**: The final positioning and movements of dancers.\n",
        "\n",
        "**2. Why SVD is Useful:**\n",
        "- **Dimensionality Reduction:** By keeping only the top singular values, we can approximate the original matrix with fewer dimensions, simplifying computations.\n",
        "- **Noise Reduction:** Smaller singular values often represent noise. Removing them can clean the data.\n"
      ],
      "metadata": {
        "id": "e41IteWrH508"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Principal Component Analysis (PCA)\n",
        "\n",
        "PCA is a technique that uses SVD to reduce the dimensionality of data while preserving as much variance (information) as possible. It finds new axes (principal components) that better capture the spread of the data.\n",
        "\n",
        "**Steps in PCA:**\n",
        "\n",
        "1. **Center the Data:**\n",
        "   - Subtract the mean of each feature from the dataset. This centers the data around the origin.\n",
        "   - **Analogy:** Imagine you have several arrows pointing from different starting points. Centering them means moving their starting points to a common origin without changing their directions.\n",
        "\n",
        "2. **Compute the Covariance Matrix:**\n",
        "   - The covariance matrix measures how much each pair of features in the dataset vary together.\n",
        "   - **Analogy:** Think of the covariance matrix as a scorecard showing how two features change together. High scores mean they change similarly, while low scores mean they don't.\n",
        "\n",
        "3. **Perform SVD:**\n",
        "   - Decompose the covariance matrix using SVD.\n",
        "   - **Analogy:** Decomposing the scorecard into simpler components to understand the main patterns.\n",
        "\n",
        "4. **Select Principal Components:**\n",
        "   - Choose the top \\(k\\) eigenvectors (principal components) corresponding to the largest eigenvalues (variances).\n",
        "   - **Analogy:** If you’re trying to understand a dance, focus on the main steps and ignore minor foot movements. The principal components are these main steps.\n",
        "\n",
        "5. **Transform the Data:**\n",
        "   - Project the original data onto the selected principal components.\n",
        "   - **Analogy:** It's like watching the dance routine from an angle where the main steps are most visible and the noise is minimized.\n",
        "\n",
        "**Why PCA is Useful:**\n",
        "- **Simplifies Data:** Reduces the number of features, making analysis easier.\n",
        "- **Highlights Key Patterns:** Focuses on the most important variations in the data.\n",
        "- **Improves Performance:** Reduces computational load and enhances the performance of machine learning algorithms.\n"
      ],
      "metadata": {
        "id": "N2RvfkjNIEqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectors and Scalars\n"
      ],
      "metadata": {
        "id": "7-_Xe608Vzy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Vector\n",
        "v = np.array([3, 4])\n",
        "print(\"Vector v:\", v)\n",
        "\n",
        "# Scalar\n",
        "scalar = 2\n",
        "scaled_v = scalar * v\n",
        "print(\"Scaled vector:\", scaled_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSs88xiZDCMk",
        "outputId": "54f97d85-778c-42c0-c8b9-cfe0509c25fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector v: [3 4]\n",
            "Scaled vector: [6 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrices"
      ],
      "metadata": {
        "id": "f1FJTe_ZV5Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "print(\"Matrix A:\\n\", A)\n",
        "\n",
        "# Transforming a vector with a matrix\n",
        "v = np.array([1, 1])\n",
        "transformed_v = np.dot(A, v)\n",
        "print(\"Transformed vector:\", transformed_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD5H49DEV2lM",
        "outputId": "a484ef81-3b63-464a-84d9-4a2b4331cde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            " [[1 2]\n",
            " [3 4]]\n",
            "Transformed vector: [3 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Operations\n",
        "### Addition"
      ],
      "metadata": {
        "id": "8uvQzuQ6V8_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = np.array([1, 2])\n",
        "v2 = np.array([3, 4])\n",
        "v3 = v1 + v2\n",
        "print(\"Vector addition v1 + v2:\", v3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BQ5i-bMV6v_",
        "outputId": "53b6b921-7912-4755-eadc-87fb979cb999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector addition v1 + v2: [4 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dot Product"
      ],
      "metadata": {
        "id": "T3CdINxzWCwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dot_product = np.dot(v1, v2)\n",
        "print(\"Dot product v1 · v2:\", dot_product)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNupBMnVWAVc",
        "outputId": "978bd1c4-a4fd-4661-ca80-0357f0a0fb93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dot product v1 · v2: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Operations\n",
        "### Multiplication"
      ],
      "metadata": {
        "id": "qIhkzFduWGKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B = np.array([[2, 0], [1, 2]])\n",
        "C = np.dot(A, B)\n",
        "print(\"Matrix multiplication A * B:\\n\", C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kbRteZ3WEHT",
        "outputId": "4c62d6f1-8da0-4f04-c1ad-7fdef945f03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication A * B:\n",
            " [[ 4  4]\n",
            " [10  8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eigenvalues and Eigenvectors"
      ],
      "metadata": {
        "id": "Z_J6tmvwWZ_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B = np.array([[2, 0], [1, 2]])\n",
        "C = np.dot(A, B)\n",
        "print(\"Matrix multiplication A * B:\\n\", C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89CvZWoQWJNl",
        "outputId": "aac9bfe7-3061-4942-8ad1-9e2583fd3bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication A * B:\n",
            " [[ 4  4]\n",
            " [10  8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Spaces and Subspaces"
      ],
      "metadata": {
        "id": "bNFafkICWiQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basis vectors in 2D\n",
        "basis_vectors = np.array([[1, 0], [0, 1]])\n",
        "print(\"Basis vectors:\\n\", basis_vectors)\n",
        "\n",
        "# Subspace example (span of vectors)\n",
        "subspace = np.array([[1, 2], [2, 4]])\n",
        "print(\"Subspace vectors:\\n\", subspace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUja0YFOWcBb",
        "outputId": "ae39d429-d41d-4930-e5f1-598d3d4efcea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basis vectors:\n",
            " [[1 0]\n",
            " [0 1]]\n",
            "Subspace vectors:\n",
            " [[1 2]\n",
            " [2 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Independence"
      ],
      "metadata": {
        "id": "KLUwg_K4WpGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import matrix_rank\n",
        "\n",
        "# Check if vectors are linearly independent\n",
        "vectors = np.array([[1, 2], [3, 4]])\n",
        "rank = matrix_rank(vectors) # https://github.com/numpy/numpy/blob/v1.26.0/numpy/linalg/linalg.py#L1825-L1927\n",
        "print(\"Rank of vectors (linearly independent if rank equals number of vectors):\", rank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsJAMgd9WmjO",
        "outputId": "53138e49-8971-4dfe-eca8-a459383933b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank of vectors (linearly independent if rank equals number of vectors): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basis and Dimension\n"
      ],
      "metadata": {
        "id": "tCszU9qAWveA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimension of a vector space\n",
        "dimension = basis_vectors.shape[0]\n",
        "print(\"Dimension of the vector space:\", dimension)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrtA3HWfWvJA",
        "outputId": "30a83ede-55c4-45e2-ac1d-c8c4bf3e8c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of the vector space: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Orthogonality"
      ],
      "metadata": {
        "id": "TlPcXXvXW3bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check orthogonality\n",
        "orthogonal = np.dot(basis_vectors[0], basis_vectors[1]) == 0\n",
        "print(\"Vectors are orthogonal:\", orthogonal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWSAn6zSWzKb",
        "outputId": "7f44b64b-271a-4a79-b48a-bb9b1ec37fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectors are orthogonal: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Projections"
      ],
      "metadata": {
        "id": "mSjDHXVlW6T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = np.array([2, 3])\n",
        "v = np.array([4, 5])\n",
        "\n",
        "# Projection of v onto u\n",
        "projection = (np.dot(v, u) / np.dot(u, u)) * u\n",
        "print(\"Projection of v onto u:\", projection)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHRV0JlpW4lG",
        "outputId": "4b0d10f5-4d04-4a8c-e24c-f7c8e6e013c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Projection of v onto u: [3.53846154 5.30769231]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Singular Value Decomposition (SVD)"
      ],
      "metadata": {
        "id": "OvIKSj-CXClr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "U, Sigma, VT = np.linalg.svd(A)\n",
        "print(\"Matrix U:\\n\", U)\n",
        "print(\"Matrix Sigma:\\n\", np.diag(Sigma))\n",
        "print(\"Matrix VT:\\n\", VT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMeyomGBW74q",
        "outputId": "201d1bb6-1581-4a68-f036-35c105aa4117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix U:\n",
            " [[-0.40455358 -0.9145143 ]\n",
            " [-0.9145143   0.40455358]]\n",
            "Matrix Sigma:\n",
            " [[5.4649857  0.        ]\n",
            " [0.         0.36596619]]\n",
            "Matrix VT:\n",
            " [[-0.57604844 -0.81741556]\n",
            " [ 0.81741556 -0.57604844]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Principal Component Analysis (PCA)"
      ],
      "metadata": {
        "id": "2RBIEeUfXFl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data = np.array([[2.5, 2.4],\n",
        "                 [0.5, 0.7],\n",
        "                 [2.2, 2.9],\n",
        "                 [1.9, 2.2],\n",
        "                 [3.1, 3.0],\n",
        "                 [2.3, 2.7],\n",
        "                 [2.0, 1.6],\n",
        "                 [1.0, 1.1],\n",
        "                 [1.5, 1.6],\n",
        "                 [1.1, 0.9]])\n",
        "\n",
        "# Applying PCA directly with SVD\n",
        "mean_data = np.mean(data, axis=0)\n",
        "centered_data = data - mean_data #(x-avg(x))\n",
        "U, Sigma, VT = np.linalg.svd(centered_data)\n",
        "\n",
        "# Select the top principal component\n",
        "top_component = VT.T[:, 0]\n",
        "print(\"Top principal component:\", top_component)\n",
        "# Project the data onto the top principal component\n",
        "projected_data = np.dot(centered_data, top_component)\n",
        "print(\"Projected data:\\n\", projected_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDP4ceLbXDoP",
        "outputId": "74c5b59e-8247-4da7-cff0-cbab11e31312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top principal component: [-0.6778734  -0.73517866]\n",
            "Projected data:\n",
            " [-0.82797019  1.77758033 -0.99219749 -0.27421042 -1.67580142 -0.9129491\n",
            "  0.09910944  1.14457216  0.43804614  1.22382056]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Example data\n",
        "data = np.array([[2.5, 2.4],\n",
        "                 [0.5, 0.7],\n",
        "                 [2.2, 2.9],\n",
        "                 [1.9, 2.2],\n",
        "                 [3.1, 3.0],\n",
        "                 [2.3, 2.7],\n",
        "                 [2.0, 1.6],\n",
        "                 [1.0, 1.1],\n",
        "                 [1.5, 1.6],\n",
        "                 [1.1, 0.9]])\n",
        "\n",
        "# Applying PCA\n",
        "pca = PCA(n_components=2)\n",
        "transformed_data = pca.fit_transform(data)\n",
        "print(\"Transformed data:\\n\", transformed_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZaIe_3JXVNC",
        "outputId": "7e1dac4e-9c8f-4ac6-db20-9d272cbe1b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data:\n",
            " [[-0.82797019 -0.17511531]\n",
            " [ 1.77758033  0.14285723]\n",
            " [-0.99219749  0.38437499]\n",
            " [-0.27421042  0.13041721]\n",
            " [-1.67580142 -0.20949846]\n",
            " [-0.9129491   0.17528244]\n",
            " [ 0.09910944 -0.3498247 ]\n",
            " [ 1.14457216  0.04641726]\n",
            " [ 0.43804614  0.01776463]\n",
            " [ 1.22382056 -0.16267529]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ArJyyVb4XYyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}