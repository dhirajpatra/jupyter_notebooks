{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np0plMPXRvoq"
   },
   "source": [
    "# Lesson 7 - Schema Proposal for Unstructured Data\n",
    "\n",
    "In this lesson, you will design agents that propose how to extract information from unstructured data.\n",
    "\n",
    "You'll learn:\n",
    "- how \"named entity recognition\" can be used to identify the people, places and things\n",
    "- how facts can be extracted as a \"triple\" of subject, predicate and object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>To access the helper.py, neo4j_for_adk.py and tools.py files :</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/entire_solution.png\" width=\"500\">\n",
    "\n",
    "Two agents to propose data extraction from unstructured data: a \"named entity recognition\" agent and a \"fact extraction\" agent:\n",
    "\n",
    "- Input: `approved_user_goal`, `approved_files`, `approved_construction_plan`\n",
    "- Output: \n",
    "    - `approved_entity_types` describing the type of entities that could be extracted from the unstructured data\n",
    "    - `approved_fact_types` describing how those entities can be related in a fact triple\n",
    "- Tools: `get_approved_user_goal`, `get_approved_files`, `get_well_known_types`, `sample_file`, `set_proposed_entities`, `get_proposed_entities`, `approve_proposed_entities`, `add_proposed_fact`, `get_proposed_facts`, `approve_proposed_facts`\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "<img src=\"images/workflow.png\" width=\"500\">\n",
    "\n",
    "Named entity recognition:\n",
    "\n",
    "1. The context is initialized with an `approved_user_goal`, `approved_files` and an `approved_construction_plan`\n",
    "2. The agent analyzes unstructured data files, looking for relevant entity types \n",
    "3. The agent proposes a list of entity types, seeking user approval\n",
    "\n",
    "Fact extraction:\n",
    "\n",
    "1. The context now includes `approved_entity_types`\n",
    "2. The agent analyzes unstructured data files, looking for how those entities can be saved as fact triples\n",
    "3. The agent proposes fact types, seeking user approval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual import of needed libraries, loading of environment variables, and connection to Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 301,
    "id": "sbwxKypOSBkN"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184,
    "id": "MI_qvZJrSJuR"
   },
   "outputs": [],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "# Check connection to Neo4j by sending a query\n",
    "\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Named Entity Recognition (NER) Sub-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NER agent is responsible for proposing entities that could be extracted from the unstructured data files.\n",
    "\n",
    "An entity is a person, place or thing that is relevant to the user's goal.\n",
    "\n",
    "There are two general kinds of entities:\n",
    "\n",
    "1. Well-known entities: these closely correlate with nodes in the existing structured data\n",
    "   - in our example, this would be things like Products, Parts and Suppliers\n",
    "2. Discovered entities: these are entities that are not pre-defined, but are mentioned in the markdown text\n",
    "    - in the product reviews, this may may Reviewers, product complaints, or product features\n",
    "\n",
    "The general goal of the NER agent is to analyze the markdown files and propose entities that are \n",
    "relevant to the user goal of root-cause analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1. Agent Instructions (NER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "ner_agent_role_and_goal = \"\"\"\n",
    "  You are a top-tier algorithm designed for analyzing text files and proposing\n",
    "  the kind of named entities that could be extracted which would be relevant \n",
    "  for a user's goal.\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 371
   },
   "outputs": [],
   "source": [
    "ner_agent_hints = \"\"\"\n",
    "  Entities are people, places, things and qualities, but not quantities. \n",
    "  Your goal is to propose a list of the type of entities, not the actual instances\n",
    "  of entities.\n",
    "\n",
    "  There are two general approaches to identifying types of entities:\n",
    "  - well-known entities: these closely correlate with approved node labels in an existing graph schema\n",
    "  - discovered entities: these may not exist in the graph schema, but appear consistently in the source text\n",
    "\n",
    "  Design rules for well-known entities:\n",
    "  - always use existing well-known entity types. For example, if there is a well-known type \"Person\", and people appear in the text, then propose \"Person\" as the type of entity.\n",
    "  - prefer reusing existing entity types rather than creating new ones\n",
    "  \n",
    "  Design rules for discovered entities:\n",
    "  - discovered entities are consistently mentioned in the text and are highly relevant to the user's goal\n",
    "  - always look for entities that would provide more depth or breadth to the existing graph\n",
    "  - for example, if the user goal is to represent social communities and the graph has \"Person\" nodes, look through the text to discover entities that are relevant like \"Hobby\" or \"Event\"\n",
    "  - avoid quantitative types that may be better represented as a property on an existing entity or relationship.\n",
    "  - for example, do not propose \"Age\" as a type of entity. That is better represented as an additional property \"age\" on a \"Person\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 286
   },
   "outputs": [],
   "source": [
    "ner_agent_chain_of_thought_directions = \"\"\"\n",
    "  Prepare for the task:\n",
    "  - use the 'get_user_goal' tool to get the user goal\n",
    "  - use the 'get_approved_files' tool to get the list of approved files\n",
    "  - use the 'get_well_known_types' tool to get the approved node labels\n",
    "\n",
    "  Think step by step:\n",
    "  1. Sample some of the files using the 'sample_file' tool to understand the content\n",
    "  2. Consider what well-known entities are mentioned in the text\n",
    "  3. Discover entities that are frequently mentioned in the text that support the user's goal\n",
    "  4. Use the 'set_proposed_entities' tool to save the list of well-known and discovered entity types\n",
    "  5. Use the 'get_proposed_entities' tool to retrieve the proposed entities and present them to the user for their approval\n",
    "  6. If the user approves, use the 'approve_proposed_entities' tool to finalize the entity types\n",
    "  7. If the user does not approve, consider their feedback and iterate on the proposal\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 131
   },
   "outputs": [],
   "source": [
    "ner_agent_instruction = f\"\"\"\n",
    "{ner_agent_role_and_goal}\n",
    "{ner_agent_hints}\n",
    "{ner_agent_chain_of_thought_directions}\n",
    "\"\"\"\n",
    "\n",
    "#print(ner_agent_instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2. Tool Definitions (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous lessons, you'll define some tools that explictly follow\n",
    "a propose then approve pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 490
   },
   "outputs": [],
   "source": [
    "# tools to propose and approve entity types\n",
    "PROPOSED_ENTITIES = \"proposed_entity_types\"\n",
    "APPROVED_ENTITIES = \"approved_entity_types\"\n",
    "\n",
    "def set_proposed_entities(proposed_entity_types: list[str], tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Sets the list proposed entity types to extract from unstructured text.\"\"\"\n",
    "    tool_context.state[PROPOSED_ENTITIES] = proposed_entity_types\n",
    "    return tool_success(PROPOSED_ENTITIES, proposed_entity_types)\n",
    "\n",
    "def get_proposed_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Gets the list of proposed entity types to extract from unstructured text.\"\"\"\n",
    "    return tool_context.state.get(PROPOSED_ENTITIES, [])\n",
    "\n",
    "def approve_proposed_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Upon approval from user, records the proposed entity types as an approved list of entity types \n",
    "\n",
    "    Only call this tool if the user has explicitly approved the suggested files.\n",
    "    \"\"\"\n",
    "    if PROPOSED_ENTITIES not in tool_context.state:\n",
    "        return tool_error(\"No proposed entity types to approve. Please set proposed entities first, ask for user approval, then call this tool.\")\n",
    "    tool_context.state[APPROVED_ENTITIES] = tool_context.state.get(PROPOSED_ENTITIES)\n",
    "    return tool_success(APPROVED_ENTITIES, tool_context.state[APPROVED_ENTITIES])\n",
    "\n",
    "def get_approved_entities(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Get the approved list of entity types to extract from unstructured text.\"\"\"\n",
    "    return tool_context.state.get(APPROVED_ENTITIES, [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"well-known entities\" are based on existing node labels used during graph construction.\n",
    "\n",
    "This helper tool will get the existing node labels from the approved construction plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 167
   },
   "outputs": [],
   "source": [
    "def get_well_known_types(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Gets the approved labels that represent well-known entity types in the graph schema.\"\"\"\n",
    "    construction_plan = tool_context.state.get(\"approved_construction_plan\", {})\n",
    "    # approved labels are the keys for each construction plan entry where `construction_type` is \"node\"\n",
    "    approved_labels = {entry[\"label\"] for entry in construction_plan.values() if entry[\"construction_type\"] == \"node\"}\n",
    "    return tool_success(\"approved_labels\", approved_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full toolset includes some existing tools that you'll import\n",
    "plus the extra tools you just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 150
   },
   "outputs": [],
   "source": [
    "from tools import get_approved_user_goal, get_approved_files, sample_file\n",
    "ner_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files, sample_file,\n",
    "    get_well_known_types,\n",
    "    set_proposed_entities,\n",
    "    approve_proposed_entities\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what the NER agent is working with, use the sample_file tool to look\n",
    "at one of the markdown files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 82
   },
   "outputs": [],
   "source": [
    "file_result = sample_file(\"product_reviews/gothenburg_table_reviews.md\")\n",
    "\n",
    "print(file_result[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The markdown has product reviews from multiple users that include a rating, the review and their username.\n",
    "\n",
    "For root-cause analysis, you'll be interested in reviews that are negative and report product issues\n",
    "like quality, challenges in assembly, or reliability.\n",
    "\n",
    "We won't provide explicit instructions about product reviews to the agent, instead relying\n",
    "on a combination of the stated user goal along with instruction to find entity types\n",
    "that would support that user goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3. Construct the Sub-agent (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184
   },
   "outputs": [],
   "source": [
    "NER_AGENT_NAME = \"ner_schema_agent_v1\"\n",
    "ner_schema_agent = Agent(\n",
    "    name=NER_AGENT_NAME,\n",
    "    description=\"Proposes the kind of named entities that could be extracted from text files.\",\n",
    "    model=llm,\n",
    "    instruction=ner_agent_instruction,\n",
    "    tools=ner_agent_tools, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial state is important in this phase, as the agent is designed to act\n",
    "within a particular phase of an overall workflow.\n",
    "\n",
    "The NER agent will need:\n",
    "\n",
    "- the user goal, extended to mention product reviews and what to look for there\n",
    "- a list of markdown files that have been pre-approved\n",
    "- the approved construction plan from the structured data design phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 677
   },
   "outputs": [],
   "source": [
    "ner_agent_initial_state = {\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"supply chain analysis\",\n",
    "        \"description\": \"\"\"A multi-level bill of materials for manufactured products, useful for root cause analysis. \n",
    "        Add product reviews to start analysis from reported issues like quality, difficulty, or durability.\"\"\"\n",
    "    },\n",
    "    \"approved_files\": [\n",
    "        \"product_reviews/gothenburg_table_reviews.md\",\n",
    "        \"product_reviews/helsingborg_dresser_reviews.md\",\n",
    "        \"product_reviews/jonkoping_coffee_table_reviews.md\",\n",
    "        \"product_reviews/linkoping_bed_reviews.md\",\n",
    "        \"product_reviews/malmo_desk_reviews.md\",\n",
    "        \"product_reviews/norrkoping_nightstand_reviews.md\",\n",
    "        \"product_reviews/orebro_lamp_reviews.md\",\n",
    "        \"product_reviews/stockholm_chair_reviews.md\",\n",
    "        \"product_reviews/uppsala_sofa_reviews.md\",\n",
    "        \"product_reviews/vasteras_bookshelf_reviews.md\"\n",
    "    ],\n",
    "    \"approved_construction_plan\": {\n",
    "        \"Product\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Product\",\n",
    "        },\n",
    "        \"Assembly\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Assembly\",\n",
    "        },\n",
    "        \"Part\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Part\",\n",
    "        },\n",
    "        \"Supplier\": {\n",
    "            \"construction_type\": \"node\",\n",
    "            \"label\": \"Supplier\",\n",
    "        }\n",
    "        # Relationship construction omitted, since it won't get used in this notebook\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, you're ready to run the agent. \n",
    "\n",
    "- use the make_agent_caller to create an execution environment\n",
    "- prompt the agent with a single message that should kick-off the analysis\n",
    "- expect the result to be a proposed list of entity types\n",
    "- but *not* a list of approved entity types\n",
    "\n",
    "**The entity types here may vary quite a bit. If you're not happy with the proposal,\n",
    "you can run the cell again to get a new list.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by LLMs can vary with each execution due to their stochastic nature. Your results might differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 405
   },
   "outputs": [],
   "source": [
    "from helper import make_agent_caller\n",
    "\n",
    "ner_agent_caller = await make_agent_caller(ner_schema_agent, ner_agent_initial_state)\n",
    "\n",
    "await ner_agent_caller.call(\"Add product reviews to the knowledge graph to trace product complaints back through the manufacturing process.\")\n",
    "\n",
    "# Alternatively, uncomment this line to get verbose output\n",
    "# await ner_agent_caller.call(\"Add product reviews.\", True)\n",
    "\n",
    "session_end = await ner_agent_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"\\nSession state: \", session_end.state)\n",
    "\n",
    "if PROPOSED_ENTITIES in session_end.state:\n",
    "    print(\"\\nProposed entities: \", session_end.state[PROPOSED_ENTITIES])\n",
    "\n",
    "if APPROVED_ENTITIES in session_end.state:\n",
    "    print(\"\\nInappropriately approved entities: \", session_end.state[APPROVED_ENTITIES])\n",
    "else:\n",
    "    print(\"\\nAwaiting approval.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "- often, the agent will confuse the process of \"Assembly\" with the resulting thing that is an \"Assembly\"\n",
    "- why is that?\n",
    "- the agent will see the term \"Assembly\" in the list of well-known entity types\n",
    "- and, it will notice complaints about assembling furniture\n",
    "- but, it has no way to know those are two different uses of the word\n",
    "- to fix this, the schema proposal from the previous lesson could save descriptions for each node label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're happy with the proposal, you can tell the agent that you approve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 235
   },
   "outputs": [],
   "source": [
    "await ner_agent_caller.call(\"Approve the proposed entities.\")\n",
    "\n",
    "session_end = await ner_agent_caller.get_session()\n",
    "\n",
    "ner_end_state = session_end.state if session_end else {}\n",
    "\n",
    "print(\"Session state: \", ner_end_state)\n",
    "\n",
    "if APPROVED_ENTITIES in ner_end_state:\n",
    "    print(\"\\nApproved entities: \", ner_end_state[APPROVED_ENTITIES])\n",
    "else:\n",
    "    print(\"\\nStill awaiting approval? That is weird. Please check the agent's state and the proposed entities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Fact Type Extraction Sub-agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1. Agent Instructions (fact type extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "fact_agent_role_and_goal = \"\"\"\n",
    "  You are a top-tier algorithm designed for analyzing text files and proposing\n",
    "  the type of facts that could be extracted from text that would be relevant \n",
    "  for a user's goal. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 303
   },
   "outputs": [],
   "source": [
    "fact_agent_hints = \"\"\"\n",
    "  Do not propose specific individual facts, but instead propose the general type \n",
    "  of facts that would be relevant for the user's goal. \n",
    "  For example, do not propose \"ABK likes coffee\" but the general type of fact \"Person likes Beverage\".\n",
    "  \n",
    "  Facts are triplets of (subject, predicate, object) where the subject and object are\n",
    "  approved entity types, and the proposed predicate provides information about\n",
    "  how they are related. For example, a fact type could be (Person, likes, Beverage).\n",
    "\n",
    "  Design rules for facts:\n",
    "  - only use approved entity types as subjects or objects. Do not propose new types of entities\n",
    "  - the proposed predicate should describe the relationship between the approved subject and object\n",
    "  - the predicate should optimize for information that is relevant to the user's goal\n",
    "  - the predicate must appear in the source text. Do not guess.\n",
    "  - use the 'add_proposed_fact' tool to record each proposed fact type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 269
   },
   "outputs": [],
   "source": [
    "fact_agent_chain_of_thought_directions = \"\"\"\n",
    "    Prepare for the task:\n",
    "    - use the 'get_approved_user_goal' tool to get the user goal\n",
    "    - use the 'get_approved_files' tool to get the list of approved files\n",
    "    - use the 'get_approved_entities' tool to get the list of approved entity types\n",
    "\n",
    "    Think step by step:\n",
    "    1. Use the 'get_approved_user_goal' tool to get the user goal\n",
    "    2. Sample some of the approved files using the 'sample_file' tool to understand the content\n",
    "    3. Consider how subjects and objects are related in the text\n",
    "    4. Call the 'add_proposed_fact' tool for each type of fact you propose\n",
    "    5. Use the 'get_proposed_facts' tool to retrieve all the proposed facts\n",
    "    6. Present the proposed types of facts to the user, along with an explanation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 97
   },
   "outputs": [],
   "source": [
    "fact_agent_instruction = f\"\"\"\n",
    "{fact_agent_role_and_goal}\n",
    "{fact_agent_hints}\n",
    "{fact_agent_chain_of_thought_directions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2. Tool Definitions (fact type extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 881
   },
   "outputs": [],
   "source": [
    "PROPOSED_FACTS = \"proposed_fact_types\"\n",
    "APPROVED_FACTS = \"approved_fact_types\"\n",
    "\n",
    "def add_proposed_fact(approved_subject_label:str,\n",
    "                      proposed_predicate_label:str,\n",
    "                      approved_object_label:str,\n",
    "                      tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Add a proposed type of fact that could be extracted from the files.\n",
    "\n",
    "    A proposed fact type is a tuple of (subject, predicate, object) where\n",
    "    the subject and object are approved entity types and the predicate \n",
    "    is a proposed relationship label.\n",
    "\n",
    "    Args:\n",
    "      approved_subject_label: approved label of the subject entity type\n",
    "      proposed_predicate_label: label of the predicate\n",
    "      approved_object_label: approved label of the object entity type\n",
    "    \"\"\"\n",
    "    # Guard against invalid labels\n",
    "    approved_entities = tool_context.state.get(APPROVED_ENTITIES, [])\n",
    "    \n",
    "    if approved_subject_label not in approved_entities:\n",
    "        return tool_error(f\"Approved subject label {approved_subject_label} not found. Try again.\")\n",
    "    if approved_object_label not in approved_entities:\n",
    "        return tool_error(f\"Approved object label {approved_object_label} not found. Try again.\")\n",
    "    \n",
    "    current_predicates = tool_context.state.get(PROPOSED_FACTS, {})\n",
    "    current_predicates[proposed_predicate_label] = {\n",
    "        \"subject_label\": approved_subject_label,\n",
    "        \"predicate_label\": proposed_predicate_label,\n",
    "        \"object_label\": approved_object_label\n",
    "    }\n",
    "    tool_context.state[PROPOSED_FACTS] = current_predicates\n",
    "    return tool_success(PROPOSED_FACTS, current_predicates)\n",
    "    \n",
    "def get_proposed_facts(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Get the proposed types of facts that could be extracted from the files.\"\"\"\n",
    "    return tool_context.state.get(PROPOSED_FACTS, {})\n",
    "\n",
    "\n",
    "def approve_proposed_facts(tool_context:ToolContext) -> dict:\n",
    "    \"\"\"Upon user approval, records the proposed fact types as approved fact types\n",
    "\n",
    "    Only call this tool if the user has explicitly approved the proposed fact types.\n",
    "    \"\"\"\n",
    "    if PROPOSED_FACTS not in tool_context.state:\n",
    "        return tool_error(\"No proposed fact types to approve. Please set proposed facts first, ask for user approval, then call this tool.\")\n",
    "    tool_context.state[APPROVED_FACTS] = tool_context.state.get(PROPOSED_FACTS)\n",
    "    return tool_success(APPROVED_FACTS, tool_context.state[APPROVED_FACTS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 148
   },
   "outputs": [],
   "source": [
    "fact_agent_tools = [\n",
    "    get_approved_user_goal, get_approved_files, \n",
    "    get_approved_entities,\n",
    "    sample_file,\n",
    "    add_proposed_fact,\n",
    "    get_proposed_facts,\n",
    "    approve_proposed_facts\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3. Construct the Sub-agent (fact type extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184
   },
   "outputs": [],
   "source": [
    "FACT_AGENT_NAME = \"fact_type_extraction_agent_v1\"\n",
    "relevant_fact_agent = Agent(\n",
    "    name=FACT_AGENT_NAME,\n",
    "    description=\"Proposes the kind of relevant facts that could be extracted from text files.\",\n",
    "    model=llm,\n",
    "    instruction=fact_agent_instruction,\n",
    "    tools=fact_agent_tools, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by LLMs can vary with each execution due to their stochastic nature. Your results might differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 490
   },
   "outputs": [],
   "source": [
    "# make a copy of the NER agent's end state to use as the initial state for the fact agent\n",
    "fact_agent_initial_state = ner_end_state.copy()\n",
    "\n",
    "fact_agent_caller = await make_agent_caller(relevant_fact_agent, fact_agent_initial_state)\n",
    "\n",
    "await fact_agent_caller.call(\"Propose fact types that can be found in the text.\")\n",
    "# await fact_agent_caller.call(\"Propose fact types that can be found in the text.\", True)\n",
    "\n",
    "session_end = await fact_agent_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"\\nSession state: \", session_end.state)\n",
    "\n",
    "print(\"\\nApproved entities: \", session_end.state.get(APPROVED_ENTITIES, []))\n",
    "\n",
    "# Check that the agent proposed facts\n",
    "if PROPOSED_FACTS in session_end.state:\n",
    "    print(\"\\nCorrectly proposed facts: \", session_end.state[PROPOSED_FACTS])\n",
    "else:\n",
    "    print(\"\\nProposed facts not found in session state. What went wrong?\")\n",
    "\n",
    "# Check that the agent did not inappropriately approve facts\n",
    "if APPROVED_FACTS in session_end.state:\n",
    "    print(\"\\nInappriately approved facts: \", session_end.state[APPROVED_FACTS])\n",
    "else:\n",
    "    print(\"\\nApproved facts not found in session state, which is good.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're happy with the fact type proposal, approve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 201
   },
   "outputs": [],
   "source": [
    "await fact_agent_caller.call(\"Approve the proposed fact types.\")\n",
    "\n",
    "session_end = await fact_agent_caller.get_session()\n",
    "\n",
    "print(\"Session state: \", session_end.state)\n",
    "\n",
    "if APPROVED_FACTS in session_end.state:\n",
    "    print(\"\\nApproved fact types: \", session_end.state[APPROVED_FACTS])\n",
    "else:\n",
    "    print(\"\\nFailed to approve fact types.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
