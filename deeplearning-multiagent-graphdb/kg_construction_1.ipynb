{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np0plMPXRvoq"
   },
   "source": [
    "# Lesson 8 - Knowledge Graph Construction - Part I\n",
    "\n",
    "With all the plans in place, it's time to construct the knowledge graph. \n",
    "\n",
    "For the **domain graph** construction, no agent is required. The construction plan has all the information needed to drive a rule-based import.\n",
    "\n",
    "<img src=\"images/domain.png\" width=\"600\">\n",
    "\n",
    "**Note**: This notebook uses Cypher queries to build the domain graph from CSV files. Don't worry if you're unfamiliar with Cypher â€” focus on understanding the big picture of how the structured data is transformed into a graph structure based on the construction plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single tool which will build a knowledge graph using the defined construction rules.\n",
    "- Input: `approved_construction_plan`\n",
    "- Output: a domain graph in Neo4j\n",
    "- Tools: `construct_domain_graph` + helper functions\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "1. The context is initialized with an `approved_construction_plan` and `approved_files`\n",
    "2. Process all the node construction rules\n",
    "3. Process all the relationship construction rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual import of needed libraries, loading of environment variables, and connection to Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 301,
    "id": "sbwxKypOSBkN"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "from typing import Dict, Any\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 184,
    "id": "MI_qvZJrSJuR"
   },
   "outputs": [],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "# Check connection to Neo4j by sending a query\n",
    "\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. Tool Definitions (Domain Graph Construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `construct_domain_graph` tool is responsible for constructing the \"domain graph\" from CSV files,\n",
    "according to the approved construction plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: create_uniqueness_constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This function creates a uniqueness constraint in Neo4j to prevent duplicate nodes with the same label and property value from being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 439
   },
   "outputs": [],
   "source": [
    "def create_uniqueness_constraint(\n",
    "    label: str,\n",
    "    unique_property_key: str,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Creates a uniqueness constraint for a node label and property key.\n",
    "    A uniqueness constraint ensures that no two nodes with the same label and property key have the same value.\n",
    "    This improves the performance and integrity of data import and later queries.\n",
    "\n",
    "    Args:\n",
    "        label: The label of the node to create a constraint for.\n",
    "        unique_property_key: The property key that should have a unique value.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with a status key ('success' or 'error').\n",
    "        On error, includes an 'error_message' key.\n",
    "    \"\"\"    \n",
    "    # Use string formatting since Neo4j doesn't support parameterization of labels and property keys when creating a constraint\n",
    "    constraint_name = f\"{label}_{unique_property_key}_constraint\"\n",
    "    query = f\"\"\"CREATE CONSTRAINT `{constraint_name}` IF NOT EXISTS\n",
    "    FOR (n:`{label}`)\n",
    "    REQUIRE n.`{unique_property_key}` IS UNIQUE\"\"\"\n",
    "    results = graphdb.send_query(query)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: load_nodes_from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs batch loading of nodes from a CSV file into Neo4j. It uses the `LOAD CSV` command with the `MERGE` operation to create nodes while avoiding duplicates based on the unique column. The Cypher query processes data in batches of 1000 rows for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The csv files are stored in the `/import` directory of `neo4j` database. When you use the query `LOAD CSV from \"file:///\" + $source_file`, neo4j checks the `/import` directory by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 439
   },
   "outputs": [],
   "source": [
    "def load_nodes_from_csv(\n",
    "    source_file: str,\n",
    "    label: str,\n",
    "    unique_column_name: str,\n",
    "    properties: list[str],\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Batch loading of nodes from a CSV file\"\"\"\n",
    "\n",
    "    # load nodes from CSV file by merging on the unique_column_name value\n",
    "    query = f\"\"\"LOAD CSV WITH HEADERS FROM \"file:///\" + $source_file AS row\n",
    "    CALL (row) {{\n",
    "        MERGE (n:$($label) {{ {unique_column_name} : row[$unique_column_name] }})\n",
    "        FOREACH (k IN $properties | SET n[k] = row[k])\n",
    "    }} IN TRANSACTIONS OF 1000 ROWS\n",
    "    \"\"\"\n",
    "\n",
    "    results = graphdb.send_query(query, {\n",
    "        \"source_file\": source_file,\n",
    "        \"label\": label,\n",
    "        \"unique_column_name\": unique_column_name,\n",
    "        \"properties\": properties\n",
    "    })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Domain Graph Construction\n",
    "\n",
    "This cell executes the main construction function using the approved construction plan. It builds the complete knowledge graph by importing all nodes and relationships according to the defined rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: import_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function orchestrates the node import process by first creating a uniqueness constraint and then loading nodes from the CSV file. It ensures data integrity by establishing constraints before importing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 369
   },
   "outputs": [],
   "source": [
    "def import_nodes(node_construction: dict) -> dict:\n",
    "    \"\"\"Import nodes as defined by a node construction rule.\"\"\"\n",
    "\n",
    "    # create a uniqueness constraint for the unique_column\n",
    "    uniqueness_result = create_uniqueness_constraint(\n",
    "        node_construction[\"label\"],\n",
    "        node_construction[\"unique_column_name\"]\n",
    "    )\n",
    "\n",
    "    if (uniqueness_result[\"status\"] == \"error\"):\n",
    "        return uniqueness_result\n",
    "\n",
    "    # import nodes from csv\n",
    "    load_nodes_result = load_nodes_from_csv(\n",
    "        node_construction[\"source_file\"],\n",
    "        node_construction[\"label\"],\n",
    "        node_construction[\"unique_column_name\"],\n",
    "        node_construction[\"properties\"]\n",
    "    )\n",
    "\n",
    "    return load_nodes_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: import_relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function imports relationships between nodes from a CSV file. It uses a Cypher query that matches existing nodes and creates relationships between them. The query finds pairs of nodes and creates relationships with specified properties between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 456
   },
   "outputs": [],
   "source": [
    "def import_relationships(relationship_construction: dict) -> Dict[str, Any]:\n",
    "    \"\"\"Import relationships as defined by a relationship construction rule.\"\"\"\n",
    "\n",
    "    # load nodes from CSV file by merging on the unique_column_name value \n",
    "    from_node_column = relationship_construction[\"from_node_column\"]\n",
    "    to_node_column = relationship_construction[\"to_node_column\"]\n",
    "    query = f\"\"\"LOAD CSV WITH HEADERS FROM \"file:///\" + $source_file AS row\n",
    "    CALL (row) {{\n",
    "        MATCH (from_node:$($from_node_label) {{ {from_node_column} : row[$from_node_column] }}),\n",
    "              (to_node:$($to_node_label) {{ {to_node_column} : row[$to_node_column] }} )\n",
    "        MERGE (from_node)-[r:$($relationship_type)]->(to_node)\n",
    "        FOREACH (k IN $properties | SET r[k] = row[k])\n",
    "    }} IN TRANSACTIONS OF 1000 ROWS\n",
    "    \"\"\"\n",
    "    \n",
    "    results = graphdb.send_query(query, {\n",
    "        \"source_file\": relationship_construction[\"source_file\"],\n",
    "        \"from_node_label\": relationship_construction[\"from_node_label\"],\n",
    "        \"from_node_column\": relationship_construction[\"from_node_column\"],\n",
    "        \"to_node_label\": relationship_construction[\"to_node_label\"],\n",
    "        \"to_node_column\": relationship_construction[\"to_node_column\"],\n",
    "        \"relationship_type\": relationship_construction[\"relationship_type\"],\n",
    "        \"properties\": relationship_construction[\"properties\"]\n",
    "    })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: construct_domain_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main orchestration function that builds the entire domain graph. It processes the construction plan in two phases:\n",
    "1. **Node Construction**: First imports all nodes to ensure they exist before creating relationships\n",
    "2. **Relationship Construction**: Then creates relationships between the existing nodes\n",
    "\n",
    "This two-phase approach prevents relationship creation failures due to missing nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 218
   },
   "outputs": [],
   "source": [
    "def construct_domain_graph(construction_plan: dict) -> Dict[str, Any]:\n",
    "    \"\"\"Construct a domain graph according to a construction plan.\"\"\"\n",
    "    # first, import nodes\n",
    "    node_constructions = [value for value in construction_plan.values() if value['construction_type'] == 'node']\n",
    "    for node_construction in node_constructions:\n",
    "        import_nodes(node_construction)\n",
    "\n",
    "    # second, import relationships\n",
    "    relationship_constructions = [value for value in construction_plan.values() if value['construction_type'] == 'relationship']\n",
    "    for relationship_construction in relationship_constructions:\n",
    "        import_relationships(relationship_construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4. Run construct_domain_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines the approved construction plan as a dictionary containing rules for creating nodes and relationships. The plan includes:\n",
    "\n",
    "- **Node Rules**: Define how to create Assembly, Part, Product, and Supplier nodes from CSV files\n",
    "- **Relationship Rules**: Define how to create Contains, Is_Part_Of, and Supplied_By relationships\n",
    "\n",
    "Each rule specifies the source file, labels, unique identifiers, and properties to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 1085
   },
   "outputs": [],
   "source": [
    "# the approved construction plan should look something like this...\n",
    "approved_construction_plan = {\n",
    "    \"Assembly\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"assemblies.csv\", \n",
    "        \"label\": \"Assembly\", \n",
    "        \"unique_column_name\": \"assembly_id\", \n",
    "        \"properties\": [\"assembly_name\", \"quantity\", \"product_id\"]\n",
    "    }, \n",
    "    \"Part\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"parts.csv\", \n",
    "        \"label\": \"Part\", \n",
    "        \"unique_column_name\": \"part_id\", \n",
    "        \"properties\": [\"part_name\", \"quantity\", \"assembly_id\"]\n",
    "    }, \n",
    "    \"Product\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"products.csv\", \n",
    "        \"label\": \"Product\", \n",
    "        \"unique_column_name\": \"product_id\", \n",
    "        \"properties\": [\"product_name\", \"price\", \"description\"]\n",
    "    }, \n",
    "    \"Supplier\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"suppliers.csv\", \n",
    "        \"label\": \"Supplier\", \n",
    "        \"unique_column_name\": \"supplier_id\", \n",
    "        \"properties\": [\"name\", \"specialty\", \"city\", \"country\", \"website\", \"contact_email\"]\n",
    "    }, \n",
    "    \"Contains\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"assemblies.csv\", \n",
    "        \"relationship_type\": \"Contains\", \n",
    "        \"from_node_label\": \"Product\", \n",
    "        \"from_node_column\": \"product_id\", \n",
    "        \"to_node_label\": \"Assembly\", \n",
    "        \"to_node_column\": \"assembly_id\", \n",
    "        \"properties\": [\"quantity\"]\n",
    "    }, \n",
    "    \"Is_Part_Of\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"parts.csv\", \n",
    "        \"relationship_type\": \"Is_Part_Of\", \n",
    "        \"from_node_label\": \"Part\", \n",
    "        \"from_node_column\": \"part_id\", \n",
    "        \"to_node_label\": \"Assembly\", \n",
    "        \"to_node_column\": \"assembly_id\", \n",
    "        \"properties\": [\"quantity\"]\n",
    "    }, \n",
    "    \"Supplied_By\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"part_supplier_mapping.csv\", \n",
    "        \"relationship_type\": \"Supplied_By\", \n",
    "        \"from_node_label\": \"Part\", \n",
    "        \"from_node_column\": \"part_id\", \n",
    "        \"to_node_label\": \"Supplier\", \n",
    "        \"to_node_column\": \"supplier_id\", \n",
    "        \"properties\": [\"supplier_name\", \"lead_time_days\", \"unit_cost\", \"minimum_order_quantity\", \"preferred_supplier\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "construct_domain_graph(approved_construction_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Inspect the Domain Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell filters the construction plan to extract only the relationship construction rules. This list will be used in the next cell to verify that all relationships were successfully created in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 114
   },
   "outputs": [],
   "source": [
    "# extract a list of the relationship construction rules\n",
    "relationship_constructions = [\n",
    "    value for value in approved_construction_plan.values()\n",
    "    if value.get(\"construction_type\") == \"relationship\"\n",
    "]\n",
    "relationship_constructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates and executes a Cypher query to verify that all relationship types from the construction plan were successfully created in the graph. \n",
    "\n",
    "The query uses several advanced Cypher features:\n",
    "- `UNWIND`: Iterates through each relationship construction rule\n",
    "- `CALL (construction) { ... }`: Subquery that executes for each construction rule\n",
    "- `MATCH (from)-[r:relationship_type]->(to)`: Finds one example of each relationship type\n",
    "- `LIMIT 1`: Returns only one example per relationship type\n",
    "\n",
    "This provides a summary view showing one instance of each relationship pattern in the constructed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 558
   },
   "outputs": [],
   "source": [
    "# a fancy cypher query which to show one instance of each construction rule\n",
    "\n",
    "# turn the list of rules into multiple single rules\n",
    "unwind_list = \"UNWIND $relationship_constructions AS construction\"\n",
    "\n",
    "# match a single path for a given construction.relationship_type\n",
    "# return only the labels and types from the 3 parts of the path\n",
    "match_one_path = \"\"\"\n",
    "    MATCH (from)-[r:$(construction.relationship_type)]->(to)\n",
    "    RETURN labels(from) AS fromNode, type(r) AS relationship, labels(to) AS toNode\n",
    "    LIMIT 1\n",
    "\"\"\"\n",
    "match_in_subquery = f\"\"\"\n",
    "CALL (construction) {{\n",
    "{match_one_path}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "cypher = f\"\"\"\n",
    "{unwind_list}\n",
    "{match_in_subquery}\n",
    "RETURN fromNode, relationship, toNode\n",
    "\"\"\"\n",
    "\n",
    "print(cypher)\n",
    "\n",
    "print(\"\\n---\")\n",
    "\n",
    "graphdb.send_query(cypher, {\n",
    "    \"relationship_constructions\": relationship_constructions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
