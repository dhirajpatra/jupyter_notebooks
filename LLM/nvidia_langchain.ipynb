{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62466fff-4f13-4252-8376-8007b1ef63de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you should be able to run the code demo on your laptop with an AMD CPU, 12GB RAM, and a small Radeon GPU. However, the performance might vary depending on the complexity of the code and the specific requirements of the demo.\n",
      "\n",
      "The Radeon GPU, although small, can still assist in certain tasks that are graphically intensive or parallelizable. If the code demo is primarily CPU-bound and doesn't require heavy GPU usage, your laptop should handle it quite well.\n",
      "\n",
      "However, if the code demo is designed to leverage the GPU for acceleration, you might experience slower performance due to the smaller GPU. In such cases, you might want to consider running the demo on a machine with a more powerful GPU.\n",
      "\n",
      "Remember to ensure that your laptop meets the minimum system requirements for the code demo, if any are specified. If the demo is designed for a specific operating system and your laptop runs a different one, you might need to make some adjustments or consider using a virtual machine or dual-boot setup.\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "nvidia_api_key = os.environ.get(\"NVIDIA_API_KEY\")\n",
    "\n",
    "\n",
    "def run_code_demo_check(prompt, nvidia_api_key):\n",
    "    \"\"\"\n",
    "    Checks compatibility for running a code demo on a laptop with the given specifications\n",
    "    using the NVIDIA AI Foundation models.\n",
    "    \n",
    "    Args:\n",
    "      prompt: The user's query about running the code demo.\n",
    "      nvidia_api_key: Your NVIDIA API key for accessing the NVIDIA AI Foundation models.\n",
    "    \n",
    "    Returns:\n",
    "      A string containing the response generated by the large language model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up the NVIDIA Chat model with your API key\n",
    "    llm = ChatNVIDIA(model=\"microsoft/phi-3-mini-128k-instruct\", api_key=nvidia_api_key)\n",
    "\n",
    "    # Provide context for the model\n",
    "    context = \"The user has a laptop with a small Radeon GPU, AMD CPU, and 12GB RAM\"\n",
    "\n",
    "    try:\n",
    "        # Send the prompt with context to the model\n",
    "        response = llm.invoke(f\"{context} {prompt}\")\n",
    "        return response\n",
    "\n",
    "    except langchain.exceptions.LangchainException as e:\n",
    "        print(f\"Error during code demo check: {e}\")\n",
    "        return \"An error occurred while checking compatibility. Please try again later.\"\n",
    "\n",
    "\n",
    "# Example usage with environment variable\n",
    "# nvidia_api_key = \"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\"\n",
    "if not nvidia_api_key:\n",
    "    print(\"Please set the NVIDIA_API_KEY environment variable with your API key.\")\n",
    "    exit()\n",
    "\n",
    "prompt = \"Can I run this code demo from my laptop?\"\n",
    "response = run_code_demo_check(prompt, nvidia_api_key)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00745b9-d2ac-464a-8ee6-b245f065293c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
