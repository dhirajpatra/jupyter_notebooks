{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxztkcajNhl0"
   },
   "source": [
    "[Main research paper](https://arxiv.org/pdf/2210.11416)\n",
    "\n",
    "### Trying to build a small and quick chatbot agent. Which can be used for a small robot brain after quantize the model.\n",
    "\n",
    "Going to use embedding and vector for RAG. We have decided to use mental health dataset so that our bot can help a person espeically aged persons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QP3PzSLYh25",
    "outputId": "52531310-8c61-450e-f10f-8f98506558a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain_text_splitters\n",
      "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.1.1-py3-none-any.whl (8.5 kB)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain_text_splitters)\n",
      "  Downloading langchain_core-0.2.5-py3-none-any.whl (314 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting chromadb<0.6.0,>=0.4.0 (from langchain-chroma)\n",
      "  Downloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi<1,>=0.95.2 (from langchain-chroma)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.1)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.64.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.3.0)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading orjson-3.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting starlette<0.38.0,>=0.37.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Collecting httpx>=0.23.0 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart>=0.0.7 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
      "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain_text_splitters)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.66 (from langchain-core<0.3.0,>=0.2.0->langchain_text_splitters)\n",
      "  Downloading langsmith-0.1.77-py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging>=20.0 (from transformers)\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.1.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.0.1)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma) (3.7.1)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma) (1.3.1)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_text_splitters)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.27.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.20.3)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (7.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.63.1)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
      "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.14.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma) (1.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=3db53cf351cc76ab76d57c16546f5ce3711405c31b6e91e6f1d5fc50a05755cc\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, xxhash, websockets, uvloop, ujson, requests, python-multipart, python-dotenv, packaging, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jsonpointer, humanfriendly, httptools, h11, dnspython, dill, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jsonpatch, httpcore, email_validator, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, nvidia-cusolver-cu12, langsmith, kubernetes, httpx, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langchain-core, fastapi-cli, datasets, sentence_transformers, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain_text_splitters, fastapi, chromadb, langchain-chroma\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.5.0 coloredlogs-15.0.1 datasets-2.19.2 deprecated-1.2.14 dill-0.3.8 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-30.1.0 langchain-chroma-0.1.1 langchain-core-0.2.5 langchain_text_splitters-0.2.1 langsmith-0.1.77 mmh3-4.1.0 monotonic-1.6 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 onnxruntime-1.18.0 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 orjson-3.10.4 overrides-7.7.0 packaging-23.2 posthog-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 python-multipart-0.0.9 requests-2.32.3 sentence_transformers-3.0.1 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0 xxhash-3.4.1\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.2.3-py3-none-any.whl (974 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain_community\n",
      "  Downloading langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
      "Collecting pipeline\n",
      "  Downloading pipeline-0.1.0-py3-none-any.whl (2.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m375.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: pipeline, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-0.2.3 langchain_community-0.2.4 marshmallow-3.21.3 mypy-extensions-1.0.0 pipeline-0.1.0 typing-inspect-0.9.0\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install tqdm transformers spacy datasets langchain_text_splitters langchain-chroma sentence_transformers\n",
    "!pip install langchain langchain_community transformers pipeline\n",
    "# !pip install -U datasets\n",
    "# %pip install llama-index-embeddings-huggingface\n",
    "# %pip install llama-index-embeddings-instructor\n",
    "# !pip install llama-index\n",
    "!pip install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUPaIRu4rSH9",
    "outputId": "56eef9a7-2a7f-4188-f156-5f00d397d2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM, T5ForConditionalGeneration, T5Tokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from google.colab import userdata\n",
    "import urllib.request\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "# from langchain_community.document_loaders import HuggingFaceDatasetLoader\n",
    "import torch\n",
    "# import torch.nn.functional as F\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')  # Mount your Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15ilnZaEr4sz"
   },
   "outputs": [],
   "source": [
    "HUGGING_FACE_API_KEY = userdata.get('HUGGING_FACE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4x6nS17r9lO"
   },
   "outputs": [],
   "source": [
    "model_id = \"google/flan-t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348,
     "referenced_widgets": [
      "40c85ec04d00404b9479e7f75eee91f1",
      "a462d0e0cf294e469a09a34d804ae41f",
      "ecbdce2bd62440afb7ad681bc9ead7e4",
      "4dc73007c56644e4918545e88a72d1ca",
      "76434cf710934ac4b4180c5af75cc096",
      "dcbcdf5d11124036ba80737b1805f336",
      "ffae52ced8d44882aa0714f09f9e1f07",
      "9c3f3ae55196422481250ba2a1472c7e",
      "81d2f8ed48a141b595f51fbb0af62374",
      "a1cd6ff981ed4b3d9fbf0439a75fe940",
      "bd386ef500674936b1f1fd9e107ee9fb",
      "cafa3e730c1042ab8b0e8c6a9e74aa16",
      "4262bc12849a46bc944797c96248af82",
      "fcedb9938252478a93a4a7360b6e3cab",
      "9c492bcd67404acca6e1da6162059d45",
      "55463e5abbc54c23a00f640065a65ea8",
      "b71ca1b81f7740f28cc563471044be5f",
      "6ba1302417b4409aaa673a3d23c809ff",
      "077402c5aab3497eafc548cd2af5261b",
      "17557239383d4bc197fd6e876bfbc9c9",
      "4083c07308ff47b9b206a25e2c9edd7b",
      "b302fb4c09c14c339be06422e7993284",
      "4a1afc3b98be4d3fa9af721d079fed64",
      "2d9dd98563a74c999b5d30091c6f2287",
      "7a6df4dc855e4c0ebf4a69d98dbbb0dd",
      "276be142a7ea4124b7e8f77ca6106940",
      "936bea7d6baf4e6a81bdb70a6f7635a9",
      "84caef96e04a4dd2bd75c8eeff4870b1",
      "fa41e73b3bb94471b5d534ebc574ddd0",
      "6e779f4d0863479f950422e044ad434c",
      "14d7b73be6a5408b8456884b0e205fc9",
      "458d7aa40a5f4efa911b40863ca03483",
      "6289acb47fc9497286ebf35ad59e1f0d",
      "39540246e3b249b196ef72a934a0de07",
      "125c94a72eae4f1586906ddb3f330612",
      "41b1dd09bd2d489e877337557dd3db90",
      "6905891c3e524a7c8df3ba2750dc52ec",
      "2693f4b686924e208d4c863f9ac66216",
      "ac9a4c559c9c4ec2967eb2d673f66925",
      "ed8f97ef912c4c769325d8c3f7b61533",
      "a15c78698e0f4d418b7759e4c6871b47",
      "9ca7a25bf4814d72ad53918f5163bd4b",
      "4931db783028447ab7263a41c46e5865",
      "cca46811a9e64cee85cd6ccbf97d4a89",
      "b818c601a74a4552932da7a71ae65974",
      "b9ffdee310944ffca6af6d563823ea7a",
      "d1d0550e8a4f492792790b6be9941e6a",
      "21e620bea7304ea3be79753d71eaf737",
      "a89656dd30fe43039caa2a933da4bb7a",
      "f04a5311c3714be6ba0fea83568edacc",
      "34dbc5f81dd94768a01cfbca6b4bfbe2",
      "c6bd2be85557474b85bae5c68fa7640a",
      "fbd413e611894157ab1fbefa2c907857",
      "588b00e7f13941399df2b443b26a03a2",
      "d06ab7f6807949658a16d8317e2ddff9",
      "82cd2f28f2354d86b1106730afa82b29",
      "4dc664a1271e4d93952e778ca64fdb40",
      "b12ca3c7610347d5b5535986f460900a",
      "c9957bb15fcc4ecfa52dcc399c9c0fd2",
      "970895aeeefa4fc8a2847525304a8a22",
      "e3d3caa210a04313898928f4cee13146",
      "3db21bd1d5674036a09fcda6275e3e2d",
      "7b82db1484354d389bc3ce810e425d88",
      "d6ad490c518945ed8d2306d23a0c47b2",
      "eafb13952083441fb014c48dbfbda7e0",
      "825750d814174250882ac668607c4f24",
      "3fce0b853b474eb1b848e6e9fa7069bb",
      "d208f847ff6d4b09b71d8644ac8c8a2a",
      "c0ff54d1ac054dcf9e441c52f5134442",
      "3a7ee0f9a6264e379789236a19ba59e5",
      "1d28ff6020fd4c9baae451c8a0c5ef40",
      "92c18672c20c419eb3cabea082912232",
      "abb0096c506f41b79330aa47c85dab08",
      "d4ae4f9065c0484a9e1f5b2e5ae0edc4",
      "399f15b2c0bc4ea1b9abbbf26390222d",
      "baa40bfe137649bbb50291091885e7c4",
      "036ba249d0d347a39da67e32d121b1f3"
     ]
    },
    "id": "hRdL9DLLsTSR",
    "outputId": "75f02858-759b-46f9-f28a-77fa37b2fad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c85ec04d00404b9479e7f75eee91f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafa3e730c1042ab8b0e8c6a9e74aa16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1afc3b98be4d3fa9af721d079fed64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39540246e3b249b196ef72a934a0de07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b818c601a74a4552932da7a71ae65974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cd2f28f2354d86b1106730afa82b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fce0b853b474eb1b848e6e9fa7069bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pour a cup of bolognese into a large bowl and add the pasta']\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the T5 tokenizer (device-agnostic)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_id, legacy=False)\n",
    "\n",
    "# Load the T5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_id)\n",
    "\n",
    "# Move the model to the chosen device (if applicable)\n",
    "model.to(device)\n",
    "\n",
    "# for testing\n",
    "inputs = tokenizer(\"A step by step recipe to make bolognese pasta:\", return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-xcOG_q8miG"
   },
   "outputs": [],
   "source": [
    "# Function to generate responses from the model\n",
    "def generate_response(input_text):\n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\", max_length=1000, truncation=True).input_ids.to(device)\n",
    "\n",
    "    # Generate response\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=500,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=2,\n",
    "        repetition_penalty=2.0,\n",
    "        top_p=0.92,\n",
    "        temperature=0.7,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    # Decode and return the response\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01c6hKtQ89ng"
   },
   "outputs": [],
   "source": [
    "# Generate response based on messages\n",
    "def chat(messages):\n",
    "    conversation = \" \".join([message.content for message in messages if isinstance(message, (HumanMessage, AIMessage))])\n",
    "    response_text = generate_response(conversation)\n",
    "    return AIMessage(content=response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUELsOCqtNY-",
    "outputId": "12394b61-f5a3-4a52-be53-c3c816834338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Thank you.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "]\n",
    "\n",
    "# Simulate the conversation\n",
    "response = chat(messages)\n",
    "print(\"AI:\", response.content)\n",
    "# Add latest AI response to messages\n",
    "messages.append(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0A246UCb9fw3"
   },
   "outputs": [],
   "source": [
    "# Add a new user prompt\n",
    "new_user_prompt = HumanMessage(content=\"Who is the inventor of Artificial Intelligence?\")\n",
    "messages.append(new_user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uRhAH3nl9lRq",
    "outputId": "78210856-1944-4c0a-be60-13f5f0c7e008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: samuel roosevelt\n"
     ]
    }
   ],
   "source": [
    "# Get AI response for the new prompt\n",
    "new_response = chat(messages)\n",
    "print(\"AI:\", new_response.content)\n",
    "\n",
    "# Add the new AI response to messages\n",
    "messages.append(new_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CH9spc7a6H_R",
    "outputId": "4febe122-9df2-43b8-a114-bc7a56599c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samuel roosevelt\n"
     ]
    }
   ],
   "source": [
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"What is the difference between study and knowledge?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to LLM\n",
    "res = chat(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHLAc3Pk9486",
    "outputId": "8f621dca-8e18-4ac8-d406-4b84fe8d62f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samuel roosevelt\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Can you tell me who was invented radio?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to OpenAI\n",
    "res = chat(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPmoKoSg-N3n"
   },
   "outputs": [],
   "source": [
    "science_facts = [\n",
    "    \"The Earth is not a perfect sphere! It bulges slightly at the equator (about 21 kilometers) due to the centrifugal force caused by its rotation. Imagine spinning a pizza dough in the air - the outward force stretches the dough, causing a similar effect on Earth's shape.\",\n",
    "    \"Light travels incredibly fast, at a speed of about 299,792,458 meters per second in a vacuum. This means it takes light only about 8 minutes to travel from the Sun to Earth! However, light speed can slow down slightly when it passes through different materials.\",\n",
    "    \"DNA, or deoxyribonucleic acid, is the blueprint of life! This amazing molecule stores the genetic instructions that determine the traits of all living organisms, from the simplest bacteria to complex humans. Each strand of DNA contains a code made up of four chemical bases, which scientists have nicknamed A, T, C, and G.\",\n",
    "    \"Gravity is an invisible force that keeps us grounded! It's the attraction between any two objects with mass. The greater the mass of an object, the stronger its gravitational pull. This force is what keeps us on Earth, shapes the orbits of planets around the Sun, and even influences the formation of galaxies.\",\n",
    "    \"The periodic table is a scientist's map of the elements! It organizes all known chemical elements based on their atomic number (the number of protons in their nucleus) and their electronic structure. This arrangement reveals fascinating patterns and helps predict the properties of elements, allowing scientists to understand how elements combine to form new materials and molecules.\",\n",
    "]\n",
    "\n",
    "source_knowledge = \"\\n\".join(science_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psmpbU55-UIP"
   },
   "outputs": [],
   "source": [
    "# genearte augmented response from previous document fed into knowledge base\n",
    "def generate_augmented_response(query):\n",
    "  # create a new user prompt\n",
    "  augmented_prompt = f\"\"\"<s>[INST] <<SYS>>Use the following context to answer the user's question. If you don't know the answer, just say that you don't know, don't try to make up an answer. <</SYS>>\"\n",
    " <s>[INST]\n",
    "\n",
    " Context: {source_knowledge}\n",
    " Question: {query}\n",
    "\n",
    " Only return the helpful answer below and nothing else. Helpful answer:[/INST]\"\"\"\n",
    "\n",
    "  # create a new user prompt\n",
    "  prompt = HumanMessage(\n",
    "      content=augmented_prompt\n",
    "  )\n",
    "  # add to messages\n",
    "  messages.append(prompt)\n",
    "\n",
    "  # send to OpenAI\n",
    "  res = chat(messages)\n",
    "\n",
    "  return res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-W3YOKR7-Xbo",
    "outputId": "6cfd2114-11c4-4997-895b-b999912c8292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deoxyribonucleic acid\n"
     ]
    }
   ],
   "source": [
    "query = \"What is DNA?\"\n",
    "res = generate_augmented_response(query)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvkbjmUHIpc9",
    "outputId": "595a5aeb-8e46-458a-c722-19249f6b8e93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an invisible force that keeps us grounded!\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Gravity?\"\n",
    "res = generate_augmented_response(query)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274,
     "referenced_widgets": [
      "cf0362fb1de5408fbc5bde52b31a2d13",
      "484a93536e944c3eb90fa01200916f8a",
      "56d3a33994d2404b9179cd8b4ca137f1",
      "81c40bd32cc44715b210a059a179c704",
      "ba958474fce94ff4846970796454616b",
      "b0a53d7e45364ed0a7df179af69699f4",
      "f849b4b64ba0452b817d76a93286aa6e",
      "37b74b2b531d4d1c98be184065464305",
      "fbdfd53e66ec486692d3e2f9bc1e39cb",
      "fcf78414d9f44f8e938a8d9998297dc4",
      "446fe6d13e2d4d8e94b7ed83f59cc3e7",
      "ba8eee20537b4b1e92b9e1bb28e6046a",
      "4c3c4f6cc9cb491c95e89c322823bc0e",
      "f6a7b0c72ee04187bb4073c9c6bc3e60",
      "b98331d832f048f6b2fa4d56b6b08711",
      "35c0bd81e2b54d07a23b5309095b85bb",
      "2b401e56ec5140c382d81ea29eec5dc1",
      "19604d7fff60478eaedc9698019b200e",
      "8ecb0ea52ca543c88826524068a7b790",
      "d06b1f433cf142cc9f93c1a0a8d01de9",
      "65564927405c4f0794295799dc4a35d3",
      "f04288120303426b8e92af1130d6d03b"
     ]
    },
    "id": "Qejqy9sb-cBu",
    "outputId": "0f379e87-3bbe-4067-e98c-0218596c04af"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0362fb1de5408fbc5bde52b31a2d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/594 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8eee20537b4b1e92b9e1bb28e6046a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/18430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and saved successfully.\n",
      "{'post': [['Science fiction', \"I'm a huge fan of science fiction myself! \", 'I agree. One of my favorite forms of science fiction is anything related to time travel! I find it fascinating.', \"And that's difficult to do when dealing with time travel. I actually haven't seen the latest Harry Potter movies. Guess it's time to check them out!\"]], 'knowledge': [[['no_passages_used __knowledge__ no_passages_used', 'Science fiction __knowledge__ Science fiction (often shortened to SF or sci-fi) is a genre of speculative fiction, typically dealing with imaginative concepts such as futuristic science and technology, space travel, time travel, faster than light travel, parallel universes, and extraterrestrial life.', 'Science fiction __knowledge__ Science fiction often explores the potential consequences of scientific and other innovations, and has been called a \"literature of ideas\".', 'Science fiction __knowledge__ It usually avoids the supernatural, unlike the related genre of fantasy.', 'Science fiction __knowledge__ Historically, science-fiction stories have had a grounding in actual science, but now this is only expected of hard science fiction.', 'Science fiction __knowledge__ Science fiction is difficult to define, as it includes a wide range of subgenres and themes.', 'Science fiction __knowledge__ Hugo Gernsback, who suggested the term \"scientifiction\" for his \"Amazing Stories\" magazine, wrote: \"By \\'scientifiction\\' I mean the Jules Verne, H. G. Wells and Edgar Allan Poe type of story—a charming romance intermingled with scientific fact and prophetic vision... Not only do these amazing tales make tremendously interesting reading—they are always instructive.', 'Science fiction __knowledge__ They supply knowledge... in a very palatable form... New adventures pictured for us in the scientifiction of today are not at all impossible of realization tomorrow...'], ['no_passages_used __knowledge__ no_passages_used', 'Science fiction __knowledge__ Science fiction (often shortened to SF or sci-fi) is a genre of speculative fiction, typically dealing with imaginative concepts such as futuristic science and technology, space travel, time travel, faster than light travel, parallel universes, and extraterrestrial life.', 'Science fiction __knowledge__ Science fiction often explores the potential consequences of scientific and other innovations, and has been called a \"literature of ideas\".', 'Science fiction __knowledge__ It usually avoids the supernatural, unlike the related genre of fantasy.', 'Science fiction __knowledge__ Historically, science-fiction stories have had a grounding in actual science, but now this is only expected of hard science fiction.', 'Science fiction __knowledge__ Science fiction is difficult to define, as it includes a wide range of subgenres and themes.', 'Science fiction __knowledge__ Hugo Gernsback, who suggested the term \"scientifiction\" for his \"Amazing Stories\" magazine, wrote: \"By \\'scientifiction\\' I mean the Jules Verne, H. G. Wells and Edgar Allan Poe type of story—a charming romance intermingled with scientific fact and prophetic vision... Not only do these amazing tales make tremendously interesting reading—they are always instructive.', 'Science fiction __knowledge__ They supply knowledge... in a very palatable form... New adventures pictured for us in the scientifiction of today are not at all impossible of realization tomorrow...', 'History of science fiction __knowledge__ The literary genre of science fiction is diverse, and its exact definition remains a contested question among both scholars and devotees.', \"History of science fiction __knowledge__ This lack of consensus is reflected in debates about the genre's history, particularly over determining its exact origins.\", 'History of science fiction __knowledge__ There are two broad camps of thought, one that identifies the genre\\'s roots in early fantastical works such as the Sumerian \"Epic of Gilgamesh\" (earliest Sumerian text versions c. 2150–2000 BCE).', 'History of science fiction __knowledge__ A second approach argues that science fiction only became possible sometime between the 17th and early 19th centuries, following the scientific revolution and major discoveries in astronomy, physics, and mathematics.', 'Isaac Asimov __knowledge__ Isaac Asimov (; born Isaak Ozimov; January 2, 1920\\xa0– April 6, 1992) was an American writer and professor of biochemistry at Boston University.', 'Isaac Asimov __knowledge__ He was known for his works of science fiction and popular science.', 'Isaac Asimov __knowledge__ Asimov was a prolific writer, and wrote or edited more than 500 books and an estimated 90,000 letters and postcards.', 'Isaac Asimov __knowledge__ His books have been published in 9 of the 10 major categories of the Dewey Decimal Classification.', 'Isaac Asimov __knowledge__ Asimov wrote hard science fiction and, along with Robert A. Heinlein and Arthur C. Clarke, he was considered one of the \"Big Three\" science fiction writers during his lifetime.', 'U.S. television science fiction __knowledge__ U.S. television science fiction is a popular genre of television in the United States that has produced many of the best-known and most popular science fiction shows in the world.', 'U.S. television science fiction __knowledge__ Most famous of all, and one of the most influential science-fiction series in history, is the iconic \"\" and its various spin-off shows, which comprise the Star Trek franchise.', 'U.S. television science fiction __knowledge__ Other hugely influential programs have included the 1960s anthology series \"The Twilight Zone,\" the internationally successful \"The X-Files,\" and a wide variety of television movies and continuing series for more than half a century.', 'U.S. television science fiction __knowledge__ The first popular science-fiction program on American television was the children\\'s adventure serial \"Captain Video and His Video Rangers\", which ran from June 1949 to April 1955.', 'History of US science fiction and fantasy magazines to 1950 __knowledge__ Science fiction and fantasy magazines began to be published in the US in the 1920s.', 'History of US science fiction and fantasy magazines to 1950 __knowledge__ Stories with science fiction themes had been appearing for decades in pulp magazines such as \"Argosy\", but there were no magazines that specialized in a single genre until 1915, when Street & Smith, one of the major pulp publishers, brought out \"Detective Story Magazine\".', 'History of US science fiction and fantasy magazines to 1950 __knowledge__ The first magazine to focus solely on fantasy and horror was \"Weird Tales\", which was launched in 1923, and established itself as the leading weird fiction magazine over the next two decades; writers such as H.P.', 'History of US science fiction and fantasy magazines to 1950 __knowledge__ Lovecraft, Clark Ashton Smith and Robert E. Howard became regular contributors.', 'Starstruck (comics) __knowledge__ Starstruck is an American comic book series.', 'Starstruck (comics) __knowledge__ It was inspired by the off-Broadway stage play with the same name written by Elaine Lee, with contributions from Susan Norfleet Lee and Dale Place.', 'Starstruck (comics) __knowledge__ The \"Starstruck\" creator-owned illustrated science fiction serial has been produced at various intervals since 1982 by writer Lee and artist Michael Wm.', 'Starstruck (comics) __knowledge__ Kaluta; their primary collaborators are colorist Lee Moyer and letterer Todd Klein.', 'Starstruck (comics) __knowledge__ The series, epic in scope, has been carried across multiple comic companies, but primarily by Epic Comics, Dark Horse Comics, and IDW Publishing.', 'Starstruck (comics) __knowledge__ It was collected in a revised and recolored hardcover book form as \"Starstruck Deluxe Edition\" in 2011.', 'LGBT themes in speculative fiction __knowledge__ LGBT themes in speculative fiction refer to the incorporation of lesbian, gay, bisexual, or transgender (LGBT) themes into science fiction, fantasy, horror fiction and related genres.', 'LGBT themes in speculative fiction __knowledge__ Such elements may include an LGBT character as the protagonist or a major character, or explorations of sexuality or gender that deviate from the hetero-normative.', 'LGBT themes in speculative fiction __knowledge__ Science fiction and fantasy have traditionally been puritanical genres aimed at a male readership, and can be more restricted than non-genre literature by their conventions of characterisation and the effect that these conventions have on depictions of sexuality and gender.', 'Hyperspace (science fiction) __knowledge__ Hyperspace is a faster-than-light (FTL) method of traveling used in science fiction.', 'Hyperspace (science fiction) __knowledge__ It is typically described as an alternative \"sub-region\" of space co-existing with our own universe which may be entered using an energy field or other device.', 'Hyperspace (science fiction) __knowledge__ As seen in most fiction hyperspace is most succinctly described as a \"somewhere else\" within which the laws of general and special relativity decidedly do \"not\" apply – especially with respect to the speed of light being the cosmic speed limit.', 'Hyperspace (science fiction) __knowledge__ Entering and exiting said \"elsewhere\" thus directly enables travel near or faster than the speed of light – almost universally with the aid of extremely advanced technology.', 'Science fiction film __knowledge__ Science fiction film (or sci-fi film) is a genre that uses speculative, fictional science-based depictions of phenomena that are not fully accepted by mainstream science, such as extraterrestrial lifeforms, alien worlds, extrasensory perception and time travel, along with futuristic elements such as spacecraft, robots, cyborgs, interstellar travel or other technologies.', 'Science fiction film __knowledge__ Science fiction films have often been used to focus on political or social issues, and to explore philosophical issues like the human condition.', 'Science fiction film __knowledge__ In many cases, tropes derived from written science fiction may be used by filmmakers ignorant of or at best indifferent to the standards of scientific plausibility and plot logic to which written science fiction is traditionally held.', 'Time travel __knowledge__ Time travel is the concept of movement between certain points in time, analogous to movement between different points in space by an object or a person, typically using a hypothetical device known as a time machine, in the form of a vehicle or of a portal connecting distant points in spacetime, either to an earlier time or to a later time, without the need for the time-traveling body to experience the intervening period in the usual sense.', 'Time travel __knowledge__ Time travel is a widely-recognized concept in philosophy and fiction.', 'Time travel __knowledge__ It was popularized by H. G. Wells\\' 1895 novel \"The Time Machine\", which moved the concept of time travel into the public imagination.', 'List of starships in Stargate __knowledge__ This is a list of fictional starships in the \"Stargate\" universe depicted through a series of television shows and three feature-length movies.', 'List of starships in Stargate __knowledge__ The Ancients are one of the most technologically advanced races in \"Stargate\", and this is reflected in their starships.', 'List of starships in Stargate __knowledge__ Duplicates of these ships are utilized by their nanite creations, the Asurans, as they also possess knowledge of Ancient technology.', 'List of starships in Stargate __knowledge__ The Puddle Jumper or Jumper is a small spacecraft used extensively in the \"Stargate Atlantis\" series.', 'List of starships in Stargate __knowledge__ Puddle Jumpers were created by the Ancients and most exist within the city built by the Ancients known as Atlantis.'], ['no_passages_used __knowledge__ no_passages_used', 'Science fiction __knowledge__ Science fiction (often shortened to SF or sci-fi) is a genre of speculative fiction, typically dealing with imaginative concepts such as futuristic science and technology, space travel, time travel, faster than light travel, parallel universes, and extraterrestrial life.', 'Science fiction __knowledge__ Science fiction often explores the potential consequences of scientific and other innovations, and has been called a \"literature of ideas\".', 'Science fiction __knowledge__ It usually avoids the supernatural, unlike the related genre of fantasy.', 'Science fiction __knowledge__ Historically, science-fiction stories have had a grounding in actual science, but now this is only expected of hard science fiction.', 'Science fiction __knowledge__ Science fiction is difficult to define, as it includes a wide range of subgenres and themes.', 'Science fiction __knowledge__ Hugo Gernsback, who suggested the term \"scientifiction\" for his \"Amazing Stories\" magazine, wrote: \"By \\'scientifiction\\' I mean the Jules Verne, H. G. Wells and Edgar Allan Poe type of story—a charming romance intermingled with scientific fact and prophetic vision... Not only do these amazing tales make tremendously interesting reading—they are always instructive.', 'Science fiction __knowledge__ They supply knowledge... in a very palatable form... New adventures pictured for us in the scientifiction of today are not at all impossible of realization tomorrow...', 'Science fiction film __knowledge__ Science fiction film (or sci-fi film) is a genre that uses speculative, fictional science-based depictions of phenomena that are not fully accepted by mainstream science, such as extraterrestrial lifeforms, alien worlds, extrasensory perception and time travel, along with futuristic elements such as spacecraft, robots, cyborgs, interstellar travel or other technologies.', 'Science fiction film __knowledge__ Science fiction films have often been used to focus on political or social issues, and to explore philosophical issues like the human condition.', 'Science fiction film __knowledge__ In many cases, tropes derived from written science fiction may be used by filmmakers ignorant of or at best indifferent to the standards of scientific plausibility and plot logic to which written science fiction is traditionally held.', 'History of science fiction __knowledge__ The literary genre of science fiction is diverse, and its exact definition remains a contested question among both scholars and devotees.', \"History of science fiction __knowledge__ This lack of consensus is reflected in debates about the genre's history, particularly over determining its exact origins.\", 'History of science fiction __knowledge__ There are two broad camps of thought, one that identifies the genre\\'s roots in early fantastical works such as the Sumerian \"Epic of Gilgamesh\" (earliest Sumerian text versions c. 2150–2000 BCE).', 'History of science fiction __knowledge__ A second approach argues that science fiction only became possible sometime between the 17th and early 19th centuries, following the scientific revolution and major discoveries in astronomy, physics, and mathematics.', 'Time travel __knowledge__ Time travel is the concept of movement between certain points in time, analogous to movement between different points in space by an object or a person, typically using a hypothetical device known as a time machine, in the form of a vehicle or of a portal connecting distant points in spacetime, either to an earlier time or to a later time, without the need for the time-traveling body to experience the intervening period in the usual sense.', 'Time travel __knowledge__ Time travel is a widely-recognized concept in philosophy and fiction.', 'Time travel __knowledge__ It was popularized by H. G. Wells\\' 1895 novel \"The Time Machine\", which moved the concept of time travel into the public imagination.', \"Parallel universes in fiction __knowledge__ A parallel universe is a hypothetical self-contained reality co-existing with one's own.\", 'Parallel universes in fiction __knowledge__ A specific group of parallel universes are called a \"multiverse\", although this term can also be used to describe the possible parallel universes that constitute reality.', 'Parallel universes in fiction __knowledge__ While the terms \"parallel universe\" and \"alternative reality\" are generally synonymous and can be used interchangeably in most cases, there is sometimes an additional connotation implied with the term \"alternative reality\" that implies that the reality is a variant of our own.', 'Parallel universes in fiction __knowledge__ The term \"parallel universe\" is more general, without any connotations implying a relationship, or lack of relationship, with our own universe.', 'Alternate history __knowledge__ Alternate history or alternative history (Commonwealth English), sometimes abbreviated as AH, is a genre of fiction consisting of stories in which one or more historical events occur differently.', 'Alternate history __knowledge__ These stories usually contain \"what if\" scenarios at crucial points in history and present outcomes other than those in the historical record.', 'Alternate history __knowledge__ The stories are conjectural, but are sometimes based on fact.', 'Alternate history __knowledge__ Alternate history has been seen as a subgenre of literary fiction, science fiction, or historical fiction; alternate history works may use tropes from any or all of these genres.', 'Alternate history __knowledge__ Another term occasionally used for the genre is \"allohistory\" (literally \"other history\").', 'Time travel in fiction __knowledge__ Time travel is a common theme in fiction and has been depicted in a variety of media, such as literature, television, film, and advertisements.', 'Time travel in fiction __knowledge__ The concept of time travel by mechanical means was popularized in H. G. Wells\\' 1895 story, \"The Time Machine\".', 'Time travel in fiction __knowledge__ In general, time travel stories focus on the consequences of traveling into the past or the future.', 'Time travel in fiction __knowledge__ The central premise for these stories oftentimes involves changing history, either intentionally or by accident, and the ways by which altering the past changes the future and creates an altered present or future for the time traveler when they return home.', 'Oddworld Inhabitants __knowledge__ Oddworld Inhabitants Inc. is an American video game developer founded in 1994 by special-effects and computer-animation veterans Sherry McKenna and Lorne Lanning.', 'Oddworld Inhabitants __knowledge__ The company is primarily known for the incomplete \"Oddworld Quintology\", a series of award-winning video games about the fictional planet of Oddworld and its native creatures.', 'Oddworld Inhabitants __knowledge__ The series debuted with \"\" in 1997 and continued with \"\" in 2001 but the studio has also developed standalone titles \"\" in 1998 and \"\" in 2005.', 'Oddworld Inhabitants __knowledge__ Oddworld Inhabitants took a break from game development for a time following the release of \"Stranger\\'s Wrath\", even though it had already begun preliminary work on its next Oddworld title, \"The Brutal Ballad of Fangus Klot\".', \"Legalism (Chinese philosophy) __knowledge__ Fajia () or Legalism is one of Sima Tan's six classical schools of thought in Chinese philosophy.\", 'Legalism (Chinese philosophy) __knowledge__ Roughly meaning \"house of Fa\" (administrative \"methods\" or \"standards\"), the \"school\" (term) represents some several branches of realistic statesmen or \"men of methods\" (fashu zishi) foundational for the traditional Chinese bureaucratic empire.', 'Legalism (Chinese philosophy) __knowledge__ Compared with Machiavelli, it has often been considered in the Western world as akin to the Realpolitikal thought of ancient China.', 'Legalism (Chinese philosophy) __knowledge__ Largely ignoring morality or questions on how a society ideally should function, they examined contemporary government; emphasizing a realistic consolidation of the wealth and power of autocrat and state, with the goal of achieving increased order, security and stability.', \"Sci-Fi on the Rock __knowledge__ Sci-Fi on the Rock is an annual science fiction, fantasy and horror festival held in St. John's, Newfoundland, Canada.\", 'Sci-Fi on the Rock __knowledge__ It was founded by Darren Hann and Melanie Collins in mid-to-late 2006, and held its first festival in 2007.', \"Sci-Fi on the Rock __knowledge__ It began in 2007 at the Hotel Mount Pearl, moving on to be housed in the Holiday Inn in St. John's as of April 2008.\", 'Sci-Fi on the Rock __knowledge__ The convention made another move in 2016 to the Sheraton Hotel Newfoundland.', 'Sci-Fi on the Rock __knowledge__ The festival has had a number a notable guests both from Newfoundland and beyond, including science-fiction author Kenneth Tam (\"Defense Command\", \"His Majesty\\'s New World\"), comic-book artist Paul Tucker (\"The Underworld Railroad\", \"Google John Smith\"), actor Brian Downey (\"Lexx\", \"Millennium\"), actor Jeremy Bulloch (\"The Empire Strikes Back\", \"Octopussy\"), author William Meikle (\"The Midnight Eye\" series), horror author Matthew LeDrew (\"Black Womb\", \"Roulette\") and author Shannon Patrick Sullivan (\"The Dying Days\").', 'Starstruck (comics) __knowledge__ Starstruck is an American comic book series.', 'Starstruck (comics) __knowledge__ It was inspired by the off-Broadway stage play with the same name written by Elaine Lee, with contributions from Susan Norfleet Lee and Dale Place.', 'Starstruck (comics) __knowledge__ The \"Starstruck\" creator-owned illustrated science fiction serial has been produced at various intervals since 1982 by writer Lee and artist Michael Wm.', 'Starstruck (comics) __knowledge__ Kaluta; their primary collaborators are colorist Lee Moyer and letterer Todd Klein.', 'Starstruck (comics) __knowledge__ The series, epic in scope, has been carried across multiple comic companies, but primarily by Epic Comics, Dark Horse Comics, and IDW Publishing.', 'Starstruck (comics) __knowledge__ It was collected in a revised and recolored hardcover book form as \"Starstruck Deluxe Edition\" in 2011.', 'The Spirit of the Age __knowledge__ The Spirit of the Age (full title \"The Spirit of the Age: Or, Contemporary Portraits\") is a collection of character sketches by the early 19th century English essayist, literary critic, and social commentator William Hazlitt, portraying 25 men, mostly British, whom he believed to represent significant trends in the thought, literature, and politics of his time.', 'The Spirit of the Age __knowledge__ The subjects include thinkers, social reformers, politicians, poets, essayists, and novelists, many of whom Hazlitt was personally acquainted with or had encountered.', 'The Spirit of the Age __knowledge__ Originally appearing in English periodicals, mostly \"The New Monthly Magazine\" in 1824, the essays were collected with several others written for the purpose and published in book form in 1825.', 'Music of the Marvel Cinematic Universe __knowledge__ The music of the Marvel Cinematic Universe (MCU) is the film and television scores composed by various composers for the films and television series of that franchise.', 'Music of the Marvel Cinematic Universe __knowledge__ Ramin Djawadi provided the first MCU music with his original score for \"Iron Man\" in 2008.', 'Music of the Marvel Cinematic Universe __knowledge__ Alan Silvestri was the first composer to work on multiple MCU films after he transitioned from scoring \"\" (2011) to \"Marvel\\'s The Avengers\" (2012), while Brian Tyler was the first composer to reference the work of another MCU composer when he quoted Silvestri\\'s \"Captain America March\" in his score for \"\" (2013).', 'Music of the Marvel Cinematic Universe __knowledge__ Original music has also been composed for the Marvel One-Shots short film series, and other related projects of the MCU, including the fanfares for the two Marvel Studios logos, composed by Tyler and Michael Giacchino, respectively.'], ['no_passages_used __knowledge__ no_passages_used', 'Science fiction __knowledge__ Science fiction (often shortened to SF or sci-fi) is a genre of speculative fiction, typically dealing with imaginative concepts such as futuristic science and technology, space travel, time travel, faster than light travel, parallel universes, and extraterrestrial life.', 'Science fiction __knowledge__ Science fiction often explores the potential consequences of scientific and other innovations, and has been called a \"literature of ideas\".', 'Science fiction __knowledge__ It usually avoids the supernatural, unlike the related genre of fantasy.', 'Science fiction __knowledge__ Historically, science-fiction stories have had a grounding in actual science, but now this is only expected of hard science fiction.', 'Science fiction __knowledge__ Science fiction is difficult to define, as it includes a wide range of subgenres and themes.', 'Science fiction __knowledge__ Hugo Gernsback, who suggested the term \"scientifiction\" for his \"Amazing Stories\" magazine, wrote: \"By \\'scientifiction\\' I mean the Jules Verne, H. G. Wells and Edgar Allan Poe type of story—a charming romance intermingled with scientific fact and prophetic vision... Not only do these amazing tales make tremendously interesting reading—they are always instructive.', 'Science fiction __knowledge__ They supply knowledge... in a very palatable form... New adventures pictured for us in the scientifiction of today are not at all impossible of realization tomorrow...', 'Politics of Harry Potter __knowledge__ There are many published theories about the politics of the Harry Potter books by J. K. Rowling, which range from them containing criticism of racism to anti-government sentiments.', 'Politics of Harry Potter __knowledge__ According to \"Inside Higher Ed\", doctoral theses have been devoted to the Harry Potter books.', 'Politics of Harry Potter __knowledge__ There are also several university courses centred on analysis of the Potter series, including an upper division Political Science course.', 'Politics of Harry Potter __knowledge__ \"Time\" magazine noted the political and social aspects of Harry Potter in their 2007 Person of the Year issue where Rowling placed third behind politicians Vladimir Putin and Al Gore.', 'Politics of Harry Potter __knowledge__ Harry Potter\\'s potential social and political impact was called similar to the 19th century phenomenon of Harriet Beecher Stowe\\'s popular, but critically maligned book, \"Uncle Tom\\'s Cabin\", which fuelled the abolitionist movement leading up to the American Civil War.', 'Religious debates over the Harry Potter series __knowledge__ Religious debates over the \"Harry Potter\" series of books by J. K. Rowling are based on claims that the novels contain occult or Satanic subtexts.', 'Religious debates over the Harry Potter series __knowledge__ A number of Protestant, Catholic, and Orthodox Christians have argued against the series, as have some Shia and Sunni Muslims.', 'Religious debates over the Harry Potter series __knowledge__ Supporters of the series have said that the magic in \"Harry Potter\" bears little resemblance to occultism, being more in the vein of fairy tales such as \"Cinderella\" and \"Snow White\", or to the works of C. S. Lewis and J. R. R. Tolkien, both of whom are known for writing fantasy novels with Christian subtexts.', 'Religious debates over the Harry Potter series __knowledge__ Far from promoting a particular religion, some argue, the \"Harry Potter\" novels go out of their way to avoid discussing religion at all.', 'Magical objects in Harry Potter __knowledge__ The following is a list of magical objects used in the \"Harry Potter\" series.', 'Magical objects in Harry Potter __knowledge__ In \"Harry Potter and the Order of the Phoenix\", Hermione Granger creates fake, enchanted Galleons that are used for communication between members of Dumbledore\\'s Army.', \"Magical objects in Harry Potter __knowledge__ Like real Galleons, the coins have numerals around the edge; on normal Galleons these serial numbers aren't used the same way the enchanted coins are used, the numbers represent the time and date of the next meeting, and automatically change to match whatever numbers Harry Potter sets on his coin.\", 'Magical objects in Harry Potter __knowledge__ Due to the coins being infused with a Protean Charm, once Harry Potter alters his, every coin changes to suit.', 'Harry Potter __knowledge__ Harry Potter is a series of fantasy novels written by British author J. K. Rowling.', 'Harry Potter __knowledge__ The novels chronicle the life of a young wizard, Harry Potter, and his friends Hermione Granger and Ron Weasley, all of whom are students at Hogwarts School of Witchcraft and Wizardry.', \"Harry Potter __knowledge__ The main story arc concerns Harry's struggle against Lord Voldemort, a dark wizard who intends to become immortal, overthrow the wizard governing body known as the Ministry of Magic, and subjugate all wizards and muggles, a reference term that means non-magical people.\", 'Harry Potter __knowledge__ Since the release of the first novel, \"Harry Potter and the Philosopher\\'s Stone\", on 26 June 1997, the books have found immense popularity, critical acclaim, and commercial success worldwide.', 'Harry Potter fandom __knowledge__ \"\"Harry Potter\" fandom\" refers to the community of fans of the \"Harry Potter\" books and movies who participate in entertainment activities that revolve around the series, such as reading and writing fan fiction, creating and soliciting fan art, engaging in role-playing games, socializing on \"Harry Potter\"-based forums, and more.', 'Harry Potter fandom __knowledge__ The fandom interacts online as well as offline through activities such as fan conventions, tours of iconic landmarks relevant to the books and production of the films, and parties held for the midnight release of each book and film.', 'Harry Potter fandom __knowledge__ By the fourth \"Harry Potter\" book, the legions of fans had grown so large that considerable security measures were taken to ensure that no book was purchased before the official release date.', 'List of supporting Harry Potter characters __knowledge__ The following are supporting characters in the \"Harry Potter\" series written by J. K. Rowling.', \"List of supporting Harry Potter characters __knowledge__ For members of the Order of the Phoenix, Dumbledore's Army, Hogwarts staff, Ministry of Magic, or for Death Eaters, see the respective articles.\", \"List of supporting Harry Potter characters __knowledge__ The Dursley family are Harry Potter's last living relatives.\", \"List of supporting Harry Potter characters __knowledge__ To ensure Harry's safety, Albus Dumbledore placed him in the Dursleys' care when he was a baby.\", 'List of supporting Harry Potter characters __knowledge__ The Dursleys live at Number 4, Privet Drive, Little Whinging in Surrey, England.', 'List of supporting Harry Potter characters __knowledge__ They are all Muggles, and despise all things related to magic – and anything out of the ordinary in general – and the Wizarding World, especially the Potters.', 'Legal disputes over the Harry Potter series __knowledge__ Since first coming to wide notice in the late 1990s, the \"Harry Potter\" book series by J. K. Rowling has engendered a number of legal disputes.', 'Legal disputes over the Harry Potter series __knowledge__ Rowling, her various publishers and Time Warner, the owner of the rights to the \"Harry Potter\" films, have taken numerous legal actions to protect their copyrights, and also have fielded accusations of copyright theft themselves.', 'Legal disputes over the Harry Potter series __knowledge__ The worldwide popularity of the \"Harry Potter\" series has led to the appearance of a number of locally produced, unauthorised sequels and other derivative works, sparking efforts to ban or contain them.', 'Legal disputes over the Harry Potter series __knowledge__ While these legal proceedings have countered a number of cases of outright piracy, other attempts have targeted not-for-profit endeavours and have been criticised.', 'Order of the Phoenix (fictional organisation) __knowledge__ The Order of the Phoenix is a secret organisation in the \"Harry Potter\" series of fiction books written by J. K. Rowling.', 'Order of the Phoenix (fictional organisation) __knowledge__ Founded by Albus Dumbledore to fight Lord Voldemort and his followers, the Death Eaters, the Order lends its name to the fifth book of the series, \"Harry Potter and the Order of the Phoenix\".', 'Order of the Phoenix (fictional organisation) __knowledge__ Before the Harry Potter series starts – when the character Lord Voldemort declared war on the wizarding world – Albus Dumbledore, headmaster of Hogwarts School of Witchcraft and Wizardry and an upstanding and powerful citizen of the wizarding world, attempted to take control of the situation by founding the Order of the Phoenix.', 'Places in Harry Potter __knowledge__ J. K. Rowling\\'s \"Harry Potter\" universe contains numerous settings for the events in her fantasy novels.', 'Places in Harry Potter __knowledge__ These locations are categorised as a dwelling, school, shopping district, or government-affiliated locale.', \"Places in Harry Potter __knowledge__ The Weasleys' home, known as the Burrow, is located outside the village of Ottery St Catchpole, also near the home of the Lovegoods, the Diggorys and the Fawcetts.\", 'Places in Harry Potter __knowledge__ The Burrow was used as the Order of the Phoenix\\'s headquarters, due to the compromised Fidelius Charm placed on 12 Grimmauld Place, in \"Harry Potter and the Deathly Hallows\" until it lost its given protection.', 'Places in Harry Potter __knowledge__ The Weasley house has seven floors.', 'Ministry of Magic __knowledge__ The Ministry of Magic is the government of the Magical community of Britain in \"J. K. Rowling\\'s Wizarding World\" .The magical government in Britain is  first mentioned in \"Harry Potter and the Philosopher\\'s Stone,\" the Ministry makes its first proper appearance in \"Harry Potter and the Order of the Phoenix\".', 'Ministry of Magic __knowledge__ Throughout the books, it is generally depicted as either corrupt, incompetent, or both, with its high officials blind to actual events and dangers.', 'Ministry of Magic __knowledge__ It reaches a zenith of corruption before being effectively taken over by Lord Voldemort.', \"Ministry of Magic __knowledge__ At the end of the final book, following Voldemort's death, Kingsley Shacklebolt takes over the ministry, changing it for the better.\", 'Harry Potter (film series) __knowledge__ Harry Potter is a British-American film series based on the \"Harry Potter\" novels by author J. K. Rowling.', 'Harry Potter (film series) __knowledge__ The series is distributed by Warner Bros. and consists of eight fantasy films, beginning with \"Harry Potter and the Philosopher\\'s Stone\" (2001) and culminating with \"Harry Potter and the Deathly Hallows – Part 2\" (2011).', 'Harry Potter (film series) __knowledge__ A spin-off prequel series will consist of five films, starting with \"Fantastic Beasts and Where to Find Them\" (2016).', 'Harry Potter (film series) __knowledge__ The \"Fantastic Beasts\" films mark the beginning of a shared media franchise known as J. K. Rowling\\'s Wizarding World.', 'Harry Potter (film series) __knowledge__ The series was mainly produced by David Heyman, and stars Daniel Radcliffe, Rupert Grint, and Emma Watson as the three leading characters: Harry Potter, Ron Weasley, and Hermione Granger.']]], 'labels': [[1, 39, 30, 2]], 'response': [[\"I think science fiction is an amazing genre for anything. Future science, technology, time travel, FTL travel, they're all such interesting concepts.\", 'Awesome! I really love how sci-fi storytellers focus on political/social/philosophical issues that would still be around even in the future. Makes them relatable.', \"It's not quite sci-fi, but my favorite version of time travel is in Harry Potter and the Prisoner of Azkaban. Breaks zero logical rules.\", 'If you really want a look at the potential negative consequences of scientific innovation, what you should check out is the TV show Fringe. Incredibly well written.']], 'topics': [['Science fiction', 'Science fiction', 'Science fiction', 'Science fiction']]}\n",
      "['post', 'knowledge', 'labels', 'response', 'topics']\n",
      "(18430, 5)\n",
      "DatasetInfo(description='', citation='', homepage='', license='', features={'post': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'knowledge': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'response': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'topics': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='json', dataset_name='wizard_of_wikipedia', config_name='default', version=0.0.0, splits={'train': SplitInfo(name='train', num_bytes=825662616, num_examples=18430, shard_lengths=None, dataset_name='wizard_of_wikipedia'), 'validation': SplitInfo(name='validation', num_bytes=88550737, num_examples=1948, shard_lengths=None, dataset_name='wizard_of_wikipedia'), 'test': SplitInfo(name='test', num_bytes=86383499, num_examples=1933, shard_lengths=None, dataset_name='wizard_of_wikipedia')}, download_checksums={'hf://datasets/chujiezheng/wizard_of_wikipedia@484e8ea36929e800e26e8f21f78c050500648c19/train_collected.json': {'num_bytes': 869379986, 'checksum': None}, 'hf://datasets/chujiezheng/wizard_of_wikipedia@484e8ea36929e800e26e8f21f78c050500648c19/valid_collected.json': {'num_bytes': 46589038, 'checksum': None}, 'hf://datasets/chujiezheng/wizard_of_wikipedia@484e8ea36929e800e26e8f21f78c050500648c19/valid_unseen_collected.json': {'num_bytes': 46640931, 'checksum': None}, 'hf://datasets/chujiezheng/wizard_of_wikipedia@484e8ea36929e800e26e8f21f78c050500648c19/test_collected.json': {'num_bytes': 44904609, 'checksum': None}, 'hf://datasets/chujiezheng/wizard_of_wikipedia@484e8ea36929e800e26e8f21f78c050500648c19/test_unseen_collected.json': {'num_bytes': 46055843, 'checksum': None}}, download_size=1053570407, post_processing_size=None, dataset_size=1000596852, size_in_bytes=2054167259)\n",
      "post: list\n",
      "knowledge: list\n",
      "labels: list\n",
      "response: list\n",
      "topics: list\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import os, glob\n",
    "\n",
    "# Local dataset path where the dataset will be saved\n",
    "local_dataset_path = \"/content/drive/My Drive/my_project/wizard_of_wikipedia_dataset/\"\n",
    "\n",
    "# Check if the directory exists, create it if not\n",
    "if not os.path.exists(local_dataset_path):\n",
    "  os.makedirs(local_dataset_path)  # Create all necessary subdirectories\n",
    "\n",
    "\n",
    "def download_and_save_dataset():\n",
    "    try:\n",
    "        # Download the dataset if not found locally\n",
    "        dataset = load_dataset(\"chujiezheng/wizard_of_wikipedia\", split=\"train\", cache_dir=local_dataset_path)\n",
    "        # Save the downloaded dataset for future use\n",
    "        dataset.save_to_disk(local_dataset_path)\n",
    "        print(\"Dataset downloaded and saved successfully.\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download and save the dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_dataset_downloaded(dataset_path):\n",
    "  \"\"\"Checks if the dataset is downloaded by verifying expected files.\"\"\"\n",
    "  required_files = [\"dataset_info.json\"]  # List of essential files\n",
    "\n",
    "  # Check for presence of split folders (common structure)\n",
    "  if not os.path.isdir(os.path.join(dataset_path, \"train\")):  # Check for train split\n",
    "    return False\n",
    "\n",
    "  # Check for presence of required files within the train split folder\n",
    "  for filename in required_files:\n",
    "    filepath = os.path.join(dataset_path, \"train\", filename)\n",
    "    if not os.path.exists(filepath):\n",
    "      return False\n",
    "\n",
    "  # Optionally check for additional files (e.g., *.arrow files)\n",
    "  arrow_pattern = os.path.join(dataset_path, \"train\", \"*.arrow\")\n",
    "  if not any(os.path.isfile(f) for f in glob.glob(arrow_pattern)):  # Check for any *.arrow files\n",
    "    print(\"Warning: No Arrow files found. Dataset might be incomplete.\")\n",
    "\n",
    "  return True\n",
    "\n",
    "\n",
    "def load_local_dataset():\n",
    "  try:\n",
    "    # Load the dataset from the local cache\n",
    "    dataset = load_from_disk(local_dataset_path)\n",
    "    print(\"Dataset loaded successfully from disk.\")\n",
    "    return dataset\n",
    "  except Exception as e:\n",
    "    print(f\"Failed to load dataset from disk: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(local_dataset_path):\n",
    "  os.makedirs(local_dataset_path, exist_ok=True)\n",
    "\n",
    "# Check if the dataset is downloaded within the folder\n",
    "if not is_dataset_downloaded(local_dataset_path):\n",
    "  dataset = download_and_save_dataset()\n",
    "else:\n",
    "  dataset = load_local_dataset()\n",
    "\n",
    "# Print the first example if dataset is loaded\n",
    "if dataset:\n",
    "  print(dataset[:1])\n",
    "  print(dataset.column_names)\n",
    "  print(dataset.shape)\n",
    "  print(dataset.info)\n",
    "\n",
    "  # Assuming 'dataset' is your Hugging Face Dataset\n",
    "  dataset_features = dataset.features\n",
    "\n",
    "  # Print feature types for each column\n",
    "  for feature_name, feature in dataset_features.items():\n",
    "      print(f\"{feature_name}: {feature.dtype}\")\n",
    "\n",
    "else:\n",
    "  print(\"Dataset could not be loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UviYF91NBYTb"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import chromadb\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from langchain_community.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Define the desired folder path within your Drive (replace 'my_project/chromadb' with your path)\n",
    "persist_directory = \"/content/drive/My Drive/my_project/chromadb/\"\n",
    "\n",
    "# Check if the directory exists, create it if not\n",
    "if not os.path.exists(persist_directory):\n",
    "  os.makedirs(persist_directory)  # Create all necessary subdirectories\n",
    "\n",
    "# Create the client with the persist directory\n",
    "client = chromadb.PersistentClient(path=persist_directory)\n",
    "\n",
    "# Define collection name\n",
    "collection_name = \"chatbot_knowledgebase\"\n",
    "\n",
    "# Specify columns to embed\n",
    "# columns_to_embed = ['post', 'response', 'topics']\n",
    "columns_to_embed = ['post', 'response']\n",
    "\n",
    "collection_config = {\n",
    "    \"name\": collection_name,\n",
    "    \"metadata\": {\"hnsw:space\": \"cosine\"}\n",
    "}\n",
    "\n",
    "# switch `create_collection` to `get_or_create_collection` to avoid creating a new collection every time\n",
    "collection = client.get_or_create_collection(**collection_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaliBXD1-VS2",
    "outputId": "6b448664-ffff-427c-d6a3-205c2f9978c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Processing batches : 200batch [09:38,  2.27s/batch]WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id0_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id0_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id1_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id1_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id2_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id2_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id3_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id3_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id4_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id4_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id5_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id5_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id6_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id6_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id7_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id7_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id8_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id8_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id9_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id9_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id10_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id10_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id11_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id11_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id12_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id12_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id13_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id13_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id14_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id14_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id15_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id15_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id16_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id16_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id17_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id17_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id18_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id18_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id19_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id19_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id20_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id20_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id21_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id21_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id22_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id22_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id23_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id23_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id24_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id24_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id25_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id25_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id26_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id26_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id27_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id27_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id28_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id28_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id29_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id29_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id30_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id30_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id31_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id31_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id32_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id32_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id33_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id33_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id34_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id34_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id35_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id35_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id36_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id36_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id37_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id37_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id38_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id38_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id39_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id39_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id40_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id40_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id41_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id41_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id42_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id42_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id43_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id43_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id44_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id44_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id45_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id45_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id46_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id46_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id47_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id47_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id48_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id48_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id49_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id49_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id50_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id50_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id51_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id51_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id52_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id52_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id53_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id53_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id54_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id54_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id55_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id55_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id56_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id56_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id57_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id57_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id58_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id58_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id59_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id59_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id60_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id60_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id61_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id61_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id62_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id62_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id63_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id63_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id64_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id64_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id65_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id65_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id66_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id66_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id67_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id67_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id68_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id68_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id69_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id69_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id70_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id70_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id71_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id71_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id72_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id72_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id73_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id73_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id74_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id74_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id75_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id75_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id76_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id76_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id77_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id77_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id78_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id78_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id79_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id79_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id80_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id80_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id81_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id81_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id82_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id82_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id83_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id83_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id84_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id84_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id85_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id85_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id86_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id86_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id87_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id87_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id88_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id88_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id89_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id89_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id90_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id90_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id91_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id91_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id92_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id92_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id93_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id93_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id94_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id94_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id95_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id95_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id96_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id96_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id97_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id97_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id98_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id98_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: post_id99_chunk0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: response_id99_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id0_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id0_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id1_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id1_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id2_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id2_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id3_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id3_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id4_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id4_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id5_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id5_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id6_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id6_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id7_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id7_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id8_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id8_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id9_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id9_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id10_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id10_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id11_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id11_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id12_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id12_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id13_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id13_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id14_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id14_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id15_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id15_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id16_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id16_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id17_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id17_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id18_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id18_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id19_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id19_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id20_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id20_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id21_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id21_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id22_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id22_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id23_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id23_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id24_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id24_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id25_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id25_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id26_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id26_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id27_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id27_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id28_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id28_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id29_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id29_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id30_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id30_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id31_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id31_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id32_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id32_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id33_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id33_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id34_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id34_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id35_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id35_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id36_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id36_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id37_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id37_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id38_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id38_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id39_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id39_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id40_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id40_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id41_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id41_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id42_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id42_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id43_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id43_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id44_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id44_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id45_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id45_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id46_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id46_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id47_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id47_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id48_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id48_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id49_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id49_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id50_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id50_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id51_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id51_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id52_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id52_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id53_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id53_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id54_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id54_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id55_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id55_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id56_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id56_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id57_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id57_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id58_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id58_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id59_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id59_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id60_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id60_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id61_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id61_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id62_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id62_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id63_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id63_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id64_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id64_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id65_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id65_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id66_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id66_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id67_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id67_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id68_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id68_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id69_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id69_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id70_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id70_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id71_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id71_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id72_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id72_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id73_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id73_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id74_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id74_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id75_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id75_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id76_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id76_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id77_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id77_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id78_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id78_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id79_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id79_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id80_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id80_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id81_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id81_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id82_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id82_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id83_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id83_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id84_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id84_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id85_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id85_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id86_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id86_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id87_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id87_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id88_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id88_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id89_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id89_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id90_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id90_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id91_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id91_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id92_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id92_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id93_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id93_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id94_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id94_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id95_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id95_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id96_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id96_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id97_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id97_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id98_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id98_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: post_id99_chunk0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: response_id99_chunk0\n",
      "ERROR:__main__:An error occurred: 'Collection' object has no attribute 'persist'\n",
      "Processing batches : 200batch [09:52,  2.96s/batch]\n",
      "Processing batches : 200batch [10:04,  3.93s/batch]ERROR:__main__:An error occurred: 'Collection' object has no attribute 'persist'\n",
      "Processing batches : 200batch [10:18,  3.09s/batch]\n",
      "Processing batches : 200batch [09:43,  3.30s/batch]ERROR:__main__:An error occurred: 'Collection' object has no attribute 'persist'\n",
      "Processing batches : 200batch [09:55,  2.98s/batch]\n",
      "Processing batches : 200batch [10:01,  2.61s/batch]ERROR:__main__:An error occurred: 'Collection' object has no attribute 'persist'\n",
      "Processing batches : 200batch [10:15,  3.08s/batch]\n",
      "Processing batches : 200batch [09:32,  3.47s/batch]ERROR:__main__:An error occurred: 'Collection' object has no attribute 'persist'\n",
      "Processing batches : 200batch [09:44,  2.92s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed. Checking subsequent code execution...\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging (optional)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Save the model\n",
    "model_save_path = \"/content/drive/My Drive/my_project/sentence_transformer_model/\"\n",
    "embedding_model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Check if the model is already saved in the specified path\n",
    "if os.path.exists(model_save_path):\n",
    "    # If the model exists, load it directly\n",
    "    sentence_model = SentenceTransformer(model_save_path)\n",
    "else:\n",
    "    # If the model does not exist, download it and save it to the specified path\n",
    "    sentence_model = SentenceTransformer(embedding_model_id, trust_remote_code=True)\n",
    "    sentence_model.save(model_save_path)\n",
    "\n",
    "response_tokenizer = T5Tokenizer.from_pretrained(model_id)\n",
    "response_model = T5ForConditionalGeneration.from_pretrained(model_id)\n",
    "response_model.to(device)\n",
    "\n",
    "# Assuming `dataset` is already initialized and loaded\n",
    "dataset_to_execute = dataset.select(range(500)) # total dataset rows 18430\n",
    "batch_size = 100\n",
    "\n",
    "class GenerateEmbeddings:\n",
    "    def __init__(self, model, batch_size, pca):\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.pca = pca\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        \"\"\"Preprocess text by lowercasing and removing punctuation.\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'__knowledge__', ' ', text)  # Remove custom dividers\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "        return ''.join([c for c in text if c not in string.punctuation])\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        \"\"\"Embed a list of texts using the provided model.\"\"\"\n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(texts), self.batch_size):\n",
    "                batch_texts = texts[i:i + self.batch_size]\n",
    "                batch_embeddings = self.model.encode([self.preprocess(text) for text in batch_texts], show_progress_bar=False)\n",
    "\n",
    "                # Apply PCA to reduce the dimensionality to 384 if pca is provided\n",
    "                if self.pca is not None:\n",
    "                    reduced_embeddings = self.pca.transform(batch_embeddings)\n",
    "                    batch_embeddings = [embedding.tolist() for embedding in reduced_embeddings]\n",
    "\n",
    "                embeddings.extend(batch_embeddings)  # Convert ndarray to list and extend\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        return self.embed_documents([self.preprocess(query)])[0]\n",
    "\n",
    "def generate_response(input_text):\n",
    "    \"\"\"Generate a response from the model.\"\"\"\n",
    "    input_ids = response_tokenizer(input_text, return_tensors=\"pt\", max_length=1000, truncation=True).input_ids.to(device)\n",
    "\n",
    "    outputs = response_model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=500,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=2,\n",
    "        repetition_penalty=2.0,\n",
    "        top_p=0.92,\n",
    "        temperature=0.7,\n",
    "        eos_token_id=response_tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    return response_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def flatten_data(data):\n",
    "    \"\"\"Flatten nested lists of strings into a single string concatenation.\"\"\"\n",
    "    return ' '.join(str(item) for item in data)\n",
    "\n",
    "def split_text_into_chunks(text, max_length=512):\n",
    "    tokens = text.split()\n",
    "    return [' '.join(tokens[i:i + max_length]) for i in range(0, len(tokens), max_length)]\n",
    "\n",
    "def process_document(doc_id, text, embedding_function):\n",
    "    \"\"\"Process and embed a single document.\"\"\"\n",
    "    try:\n",
    "        preprocessed_text = embedding_function.preprocess(text)\n",
    "        chunks = split_text_into_chunks(preprocessed_text)\n",
    "        chunk_embeddings = embedding_function.embed_documents(chunks)\n",
    "        responses = [generate_response(chunk) for chunk in chunks]\n",
    "        return doc_id, chunk_embeddings, chunks, responses\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while processing document {doc_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize PCA with the target number of components\n",
    "pca = PCA(n_components=384)\n",
    "\n",
    "# Fit PCA on some initial data (assuming you have some pre-saved embeddings or initial data to fit)\n",
    "# Here is an example of how to fit the PCA initially\n",
    "initial_data = sentence_model.encode(science_facts * 1000)  # Generate some sample data\n",
    "pca.fit(initial_data)\n",
    "\n",
    "# Create an embedding function instance\n",
    "embedding_function = GenerateEmbeddings(sentence_model, batch_size, pca)\n",
    "\n",
    "# Function to process and save batches\n",
    "def process_and_save_batches(batch_start, batch_end, processed_data_path, embedding_function):\n",
    "    processed_documents = {}\n",
    "    document_ids = []\n",
    "    all_responses = {}\n",
    "    progress_bar = tqdm(total=batch_end - batch_start, desc=\"Processing batches \", unit=\"batch\")\n",
    "\n",
    "    try:\n",
    "        for idx in range(batch_start, batch_end):\n",
    "            for column in columns_to_embed:\n",
    "                if column not in dataset_to_execute.column_names:\n",
    "                    logger.warning(f\"Column '{column}' not found in dataset, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                flat_text = flatten_data(dataset_to_execute[column][idx])\n",
    "                doc_id = f\"{column}_id{idx}\"\n",
    "                result = process_document(doc_id, flat_text, embedding_function)\n",
    "                if result:\n",
    "                    doc_id, chunk_embeddings, chunks, response_list = result\n",
    "                    document_ids.extend([f\"{doc_id}_chunk{i}\" for i in range(len(chunks))])\n",
    "                    processed_documents.update({f\"{doc_id}_chunk{i}\": chunk for i, chunk in enumerate(chunks)})\n",
    "                    all_responses.update({f\"{doc_id}_chunk{i}\": response_list[i] for i in range(len(response_list))})\n",
    "                    progress_bar.update(1)\n",
    "\n",
    "\n",
    "        # Embed the documents using the embedding function\n",
    "        embeddings = embedding_function.embed_documents(list(processed_documents.values()))\n",
    "\n",
    "        # Add data to ChromaDB with embeddings, responses, and IDs\n",
    "        collection.add(\n",
    "            embeddings=embeddings,\n",
    "            documents=list(processed_documents.values()),\n",
    "            metadatas=[{\"response\": all_responses[doc_id]} for doc_id in document_ids],\n",
    "            ids=document_ids\n",
    "        )\n",
    "\n",
    "        # Persist any remaining changes to ChromaDB\n",
    "        collection.persist()\n",
    "\n",
    "        # Print the collection object to verify\n",
    "\n",
    "        # print(collection)\n",
    "\n",
    "        # Save the processed documents, document IDs, and responses to disk\n",
    "        with open(processed_data_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'processed_documents': processed_documents,\n",
    "                'document_ids': document_ids,\n",
    "                'all_responses': all_responses\n",
    "            }, f)\n",
    "\n",
    "        print(f\"Processed data saved to {processed_data_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "\n",
    "    finally:\n",
    "        progress_bar.close()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# Process dataset in batches\n",
    "for start in range(0, len(dataset_to_execute), batch_size):\n",
    "    end = min(start + batch_size, len(dataset_to_execute))\n",
    "    processed_data_path = f\"/content/drive/My Drive/my_project/processed_data_batch_{start}_{end}.pkl\"\n",
    "    process_and_save_batches(start, end, processed_data_path, embedding_function)\n",
    "\n",
    "# Print statements to debug the subsequent code\n",
    "print(\"Processing completed. Checking subsequent code execution...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2rKoyY6ViXV",
    "outputId": "037a2cc8-ed8a-4f35-f690-405d194c2632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the existing collection\n",
    "collection = client.get_collection(collection_name)\n",
    "\n",
    "# Verify the loaded collection\n",
    "print(\"Collection loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O44XY_mp11Kh"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Path to load the processed data\n",
    "# processed_data_path = \"/content/drive/My Drive/my_project/processed_data.pkl\"\n",
    "\n",
    "# # Load the processed documents, document IDs, and responses from disk\n",
    "# with open(processed_data_path, 'rb') as f:\n",
    "#     saved_data = pickle.load(f)\n",
    "\n",
    "# processed_documents = saved_data['processed_documents']\n",
    "# document_ids = saved_data['document_ids']\n",
    "# all_responses = saved_data['all_responses']\n",
    "\n",
    "# print(\"Processed data loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRbg4Qd2C71s"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "def generate_augmented_response(\n",
    "    query: str,\n",
    "    embedding_function=embedding_function,\n",
    "    collection=collection,\n",
    "    model=sentence_model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    "):\n",
    "    \"\"\"\n",
    "    This function generates a response using the T5 model and retrieves\n",
    "    relevant knowledge from the provided collection.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query string.\n",
    "        embedding_function: The function used to embed the query.\n",
    "        collection: The ChromaDB collection object containing the knowledge base.\n",
    "        model: The T5 model used for generating responses.\n",
    "        tokenizer: The tokenizer used with the T5 model.\n",
    "        device: The device (CPU or GPU) on which the model is running.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Embed the query using the provided embedding function\n",
    "        query_embedding = embedding_function.embed_query(query)\n",
    "\n",
    "        # Ensure query_embedding is a list\n",
    "        query_embedding = query_embedding.tolist()\n",
    "\n",
    "        # Perform similarity search in ChromaDB using the query embedding\n",
    "        results = collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=3  # Retrieve top 3 most similar documents\n",
    "        )\n",
    "\n",
    "        if not results or not results['documents']:\n",
    "            logging.warning(\"No results returned from ChromaDB similarity search\")\n",
    "            # Fallback mechanism - generate response without knowledge augmentation\n",
    "            inputs = tokenizer(query, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "            response = model.generate(input_ids=inputs.input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "            return tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "\n",
    "        # Extract relevant knowledge from the retrieved documents (top 3)\n",
    "        source_knowledge = \"\\n\".join([\n",
    "            \" \".join(doc) if isinstance(doc, list) else doc for doc in results['documents']\n",
    "        ])\n",
    "\n",
    "        # Feed the query and retrieved knowledge into an augmented prompt\n",
    "        augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "Contexts:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\"\n",
    "\n",
    "        # Generate response using the model and the augmented prompt\n",
    "        with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "            inputs = tokenizer(augmented_prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "            response = model.generate(input_ids=inputs.input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "\n",
    "            # Decode the generated token IDs\n",
    "            response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "\n",
    "            return response_text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in generate_augmented_response: {e}\")\n",
    "        return \"Error during response generation.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMzF8JSCNtZU"
   },
   "outputs": [],
   "source": [
    "# Generate response based on messages\n",
    "def chat(messages):\n",
    "    conversation = \" \".join([message.content for message in messages if isinstance(message, (HumanMessage, AIMessage))])\n",
    "    response_text = generate_augmented_response(query=conversation)\n",
    "    return HumanMessage(content=response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d-0lZJpMSti"
   },
   "outputs": [],
   "source": [
    "def chat(messages, embedding_function=embedding_function, collection=collection, model=response_model, tokenizer=tokenizer, device=device):\n",
    "    conversation = \" \".join([message.content for message in messages if isinstance(message, (HumanMessage, AIMessage))])\n",
    "\n",
    "    # Generate embeddings for the conversation\n",
    "    query_embedding = embedding_function.embed_query(conversation)\n",
    "\n",
    "    # Convert embeddings to strings if needed (assuming embeddings are numeric)\n",
    "    query_embedding = [str(embed) for embed in query_embedding]\n",
    "\n",
    "    # Example: Query ChromaDB for relevant documents based on metadata (e.g., document IDs or tags)\n",
    "    relevant_documents = collection.query(query_texts=query_embedding, n_results=3)  # Adjust num_results as needed\n",
    "\n",
    "    # Extract relevant texts from retrieved documents\n",
    "    relevant_texts = [doc['text'] for doc in relevant_documents if isinstance(doc, dict) and 'text' in doc]\n",
    "\n",
    "    if len(relevant_texts) == 0:\n",
    "        return \"Sorry, I couldn't find any relevant information.\"\n",
    "\n",
    "    # Tokenize and pad relevant texts\n",
    "    encoded_inputs = tokenizer(relevant_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    input_ids = encoded_inputs[\"input_ids\"].to(device)\n",
    "\n",
    "    # Generate a response using T5 model\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_length=100,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=2,\n",
    "        repetition_penalty=2.0,\n",
    "        top_p=0.92,\n",
    "        temperature=0.7,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksa8pEVKHnOV",
    "outputId": "179ac994-2784-4c3f-edf1-8a0cb3c654ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, I couldn't find any relevant information.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "messages = [HumanMessage(content=\"Is red hair looks good:\")]\n",
    "response = chat(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8edK-C2XLs2p",
    "outputId": "2c84e13c-fd6a-485c-a734-4d4f4ad736c2"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, I couldn't find any relevant information.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "response = chat(\"A step by step recipe to make bolognese pasta:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GypMb58iNFuM"
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "response = chat(\"Is red hair looks good?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUqcZhpTDLg_"
   },
   "outputs": [],
   "source": [
    "query = \"Which cars has been produced for seven generation?\"\n",
    "res = chat(query)\n",
    "print(res)\n",
    "print(chat(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOtgnbiTMPVo",
    "outputId": "b8e392e9-5004-46af-87b7-bcb2cf287672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: name 'embed' is not defined\n",
      "Generated Response: Error during response generation.\n",
      "Similarity Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "def generate_response_with_similarity(\n",
    "    query: str,\n",
    "    embedding_function=embedding_function,\n",
    "    collection=collection,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    "    ):\n",
    "    \"\"\"\n",
    "    This function generates a response to a query using the T5 model and performs similarity calculations.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query string.\n",
    "        embedding_function: The function used to embed the query.\n",
    "        collection: The ChromaDB collection object containing the knowledge base.\n",
    "        model: The T5 model used for generating responses.\n",
    "        tokenizer: The tokenizer used with the T5 model.\n",
    "        device: The device (CPU or GPU) on which the model is running.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the generated response text and similarity score.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Embed the query using the provided embedding function\n",
    "        query_embedding = embedding_function.embed_query(query)\n",
    "\n",
    "        # Perform similarity search in ChromaDB using the query embedding\n",
    "        results = collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=1  # Retrieve top 1 most similar document\n",
    "        )\n",
    "\n",
    "        if results is None or 'documents' not in results or not results['documents']:\n",
    "            # If no similar documents are found, return a default response and similarity score\n",
    "            return \"No relevant information found.\", 0.0\n",
    "\n",
    "        # Extract the retrieved document embedding\n",
    "        document_embedding = results['embeddings'][0]\n",
    "\n",
    "        # Convert embeddings to tensors and move to device\n",
    "        query_tensor = torch.tensor(query_embedding).unsqueeze(0).to(device)\n",
    "        document_tensor = torch.tensor(document_embedding).unsqueeze(0).to(device)\n",
    "\n",
    "        # Calculate cosine similarity between query and document embeddings\n",
    "        similarity_score = torch.nn.functional.cosine_similarity(query_tensor, document_tensor).item()\n",
    "\n",
    "        # Generate response using the model\n",
    "        response = model.generate(input_ids=tokenizer.encode(query, return_tensors=\"pt\").to(device))\n",
    "\n",
    "        # Decode the generated token IDs\n",
    "        decoded_response = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "\n",
    "        return decoded_response, similarity_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error during response generation.\", 0.0\n",
    "\n",
    "# Example usage:\n",
    "response, similarity_score = generate_response_with_similarity(query=\"Is red hair looks good?\",\n",
    "                                                               embedding_function=embedding_function,\n",
    "                                                               collection=collection,\n",
    "                                                               model=model,\n",
    "                                                               tokenizer=tokenizer,\n",
    "                                                               device=device)\n",
    "print(\"Generated Response:\", response)\n",
    "print(\"Similarity Score:\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "rkksmM3wiuwH",
    "outputId": "865d553c-50e6-4ceb-ff9c-1e6fa291b4e3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_data_by_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2641872d5bc7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming you have a collection object for data storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mquery_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is the capital of France?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_data_by_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'search_data_by_vector' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have a collection object for data storage\n",
    "query_text = \"What is the capital of France?\"\n",
    "response_data = search_data_by_vector(query_text)\n",
    "\n",
    "if response_data:\n",
    "  print(\"Found data:\")\n",
    "  print(f\"Query: {response_data['query']}\")\n",
    "  print(f\"Response: {response_data['response']}\")\n",
    "  print(f\"Document: {response_data['document']}\")\n",
    "  print(f\"Vector: {response_data['vector']}\")\n",
    "  # Access other details from response_data['complete_response'] if needed\n",
    "else:\n",
    "  print(\"No data found for the query.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wjwx-sguDVKh"
   },
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    \"\"\"\n",
    "    This function attempts to augment the prompt using the knowledge base in ChromaDB.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string.\n",
    "\n",
    "    Returns:\n",
    "        str: The augmented prompt (or None if no results or errors occur).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Embed the query using the model\n",
    "        query_embedding = embedding_function.embed_query(query)\n",
    "\n",
    "        # Perform similarity search in ChromaDB using the query embedding\n",
    "        results = collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            k=3  # Retrieve top 3 most similar documents\n",
    "        )\n",
    "\n",
    "        if not results:\n",
    "            logging.error(\"No results returned from ChromaDB similarity search\")\n",
    "            return None\n",
    "\n",
    "        # Extract relevant knowledge from the retrieved documents (top 3)\n",
    "        source_knowledge = \"\\n\".join([\n",
    "            doc for doc in results['documents'][0]  # Assuming top result (index 0)\n",
    "        ])\n",
    "\n",
    "        # Feed into an augmented prompt\n",
    "        augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "Contexts:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\"\n",
    "\n",
    "        return augmented_prompt\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in augment_prompt: {e}\")\n",
    "        return None\n",
    "\n",
    "def chat(messages):\n",
    "    \"\"\"\n",
    "    This function processes a conversation and generates a response using the T5 model.\n",
    "\n",
    "    Args:\n",
    "        messages (list): A list of conversation messages (HumanMessage or AIMessage).\n",
    "\n",
    "    Returns:\n",
    "        AIMessage: The AI's response message containing the generated text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conversation = \" \".join([message.content for message in messages if isinstance(message, (HumanMessage, AIMessage))])\n",
    "        augmented_prompt = augment_prompt(conversation)\n",
    "\n",
    "        if not augmented_prompt:\n",
    "            logging.error(\"Augmented prompt is None\")\n",
    "            return AIMessage(content=\"Error generating response.\")\n",
    "\n",
    "        # Generate response using the model (assuming T5ForConditionalGeneration)\n",
    "        with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "            inputs = tokenizer.encode(augmented_prompt, return_tensors=\"pt\")\n",
    "            response = model.generate(input_ids=inputs, max_length=50, num_beams=4, early_stopping=True)\n",
    "\n",
    "        # Decode the generated token IDs\n",
    "        response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "\n",
    "        return AIMessage(content=response_text)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in chat: {e}\")\n",
    "        return AIMessage(content=\"Error during chat processing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDKOB3CAjhM7"
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query = \"Who is the prisoner in Harry Potter?\"\n",
    "prompt_content = augment_prompt(query)\n",
    "\n",
    "if not prompt_content:\n",
    "    raise ValueError(\"augment_prompt returned None\")\n",
    "\n",
    "prompt = HumanMessage(content=prompt_content)\n",
    "messages = [prompt]\n",
    "\n",
    "response = chat(messages)\n",
    "print(\"AI:\", response.content)\n",
    "\n",
    "# Add the latest AI response to messages\n",
    "messages.append(response)\n",
    "\n",
    "print(augment_prompt(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRf7UjDAkKAf"
   },
   "outputs": [],
   "source": [
    "# Assuming you have a HumanMessage class representing user input\n",
    "user_message = HumanMessage(content=\"What is the weather like in Paris today?\")\n",
    "\n",
    "# Call the chat function with the user message\n",
    "response = chat([user_message])\n",
    "\n",
    "# Print the AI's response\n",
    "print(\"AI:\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_i3Bu5m0kYl4"
   },
   "outputs": [],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=\"what kind of fiction are the harry potter?\"\n",
    ")\n",
    "\n",
    "res = chat(messages + [prompt])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-6ofAWskluL"
   },
   "outputs": [],
   "source": [
    "# pc.delete_index(index_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "036ba249d0d347a39da67e32d121b1f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "077402c5aab3497eafc548cd2af5261b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "125c94a72eae4f1586906ddb3f330612": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac9a4c559c9c4ec2967eb2d673f66925",
      "placeholder": "​",
      "style": "IPY_MODEL_ed8f97ef912c4c769325d8c3f7b61533",
      "value": "tokenizer.json: 100%"
     }
    },
    "14d7b73be6a5408b8456884b0e205fc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "17557239383d4bc197fd6e876bfbc9c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "19604d7fff60478eaedc9698019b200e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d28ff6020fd4c9baae451c8a0c5ef40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21e620bea7304ea3be79753d71eaf737": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_588b00e7f13941399df2b443b26a03a2",
      "placeholder": "​",
      "style": "IPY_MODEL_d06ab7f6807949658a16d8317e2ddff9",
      "value": " 1.40k/1.40k [00:00&lt;00:00, 20.8kB/s]"
     }
    },
    "2693f4b686924e208d4c863f9ac66216": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "276be142a7ea4124b7e8f77ca6106940": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_458d7aa40a5f4efa911b40863ca03483",
      "placeholder": "​",
      "style": "IPY_MODEL_6289acb47fc9497286ebf35ad59e1f0d",
      "value": " 2.20k/2.20k [00:00&lt;00:00, 41.7kB/s]"
     }
    },
    "2b401e56ec5140c382d81ea29eec5dc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d9dd98563a74c999b5d30091c6f2287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84caef96e04a4dd2bd75c8eeff4870b1",
      "placeholder": "​",
      "style": "IPY_MODEL_fa41e73b3bb94471b5d534ebc574ddd0",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "34dbc5f81dd94768a01cfbca6b4bfbe2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35c0bd81e2b54d07a23b5309095b85bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37b74b2b531d4d1c98be184065464305": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39540246e3b249b196ef72a934a0de07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_125c94a72eae4f1586906ddb3f330612",
       "IPY_MODEL_41b1dd09bd2d489e877337557dd3db90",
       "IPY_MODEL_6905891c3e524a7c8df3ba2750dc52ec"
      ],
      "layout": "IPY_MODEL_2693f4b686924e208d4c863f9ac66216"
     }
    },
    "399f15b2c0bc4ea1b9abbbf26390222d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a7ee0f9a6264e379789236a19ba59e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_baa40bfe137649bbb50291091885e7c4",
      "placeholder": "​",
      "style": "IPY_MODEL_036ba249d0d347a39da67e32d121b1f3",
      "value": " 147/147 [00:00&lt;00:00, 1.98kB/s]"
     }
    },
    "3db21bd1d5674036a09fcda6275e3e2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fce0b853b474eb1b848e6e9fa7069bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d208f847ff6d4b09b71d8644ac8c8a2a",
       "IPY_MODEL_c0ff54d1ac054dcf9e441c52f5134442",
       "IPY_MODEL_3a7ee0f9a6264e379789236a19ba59e5"
      ],
      "layout": "IPY_MODEL_1d28ff6020fd4c9baae451c8a0c5ef40"
     }
    },
    "4083c07308ff47b9b206a25e2c9edd7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40c85ec04d00404b9479e7f75eee91f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a462d0e0cf294e469a09a34d804ae41f",
       "IPY_MODEL_ecbdce2bd62440afb7ad681bc9ead7e4",
       "IPY_MODEL_4dc73007c56644e4918545e88a72d1ca"
      ],
      "layout": "IPY_MODEL_76434cf710934ac4b4180c5af75cc096"
     }
    },
    "41b1dd09bd2d489e877337557dd3db90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a15c78698e0f4d418b7759e4c6871b47",
      "max": 2424064,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ca7a25bf4814d72ad53918f5163bd4b",
      "value": 2424064
     }
    },
    "4262bc12849a46bc944797c96248af82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b71ca1b81f7740f28cc563471044be5f",
      "placeholder": "​",
      "style": "IPY_MODEL_6ba1302417b4409aaa673a3d23c809ff",
      "value": "spiece.model: 100%"
     }
    },
    "446fe6d13e2d4d8e94b7ed83f59cc3e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "458d7aa40a5f4efa911b40863ca03483": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "484a93536e944c3eb90fa01200916f8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0a53d7e45364ed0a7df179af69699f4",
      "placeholder": "​",
      "style": "IPY_MODEL_f849b4b64ba0452b817d76a93286aa6e",
      "value": "Downloading readme: 100%"
     }
    },
    "4931db783028447ab7263a41c46e5865": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a1afc3b98be4d3fa9af721d079fed64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2d9dd98563a74c999b5d30091c6f2287",
       "IPY_MODEL_7a6df4dc855e4c0ebf4a69d98dbbb0dd",
       "IPY_MODEL_276be142a7ea4124b7e8f77ca6106940"
      ],
      "layout": "IPY_MODEL_936bea7d6baf4e6a81bdb70a6f7635a9"
     }
    },
    "4c3c4f6cc9cb491c95e89c322823bc0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b401e56ec5140c382d81ea29eec5dc1",
      "placeholder": "​",
      "style": "IPY_MODEL_19604d7fff60478eaedc9698019b200e",
      "value": "Saving the dataset (2/2 shards): 100%"
     }
    },
    "4dc664a1271e4d93952e778ca64fdb40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3d3caa210a04313898928f4cee13146",
      "placeholder": "​",
      "style": "IPY_MODEL_3db21bd1d5674036a09fcda6275e3e2d",
      "value": "model.safetensors: 100%"
     }
    },
    "4dc73007c56644e4918545e88a72d1ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1cd6ff981ed4b3d9fbf0439a75fe940",
      "placeholder": "​",
      "style": "IPY_MODEL_bd386ef500674936b1f1fd9e107ee9fb",
      "value": " 2.54k/2.54k [00:00&lt;00:00, 42.8kB/s]"
     }
    },
    "55463e5abbc54c23a00f640065a65ea8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56d3a33994d2404b9179cd8b4ca137f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37b74b2b531d4d1c98be184065464305",
      "max": 594,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbdfd53e66ec486692d3e2f9bc1e39cb",
      "value": 594
     }
    },
    "588b00e7f13941399df2b443b26a03a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6289acb47fc9497286ebf35ad59e1f0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65564927405c4f0794295799dc4a35d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6905891c3e524a7c8df3ba2750dc52ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4931db783028447ab7263a41c46e5865",
      "placeholder": "​",
      "style": "IPY_MODEL_cca46811a9e64cee85cd6ccbf97d4a89",
      "value": " 2.42M/2.42M [00:00&lt;00:00, 7.50MB/s]"
     }
    },
    "6ba1302417b4409aaa673a3d23c809ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e779f4d0863479f950422e044ad434c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76434cf710934ac4b4180c5af75cc096": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a6df4dc855e4c0ebf4a69d98dbbb0dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e779f4d0863479f950422e044ad434c",
      "max": 2201,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14d7b73be6a5408b8456884b0e205fc9",
      "value": 2201
     }
    },
    "7b82db1484354d389bc3ce810e425d88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81c40bd32cc44715b210a059a179c704": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcf78414d9f44f8e938a8d9998297dc4",
      "placeholder": "​",
      "style": "IPY_MODEL_446fe6d13e2d4d8e94b7ed83f59cc3e7",
      "value": " 594/594 [00:00&lt;00:00, 8.26kB/s]"
     }
    },
    "81d2f8ed48a141b595f51fbb0af62374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "825750d814174250882ac668607c4f24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82cd2f28f2354d86b1106730afa82b29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4dc664a1271e4d93952e778ca64fdb40",
       "IPY_MODEL_b12ca3c7610347d5b5535986f460900a",
       "IPY_MODEL_c9957bb15fcc4ecfa52dcc399c9c0fd2"
      ],
      "layout": "IPY_MODEL_970895aeeefa4fc8a2847525304a8a22"
     }
    },
    "84caef96e04a4dd2bd75c8eeff4870b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ecb0ea52ca543c88826524068a7b790": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92c18672c20c419eb3cabea082912232": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "936bea7d6baf4e6a81bdb70a6f7635a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "970895aeeefa4fc8a2847525304a8a22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c3f3ae55196422481250ba2a1472c7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c492bcd67404acca6e1da6162059d45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4083c07308ff47b9b206a25e2c9edd7b",
      "placeholder": "​",
      "style": "IPY_MODEL_b302fb4c09c14c339be06422e7993284",
      "value": " 792k/792k [00:00&lt;00:00, 4.95MB/s]"
     }
    },
    "9ca7a25bf4814d72ad53918f5163bd4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a15c78698e0f4d418b7759e4c6871b47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1cd6ff981ed4b3d9fbf0439a75fe940": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a462d0e0cf294e469a09a34d804ae41f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcbcdf5d11124036ba80737b1805f336",
      "placeholder": "​",
      "style": "IPY_MODEL_ffae52ced8d44882aa0714f09f9e1f07",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "a89656dd30fe43039caa2a933da4bb7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abb0096c506f41b79330aa47c85dab08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac9a4c559c9c4ec2967eb2d673f66925": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0a53d7e45364ed0a7df179af69699f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b12ca3c7610347d5b5535986f460900a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b82db1484354d389bc3ce810e425d88",
      "max": 307867048,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6ad490c518945ed8d2306d23a0c47b2",
      "value": 307867048
     }
    },
    "b302fb4c09c14c339be06422e7993284": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b71ca1b81f7740f28cc563471044be5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b818c601a74a4552932da7a71ae65974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b9ffdee310944ffca6af6d563823ea7a",
       "IPY_MODEL_d1d0550e8a4f492792790b6be9941e6a",
       "IPY_MODEL_21e620bea7304ea3be79753d71eaf737"
      ],
      "layout": "IPY_MODEL_a89656dd30fe43039caa2a933da4bb7a"
     }
    },
    "b98331d832f048f6b2fa4d56b6b08711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65564927405c4f0794295799dc4a35d3",
      "placeholder": "​",
      "style": "IPY_MODEL_f04288120303426b8e92af1130d6d03b",
      "value": " 18430/18430 [00:19&lt;00:00, 1595.32 examples/s]"
     }
    },
    "b9ffdee310944ffca6af6d563823ea7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f04a5311c3714be6ba0fea83568edacc",
      "placeholder": "​",
      "style": "IPY_MODEL_34dbc5f81dd94768a01cfbca6b4bfbe2",
      "value": "config.json: 100%"
     }
    },
    "ba8eee20537b4b1e92b9e1bb28e6046a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c3c4f6cc9cb491c95e89c322823bc0e",
       "IPY_MODEL_f6a7b0c72ee04187bb4073c9c6bc3e60",
       "IPY_MODEL_b98331d832f048f6b2fa4d56b6b08711"
      ],
      "layout": "IPY_MODEL_35c0bd81e2b54d07a23b5309095b85bb"
     }
    },
    "ba958474fce94ff4846970796454616b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baa40bfe137649bbb50291091885e7c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd386ef500674936b1f1fd9e107ee9fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0ff54d1ac054dcf9e441c52f5134442": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4ae4f9065c0484a9e1f5b2e5ae0edc4",
      "max": 147,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_399f15b2c0bc4ea1b9abbbf26390222d",
      "value": 147
     }
    },
    "c6bd2be85557474b85bae5c68fa7640a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9957bb15fcc4ecfa52dcc399c9c0fd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eafb13952083441fb014c48dbfbda7e0",
      "placeholder": "​",
      "style": "IPY_MODEL_825750d814174250882ac668607c4f24",
      "value": " 308M/308M [00:03&lt;00:00, 76.2MB/s]"
     }
    },
    "cafa3e730c1042ab8b0e8c6a9e74aa16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4262bc12849a46bc944797c96248af82",
       "IPY_MODEL_fcedb9938252478a93a4a7360b6e3cab",
       "IPY_MODEL_9c492bcd67404acca6e1da6162059d45"
      ],
      "layout": "IPY_MODEL_55463e5abbc54c23a00f640065a65ea8"
     }
    },
    "cca46811a9e64cee85cd6ccbf97d4a89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf0362fb1de5408fbc5bde52b31a2d13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_484a93536e944c3eb90fa01200916f8a",
       "IPY_MODEL_56d3a33994d2404b9179cd8b4ca137f1",
       "IPY_MODEL_81c40bd32cc44715b210a059a179c704"
      ],
      "layout": "IPY_MODEL_ba958474fce94ff4846970796454616b"
     }
    },
    "d06ab7f6807949658a16d8317e2ddff9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d06b1f433cf142cc9f93c1a0a8d01de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d1d0550e8a4f492792790b6be9941e6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6bd2be85557474b85bae5c68fa7640a",
      "max": 1401,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbd413e611894157ab1fbefa2c907857",
      "value": 1401
     }
    },
    "d208f847ff6d4b09b71d8644ac8c8a2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92c18672c20c419eb3cabea082912232",
      "placeholder": "​",
      "style": "IPY_MODEL_abb0096c506f41b79330aa47c85dab08",
      "value": "generation_config.json: 100%"
     }
    },
    "d4ae4f9065c0484a9e1f5b2e5ae0edc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6ad490c518945ed8d2306d23a0c47b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dcbcdf5d11124036ba80737b1805f336": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3d3caa210a04313898928f4cee13146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eafb13952083441fb014c48dbfbda7e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecbdce2bd62440afb7ad681bc9ead7e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c3f3ae55196422481250ba2a1472c7e",
      "max": 2539,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_81d2f8ed48a141b595f51fbb0af62374",
      "value": 2539
     }
    },
    "ed8f97ef912c4c769325d8c3f7b61533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f04288120303426b8e92af1130d6d03b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f04a5311c3714be6ba0fea83568edacc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6a7b0c72ee04187bb4073c9c6bc3e60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ecb0ea52ca543c88826524068a7b790",
      "max": 18430,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d06b1f433cf142cc9f93c1a0a8d01de9",
      "value": 18430
     }
    },
    "f849b4b64ba0452b817d76a93286aa6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa41e73b3bb94471b5d534ebc574ddd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbd413e611894157ab1fbefa2c907857": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fbdfd53e66ec486692d3e2f9bc1e39cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fcedb9938252478a93a4a7360b6e3cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_077402c5aab3497eafc548cd2af5261b",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_17557239383d4bc197fd6e876bfbc9c9",
      "value": 791656
     }
    },
    "fcf78414d9f44f8e938a8d9998297dc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffae52ced8d44882aa0714f09f9e1f07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
