{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c7487c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openapi in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (1.1.0)\n",
      "Requirement already satisfied: inflection>=0.3.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from openapi) (0.5.1)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from openapi) (4.16.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from jsonschema>=2.6.0->openapi) (0.18.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from jsonschema>=2.6.0->openapi) (5.2.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from jsonschema>=2.6.0->openapi) (1.3.10)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from jsonschema>=2.6.0->openapi) (22.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6.0->openapi) (3.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: catboost in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: graphviz in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from catboost) (3.6.2)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from catboost) (1.10.0)\n",
      "Requirement already satisfied: six in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2022.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from matplotlib->catboost) (22.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from matplotlib->catboost) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from plotly->catboost) (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting openai\n",
      "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp38-cp38-macosx_11_0_arm64.whl (337 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.8/337.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp38-cp38-macosx_11_0_arm64.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-macosx_11_0_arm64.whl (35 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp38-cp38-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Building wheels for collected packages: openai\n",
      "  Building wheel for openai (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67596 sha256=1bb62b4c2d0376b5e4a5541820bac9fe3599e8c369358113c1072f024f5a8622\n",
      "  Stored in directory: /Users/Admin/Library/Caches/pip/wheels/a7/47/99/8273a59fbd59c303e8ff175416d5c1c9c03a2e83ebf7525a99\n",
      "Successfully built openai\n",
      "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.26.5 yarl-1.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openapi\n",
    "%pip install catboost\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92188b1",
   "metadata": {},
   "source": [
    "### still you may need to install from your terminal and then restart the jupyter\n",
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaceaacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1db343e-45a6-4ef0-93fd-945c86149b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\") # config = {\"USER\": \"foo\", \"EMAIL\": \"foo@example.org\"}\n",
    "openai.api_key = config[\"OPENAPI_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76935ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to call chatgpt and get the response\n",
    "def askChatGPT(question, engine=\"text-davinci-003\", max_tokens=240):\n",
    "    completion = openai.Completion.create(engine=engine, prompt=question, max_tokens=max_tokens)\n",
    "    return completion.choices[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ef703b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pandas is an open source library in Python for data analysis and manipulation. It is a powerful tool for analyzing, cleaning, transforming and visualizing data. Pandas has become a powerful tool for data analysis, programming, and data wrangling. The library consists of data structures, data handling functions and data analysis tools. It contains improved contents such as Panel Data, Series, Data Frames, and Numpy data types. It is a powerful library for data analysis and manipulation which allows one to quickly and easily manipulate data, create visualizations and generate reports.\n"
     ]
    }
   ],
   "source": [
    "# a generate test with simple question\n",
    "response = askChatGPT(\"What is pandas library?\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88395bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"what are some common pandas use cases?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5911a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"what are the most common deep learning librarires?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3250cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"what is deep neural network?\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf11660",
   "metadata": {},
   "source": [
    "### Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed217fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"give some ideas of feature transformations that can improve model performance?\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"Write an example numpay code using mean, std etc that performs data transformation?\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e38b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create an array\n",
    "arr = np.arange(16).reshape(4,4)\n",
    "print(arr)\n",
    "\n",
    "# Calculate the mean of the array\n",
    "mean_arr = np.mean(arr) \n",
    "print(mean_arr)\n",
    "\n",
    "# Calculate the standard deviation of the array\n",
    "std_arr = np.std(arr) \n",
    "print(std_arr)\n",
    "\n",
    "# Normalize the array\n",
    "z_score = (arr - mean_arr) / std_arr\n",
    "print(z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"Write example python code that perform data normalization on fake data\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305704f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"How do I select a time series model?\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f9285",
   "metadata": {},
   "source": [
    "### generating synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abbdb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"Write example code that generates synthetic healthcare readmission data stored in a dataframe\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# generating patient ids \n",
    "patient_ids = np.random.randint(1,10, size=5)\n",
    "# generating readmission status (boolean)\n",
    "readmission_status = np.random.choice([True, False], 5)\n",
    "# generate readmission severity (1 - 5)\n",
    "readmission_severity = np.random.randint(1,6, size=5)\n",
    "\n",
    "data = {'Patient_ID': patient_ids ,\n",
    "        'Readmission_Status': readmission_status,\n",
    "        'Readmission_Severity': readmission_severity }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"Write example code that generates synthetic healthcare readmission data stored in a dataframe. From this write code that builds a catboost model that predicts readmission outcomes. Also write code to calculate and print performance.\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after some rectification of the chatgpt code\n",
    "#importing libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def map_bool_to_int(x):\n",
    "    if x == 'yes' or x == 'male':\n",
    "        return 1\n",
    "    elif x == 'no' or x == 'female':\n",
    "        return 0\n",
    "\n",
    "#generating synthetic readmission data\n",
    "np.random.seed(123)\n",
    "print(map(map_bool_to_int, np.random.choice(['male','female'],500)))\n",
    "data = {\n",
    "    'age': np.random.randint(18,90,500),\n",
    "    'gender': map(map_bool_to_int, np.random.choice(['male','female'],500)),\n",
    "    'medication': map(map_bool_to_int, np.random.choice(['yes','no'], 500)),\n",
    "    'readmission': map(map_bool_to_int, np.random.choice(['yes','no'], 500))\n",
    "    }\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#building catboost model\n",
    "X = df[['age','gender','medication']]\n",
    "y = df['readmission']\n",
    "model = CatBoostClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "#calculating & printing performance\n",
    "predictions = model.predict(X)\n",
    "accuracy = sum(predictions == y)/len(y)\n",
    "print('Model accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"Write example python code that generates synthetic transaction data stored in a dataframe\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b55498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create empty dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Add columns\n",
    "df['CustomerName'] = [\"John Doe\", \"Jane Doe\", \"Joseph Doe\"]\n",
    "df['Amount'] = np.random.randint(20, 200, size=(3,))\n",
    "df['Category'] = ['Groceries', 'Travel', 'Food']\n",
    "df['Transaction Date'] = ['05/01/20', '06/01/20','07/01/20']\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"Write example python code that generates synthetic transaction data stored in a dataframe. Includes customer ID, CustomerName, Amount, Category, Age, Gender, and zip code\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb921b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running after some minor correction of code\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# generate customerIds\n",
    "customerIds = [random.randint(1000, 10000) for x in range(10)]\n",
    "\n",
    "# generate names\n",
    "names = [\"John\", \"Sara\", \"Mathew\", \"Graham\", \"Kris\", \"Chris\", \"Karen\", \"Olivia\",\n",
    "         \"Jack\", \"Emily\"]\n",
    "\n",
    "# generate amounts\n",
    "amounts = [random.randint(100, 2000) for x in range(10)]\n",
    "\n",
    "# generate categories\n",
    "categories = [\"Grocery\", \"Home Improvement\",\n",
    "              \"Electronics\", \"Furniture\", \"Gas\", \"Travel\", \"Clothing\", \"Kids\", \"Books\", \"Pens\"]\n",
    "\n",
    "# generate age\n",
    "ages = [random.randint(18, 70) for x in range(10)]\n",
    "\n",
    "# generate gender\n",
    "gender = np.random.choice([\"M\", \"F\"], 10)\n",
    "\n",
    "# generate zipcode\n",
    "zipCodes = [random.randint(10001, 11001) for x in range(10)]\n",
    "print(len(names), len(amounts), len(categories), len(ages), len(gender), len(zipCodes))\n",
    "# create dictionary\n",
    "d = { \"customerId\": customerIds,\n",
    "      \"CustomerName\": names,\n",
    "      \"Amount\": amounts,\n",
    "      \"Category\": categories,\n",
    "      \"Age\": ages,\n",
    "      \"Gender\": gender,\n",
    "      \"ZipCode\": zipCodes\n",
    "    }\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "# print df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156507a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"List some good public datasets\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"What are some emergning machine learning use-cases in healthcare?\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d42337",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = askChatGPT(\"Write a supervisor machine learning example code\", max_tokens=1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after correction\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#Load data into a variable\n",
    "X_train, y_train, X_test, y_test = get_data()\n",
    "\n",
    "#Initialize RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "#Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Evaluate accuracy of model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Use supervised learning techniques to get further insights into the data\n",
    "#Continuously measure performance\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "#Identifying feature importance\n",
    "f_importance = list(zip(X_train, clf.feature_importances_))\n",
    "\n",
    "#Make hyperparameter optimization to find best parameters\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c560b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92bd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
