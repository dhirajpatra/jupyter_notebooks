{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ccb741-8ff6-4b38-9f4e-e2e6494d9127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "\n",
    "# Comment this if the data visualisations doesn't work on your side\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e58a0-b38c-4c94-a373-efddb1fc3275",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow v\" + tf.__version__)\n",
    "print(\"TensorFlow Decision Forests v\" + tfdf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbefc6d-50bf-4d82-a6cd-fccd7c62950b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_function(model, data):\n",
    "  @tf.function(reduce_retracing=True)\n",
    "  def inner_function(model, data):\n",
    "    return model(data)\n",
    "\n",
    "  return inner_function(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c7061c-68f2-44ae-ab65-d8c450c06890",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/house-prices-advanced-regression-techniques/train.csv\")\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437a8fd-5e12-4ac0-b4bc-14ad16629854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'dataset' is your DataFrame\n",
    "null_counts = dataset.isnull().sum()\n",
    "null_columns = null_counts[null_counts > 0].index.tolist()  # Get column names with null values\n",
    "null_counts[null_counts > 0].plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed07d4-cb2b-4c9a-8748-f2e1981c8810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Columns with null values:\", null_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c5daf-23f8-4c1a-b6bb-0232ad271c15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop NaN valued cols\n",
    "cols_to_drop = ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "dataset.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1b6f0-b1ec-46a0-ab0d-2cff0ef88317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_counts = dataset.isnull().sum()\n",
    "null_columns = null_counts[null_counts > 0].index.tolist()  # Get column names with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64e59b-d68f-4647-a41e-df7f07eca9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716af3b-1768-4509-b76c-d5e53bba94e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming 'dataset' is your DataFrame\n",
    "for column in null_columns:\n",
    "    datatype = dataset[column].dtype\n",
    "    null_count = dataset[column].isnull().sum()\n",
    "    \n",
    "    print(f\"Column: {column}, DataType: {datatype}, Null Count: {null_count}\")\n",
    "\n",
    "    # Here, you can apply your logic to treat null values based on datatype\n",
    "    if dataset[column].dtype == object or dataset[column].dtype == bool:\n",
    "        dataset[column] = dataset[column].fillna(dataset[column].mode())\n",
    "    elif datatype in ['int64', 'float64']:\n",
    "        dataset[column] = dataset[column].fillna(dataset[column].mean())\n",
    "\n",
    "# You can customize the treatment for null values based on datatype as needed\n",
    "null_counts = dataset.isnull().sum()\n",
    "null_columns = null_counts[null_counts > 0].index.tolist()\n",
    "print(null_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b00d739-5ac4-4e06-a4b9-0642b476f665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display corellation only if it is more than 0.8\n",
    "def corelated_graph():\n",
    "    numerical_dataset = dataset.select_dtypes(include=['number'])  # Select only numerical columns\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.heatmap(dataset.corr()>0.8,\n",
    "            annot=True,\n",
    "            cbar=False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada0b98-4474-48e8-ab8f-2a6ee696d03d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corelated_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f831ec60-5bcd-40e1-9516-a59beb8b7648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop highly corelated col/features\n",
    "dataset.drop(columns=['TotRmsAbvGrd', 'TotalBsmtSF', 'GarageCars'], inplace=True)\n",
    "corelated_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55dcc50-0509-48b2-b4c7-ee539fd85147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(dataset, label=\"SaleCondition\")\n",
    "\n",
    "model = tfdf.keras.RandomForestModel()\n",
    "model.fit(tf_dataset)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1139c5-6eaa-4fa8-992f-c512dc0d676c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_file_path = \"data/house-prices-advanced-regression-techniques/test.csv\"\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338b759-1553-4457-a1a0-c5d001f59eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb29c8-6f6a-454f-9860-8a7d0225626d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_dataframe_info(df1, df2):\n",
    "  \"\"\"\n",
    "  Compares the information of two DataFrames.\n",
    "\n",
    "  Args:\n",
    "    df1: The first DataFrame.\n",
    "    df2: The second DataFrame.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of differences between the two DataFrames.\n",
    "  \"\"\"\n",
    "\n",
    "  differences = {}\n",
    "\n",
    "  # Compare the column names\n",
    "  column_names1 = df1.columns\n",
    "  column_names2 = df2.columns\n",
    "\n",
    "  # Get the columns that are only in the first DataFrame\n",
    "  df1_only_columns = list(set(column_names1) - set(column_names2))\n",
    "\n",
    "  # Get the columns that are only in the second DataFrame\n",
    "  df2_only_columns = list(set(column_names2) - set(column_names1))\n",
    "\n",
    "  # Add the column names to the differences dictionary\n",
    "  differences['column_names'] = {\n",
    "      'df1_only': df1_only_columns,\n",
    "      'df2_only': df2_only_columns\n",
    "  }\n",
    "\n",
    "  # Compare the data types\n",
    "  data_types1 = df1.dtypes\n",
    "  data_types2 = df2.dtypes\n",
    "\n",
    "  # Get the columns where the data types are different\n",
    "  different_data_types_columns = [\n",
    "      column for column in set(column_names1) & set(column_names2)\n",
    "      if data_types1[column] != data_types2[column]\n",
    "  ]\n",
    "\n",
    "  # Add the columns with different data types to the differences dictionary\n",
    "  differences['data_types'] = {\n",
    "      'different_data_types': different_data_types_columns\n",
    "  }\n",
    "\n",
    "  return differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42c5e5-db50-46ce-b693-6dac1c24d6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_dataframe_info(dataset, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c1910-af21-486d-9a07-f4005475a41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in test_data.columns:\n",
    "    print(f\"{test_data[col].name}: {test_data[col].dtype}\")\n",
    "    \n",
    "    # encode them\n",
    "    if test_data[col].dtype == object:\n",
    "        le = LabelEncoder()\n",
    "        test_data[col] = le.fit_transform(test_data[col])\n",
    "  \n",
    "    # In case of boolean data type \n",
    "    # convert them to binary\n",
    "    if test_data[col].dtype == 'bool':\n",
    "        test_data[col] = test_data[col].astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5acf8-4447-4908-b2ee-af89a183c3d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in test_data.columns:\n",
    "    # Check for null values presence\n",
    "    if test_data[col].isnull().sum() == 0:\n",
    "        continue\n",
    "\n",
    "    # If the data type is categorical filling by mode.\n",
    "    if test_data[col].dtype == object or test_data[col].dtype == bool:\n",
    "        test_data[col] = test_data[col].fillna(test_data[col].mode()[0])\n",
    "\n",
    "    # Else by mean\n",
    "    else:\n",
    "        test_data[col] = test_data[col].fillna(test_data[col].mean())\n",
    "\n",
    "test_data.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5658f5b7-84d6-4cec-ab1e-2276be8dad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b9143-a0a4-41fa-aabb-69677b2d9be4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the first record.\n",
    "first_record = dataset.iloc[0, :]\n",
    "\n",
    "# Print the record vertically.\n",
    "print(first_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f86537-d822-47f4-9342-3fd5259a5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Id', axis=1)\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365ca86-a7f4-4e29-8941-3842116c6889",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66947f2-5568-45a7-a17e-f175857aae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['SalePrice'].describe())\n",
    "plt.figure(figsize=(9, 8))\n",
    "sns.histplot(dataset['SalePrice'], bins=100, kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a97b32a-6b1b-4f9b-8ac9-acb49293ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(dataset.dtypes.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83568eae-09c8-4753-b1f0-9ef23ff31b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = dataset.select_dtypes(include = ['float64', 'int64'])\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a59c83-5129-467c-9a13-36b873fb079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3349c-2241-4c63-b9dc-c5c4b5fca9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_ratio=0.30):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "train_ds_pd, valid_ds_pd = split_dataset(dataset)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_ds_pd), len(valid_ds_pd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9dfdc-6639-49c3-8327-8b40bff66c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'SalePrice'\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)\n",
    "valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f8dda-5c74-45de-89c6-45b47c18f8a6",
   "metadata": {},
   "source": [
    "Select a Model\n",
    "\n",
    "There are several tree-based models for you to choose from.\n",
    "\n",
    "RandomForestModel\n",
    "GradientBoostedTreesModel\n",
    "CartModel\n",
    "DistributedGradientBoostedTreesModel\n",
    "\n",
    "To start, we'll work with a Random Forest. This is the most well-known of the Decision Forest training algorithms.\n",
    "\n",
    "A Random Forest is a collection of decision trees, each trained independently on a random subset of the training dataset (sampled with replacement). The algorithm is unique in that it is robust to overfitting, and easy to use.\n",
    "\n",
    "We can list the all the available models in TensorFlow Decision Forests using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43106ccf-f8b9-4b8f-af16-bbe2edfcb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdf.keras.get_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb0fc68-f746-48ff-8c97-52985282eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = tfdf.keras.RandomForestModel(hyperparameter_template=\"benchmark_rank1\", task=tfdf.keras.Task.REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6953334-ffb8-4aa7-a8dd-549b0a1375f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\n",
    "rf.compile(metrics=[\"mse\"]) # Optional, you can use this to include a list of eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df697b77-ddf3-4869-9a5e-05b88ba567e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(x=train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4997d1d-4f98-4036-8cce-566b7dcf69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdf.model_plotter.plot_model_in_colab(rf, tree_idx=0, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7456d2a-1866-4a8b-a937-6209a6450c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logs = rf.make_inspector().training_logs()\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.rmse for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"RMSE (out-of-bag)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a56cdaa-aa01-4a85-8d76-dc35dbf3e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = rf.make_inspector()\n",
    "inspector.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e12b7e-ea05-4817-b803-0b4993ad43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = rf.evaluate(x=valid_ds,return_dict=True)\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f382a-0804-4d60-b041-7196e9e0bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Available variable importances:\")\n",
    "for importance in inspector.variable_importances().keys():\n",
    "  print(\"\\t\", importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109ef8e-9c5e-44ba-9d2b-d497da41a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector.variable_importances()[\"NUM_AS_ROOT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7332a-1f69-433e-a2e9-05062e2375a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Mean decrease in AUC of the class 1 vs the others.\n",
    "variable_importance_metric = \"NUM_AS_ROOT\"\n",
    "variable_importances = inspector.variable_importances()[variable_importance_metric]\n",
    "\n",
    "# Extract the feature name and importance values.\n",
    "#\n",
    "# `variable_importances` is a list of <feature, importance> tuples.\n",
    "feature_names = [vi[0].name for vi in variable_importances]\n",
    "feature_importances = [vi[1] for vi in variable_importances]\n",
    "# The feature are ordered in decreasing importance value.\n",
    "feature_ranks = range(len(feature_names))\n",
    "\n",
    "bar = plt.barh(feature_ranks, feature_importances, label=[str(x) for x in feature_ranks])\n",
    "plt.yticks(feature_ranks, feature_names)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# TODO: Replace with \"plt.bar_label()\" when available.\n",
    "# Label each bar with values\n",
    "for importance, patch in zip(feature_importances, bar.patches):\n",
    "  plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{importance:.4f}\", va=\"top\")\n",
    "\n",
    "plt.xlabel(variable_importance_metric)\n",
    "plt.title(\"NUM AS ROOT of the class 1 vs the others\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ee081-3422-4474-abd2-549281233233",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test_data.pop('Id')\n",
    "\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "    test_data,\n",
    "    task = tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "preds = rf.predict(test_ds)\n",
    "output = pd.DataFrame({'Id': ids,\n",
    "                       'SalePrice': preds.squeeze()})\n",
    "\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2e5a9-880b-40f4-aeae-b62d32098979",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv('data/house-prices-advanced-regression-techniques/sample_submission.csv')\n",
    "sample_submission_df['SalePrice'] = rf.predict(test_ds)\n",
    "# sample_submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "sample_submission_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e79fd-90a9-4322-b463-e7f2785857fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a004f8de-deae-48ed-9b47-59c67dd779cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76412a6f-4be6-47cd-b7fa-27f63ca21554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ec2ce-31b6-4608-a468-a466776b3e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
