{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“¦ Product Demand Forecasting\n",
    "This notebook demonstrates a complete demand forecasting pipeline using:\n",
    "- **EDA** â€“ Exploratory Data Analysis\n",
    "- **Classical Models** â€“ SARIMA, Exponential Smoothing (Holt-Winters)\n",
    "- **Machine Learning** â€“ XGBoost with time-series features\n",
    "- **Evaluation** â€“ MAE, RMSE, MAPE\n",
    "- **Visualization** â€“ Forecast plots with confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install if needed\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn statsmodels xgboost pmdarima\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Plotting style\n",
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "sns.set_palette('tab10')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "print('Libraries loaded successfully âœ…')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate / Load Data\n",
    "We simulate realistic multi-product demand data with **trend**, **seasonality**, **promotions**, and **noise**.\n",
    "Replace the cell below with `pd.read_csv('your_file.csv')` if you have real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demand_data(n_products=3, start='2021-01-01', periods=156):\n",
    "    \"\"\"Simulate weekly demand for multiple products.\"\"\"\n",
    "    dates = pd.date_range(start=start, periods=periods, freq='W')\n",
    "    products = [f'Product_{chr(65+i)}' for i in range(n_products)]\n",
    "    \n",
    "    rows = []\n",
    "    for prod in products:\n",
    "        base     = np.random.randint(200, 600)\n",
    "        trend    = np.linspace(0, np.random.randint(50, 200), periods)\n",
    "        seasonal = base * 0.25 * np.sin(2 * np.pi * np.arange(periods) / 52)\n",
    "        promo    = np.random.choice([0, base * 0.3], size=periods, p=[0.88, 0.12])\n",
    "        noise    = np.random.normal(0, base * 0.08, periods)\n",
    "        demand   = np.maximum(0, base + trend + seasonal + promo + noise)\n",
    "        \n",
    "        for i, d in enumerate(dates):\n",
    "            rows.append({\n",
    "                'date'      : d,\n",
    "                'product'   : prod,\n",
    "                'demand'    : round(demand[i]),\n",
    "                'price'     : round(np.random.uniform(10, 50), 2),\n",
    "                'on_promo'  : int(promo[i] > 0)\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df = generate_demand_data()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['product', 'date']).reset_index(drop=True)\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Basic Statistics ===')\n",
    "print(df.groupby('product')['demand'].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demand over time per product\n",
    "fig, axes = plt.subplots(len(df['product'].unique()), 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "for ax, (prod, grp) in zip(axes, df.groupby('product')):\n",
    "    ax.plot(grp['date'], grp['demand'], linewidth=1.5, label=prod)\n",
    "    promo_dates = grp[grp['on_promo'] == 1]['date']\n",
    "    ax.scatter(promo_dates, grp[grp['on_promo'] == 1]['demand'],\n",
    "               color='red', s=30, zorder=5, label='Promo')\n",
    "    ax.set_ylabel('Units Sold')\n",
    "    ax.set_title(prod)\n",
    "    ax.legend(loc='upper left', fontsize=8)\n",
    "\n",
    "axes[-1].xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "plt.suptitle('Weekly Demand by Product', fontsize=14, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap and distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Distribution\n",
    "for prod, grp in df.groupby('product'):\n",
    "    axes[0].hist(grp['demand'], bins=30, alpha=0.6, label=prod)\n",
    "axes[0].set_title('Demand Distribution')\n",
    "axes[0].set_xlabel('Units Sold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Correlation\n",
    "corr = df[['demand', 'price', 'on_promo']].corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', ax=axes[1], cmap='coolwarm', center=0)\n",
    "axes[1].set_title('Feature Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on one product for decomposition\n",
    "FOCUS_PRODUCT = 'Product_A'\n",
    "series = df[df['product'] == FOCUS_PRODUCT].set_index('date')['demand']\n",
    "\n",
    "decomposition = seasonal_decompose(series, model='additive', period=52)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "for ax, component, title in zip(\n",
    "    axes,\n",
    "    [series, decomposition.trend, decomposition.seasonal, decomposition.resid],\n",
    "    ['Observed', 'Trend', 'Seasonal', 'Residual']\n",
    "):\n",
    "    ax.plot(component, linewidth=1.2)\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'Seasonal Decomposition â€” {FOCUS_PRODUCT}', fontsize=14, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller stationarity test\n",
    "adf_result = adfuller(series.dropna())\n",
    "print(f'ADF Statistic : {adf_result[0]:.4f}')\n",
    "print(f'p-value       : {adf_result[1]:.4f}')\n",
    "print(f'Stationary    : {\"Yes âœ…\" if adf_result[1] < 0.05 else \"No âŒ (consider differencing)\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_WEEKS = 12   # Forecast horizon\n",
    "\n",
    "product_data = {}\n",
    "for prod, grp in df.groupby('product'):\n",
    "    grp = grp.set_index('date').sort_index()\n",
    "    train = grp.iloc[:-TEST_WEEKS]\n",
    "    test  = grp.iloc[-TEST_WEEKS:]\n",
    "    product_data[prod] = {'train': train, 'test': test}\n",
    "    print(f'{prod}: train={len(train)} weeks, test={len(test)} weeks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 1 â€” Holt-Winters Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_holt_winters(train_series, test_len, seasonal_periods=52):\n",
    "    model = ExponentialSmoothing(\n",
    "        train_series,\n",
    "        trend='add',\n",
    "        seasonal='add',\n",
    "        seasonal_periods=seasonal_periods\n",
    "    ).fit(optimized=True)\n",
    "    forecast = model.forecast(test_len)\n",
    "    return forecast\n",
    "\n",
    "hw_forecasts = {}\n",
    "for prod, data in product_data.items():\n",
    "    hw_forecasts[prod] = fit_holt_winters(\n",
    "        data['train']['demand'], TEST_WEEKS\n",
    "    )\n",
    "print('Holt-Winters fitted âœ…')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model 2 â€” SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sarima(train_series, test_len, order=(1,1,1), seasonal_order=(1,1,1,52)):\n",
    "    model = SARIMAX(\n",
    "        train_series,\n",
    "        order=order,\n",
    "        seasonal_order=seasonal_order,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    ).fit(disp=False)\n",
    "    forecast = model.forecast(steps=test_len)\n",
    "    return forecast, model\n",
    "\n",
    "sarima_forecasts = {}\n",
    "sarima_models    = {}\n",
    "for prod, data in product_data.items():\n",
    "    print(f'Fitting SARIMA for {prod}...')\n",
    "    fc, mdl = fit_sarima(data['train']['demand'], TEST_WEEKS)\n",
    "    sarima_forecasts[prod] = fc\n",
    "    sarima_models[prod]    = mdl\n",
    "print('SARIMA fitted âœ…')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model 3 â€” XGBoost with Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df_prod):\n",
    "    \"\"\"Create time-series features from date index.\"\"\"\n",
    "    df_f = df_prod.copy()\n",
    "    df_f['week']        = df_f.index.isocalendar().week.astype(int)\n",
    "    df_f['month']       = df_f.index.month\n",
    "    df_f['quarter']     = df_f.index.quarter\n",
    "    df_f['year']        = df_f.index.year\n",
    "    df_f['week_of_year']= df_f.index.isocalendar().week.astype(int)\n",
    "    df_f['trend']       = np.arange(len(df_f))\n",
    "    # Lag features\n",
    "    for lag in [1, 2, 4, 8, 12, 52]:\n",
    "        df_f[f'lag_{lag}'] = df_f['demand'].shift(lag)\n",
    "    # Rolling stats\n",
    "    for w in [4, 8, 12]:\n",
    "        df_f[f'roll_mean_{w}'] = df_f['demand'].shift(1).rolling(w).mean()\n",
    "        df_f[f'roll_std_{w}']  = df_f['demand'].shift(1).rolling(w).std()\n",
    "    return df_f.dropna()\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    'week', 'month', 'quarter', 'year', 'trend', 'price', 'on_promo',\n",
    "    'lag_1', 'lag_2', 'lag_4', 'lag_8', 'lag_12', 'lag_52',\n",
    "    'roll_mean_4', 'roll_mean_8', 'roll_mean_12',\n",
    "    'roll_std_4',  'roll_std_8',  'roll_std_12'\n",
    "]\n",
    "\n",
    "xgb_forecasts = {}\n",
    "xgb_models    = {}\n",
    "\n",
    "for prod, data in product_data.items():\n",
    "    full_feat  = create_features(pd.concat([data['train'], data['test']]))\n",
    "    train_feat = full_feat.iloc[:-TEST_WEEKS]\n",
    "    test_feat  = full_feat.iloc[-TEST_WEEKS:]\n",
    "\n",
    "    X_train, y_train = train_feat[FEATURE_COLS], train_feat['demand']\n",
    "    X_test           = test_feat[FEATURE_COLS]\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_test, test_feat['demand'])],\n",
    "              verbose=False)\n",
    "\n",
    "    xgb_forecasts[prod] = pd.Series(\n",
    "        model.predict(X_test), index=test_feat.index\n",
    "    )\n",
    "    xgb_models[prod] = (model, FEATURE_COLS)\n",
    "\n",
    "print('XGBoost fitted âœ…')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ensemble Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple average ensemble\n",
    "ensemble_forecasts = {}\n",
    "for prod in product_data:\n",
    "    hw  = hw_forecasts[prod].values\n",
    "    sar = sarima_forecasts[prod].values\n",
    "    xgb_= xgb_forecasts[prod].values\n",
    "    idx = product_data[prod]['test'].index\n",
    "    ensemble_forecasts[prod] = pd.Series(\n",
    "        (hw + sar + xgb_) / 3, index=idx\n",
    "    )\n",
    "print('Ensemble computed âœ…')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, predicted):\n",
    "    actual, predicted = np.array(actual), np.array(predicted)\n",
    "    mask = actual != 0\n",
    "    return np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100\n",
    "\n",
    "def evaluate(actual, predicted, model_name):\n",
    "    mae  = mean_absolute_error(actual, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    map_ = mape(actual, predicted)\n",
    "    return {'Model': model_name, 'MAE': round(mae, 2),\n",
    "            'RMSE': round(rmse, 2), 'MAPE (%)': round(map_, 2)}\n",
    "\n",
    "all_results = []\n",
    "for prod in product_data:\n",
    "    actual = product_data[prod]['test']['demand']\n",
    "    for name, fc in [\n",
    "        ('Holt-Winters', hw_forecasts[prod].values),\n",
    "        ('SARIMA',       sarima_forecasts[prod].values),\n",
    "        ('XGBoost',      xgb_forecasts[prod].values),\n",
    "        ('Ensemble',     ensemble_forecasts[prod].values),\n",
    "    ]:\n",
    "        res = evaluate(actual.values, fc, name)\n",
    "        res['Product'] = prod\n",
    "        all_results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(all_results)[['Product', 'Model', 'MAE', 'RMSE', 'MAPE (%)']]\n",
    "print('=== Evaluation Results ===')\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of MAPE by model\n",
    "pivot = results_df.pivot(index='Model', columns='Product', values='MAPE (%)')\n",
    "pivot.plot(kind='bar', figsize=(10, 5), edgecolor='black', alpha=0.85)\n",
    "plt.title('MAPE (%) by Model and Product â€” Lower is Better', fontweight='bold')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Product')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Forecast Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prod, data in product_data.items():\n",
    "    train = data['train']['demand']\n",
    "    test  = data['test']['demand']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.plot(train.index[-52:], train.values[-52:], label='Train (last year)',\n",
    "            color='steelblue', linewidth=1.8)\n",
    "    ax.plot(test.index,  test.values,  label='Actual',\n",
    "            color='black', linewidth=2, linestyle='--')\n",
    "    ax.plot(test.index,  hw_forecasts[prod].values,\n",
    "            label='Holt-Winters', color='orange',    linewidth=1.5)\n",
    "    ax.plot(test.index,  sarima_forecasts[prod].values,\n",
    "            label='SARIMA',       color='purple',    linewidth=1.5)\n",
    "    ax.plot(test.index,  xgb_forecasts[prod].values,\n",
    "            label='XGBoost',      color='green',     linewidth=1.5)\n",
    "    ax.plot(test.index,  ensemble_forecasts[prod].values,\n",
    "            label='Ensemble',     color='red',       linewidth=2.5, linestyle='-.')\n",
    "\n",
    "    ax.axvline(test.index[0], color='grey', linestyle=':', linewidth=1.5, label='Forecast Start')\n",
    "    ax.set_title(f'Demand Forecast â€” {prod}', fontweight='bold', fontsize=13)\n",
    "    ax.set_ylabel('Units Sold')\n",
    "    ax.legend(loc='upper left', fontsize=8)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Feature Importance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(xgb_models), figsize=(16, 5))\n",
    "\n",
    "for ax, (prod, (model, feats)) in zip(axes, xgb_models.items()):\n",
    "    importance = pd.Series(model.feature_importances_, index=feats)\n",
    "    importance.sort_values().tail(12).plot(kind='barh', ax=ax, edgecolor='black')\n",
    "    ax.set_title(f'Feature Importance\\n{prod}', fontweight='bold')\n",
    "    ax.set_xlabel('Importance Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Future Forecast (Next 8 Weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUTURE_WEEKS = 8\n",
    "\n",
    "for prod, data in product_data.items():\n",
    "    full_series = df[df['product'] == prod].set_index('date')['demand']\n",
    "\n",
    "    # Holt-Winters future forecast\n",
    "    hw_model = ExponentialSmoothing(\n",
    "        full_series, trend='add', seasonal='add', seasonal_periods=52\n",
    "    ).fit(optimized=True)\n",
    "    future_fc = hw_model.forecast(FUTURE_WEEKS)\n",
    "    future_dates = pd.date_range(\n",
    "        full_series.index[-1] + pd.Timedelta(weeks=1),\n",
    "        periods=FUTURE_WEEKS, freq='W'\n",
    "    )\n",
    "    future_fc.index = future_dates\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(full_series.index[-52:], full_series.values[-52:],\n",
    "            label='Historical', color='steelblue', linewidth=1.8)\n",
    "    ax.plot(future_fc.index, future_fc.values,\n",
    "            label='8-Week Forecast', color='red', linewidth=2, linestyle='--', marker='o')\n",
    "    ax.fill_between(future_fc.index,\n",
    "                    future_fc.values * 0.9,\n",
    "                    future_fc.values * 1.1,\n",
    "                    alpha=0.2, color='red', label='Â±10% CI')\n",
    "    ax.set_title(f'Future Demand Forecast â€” {prod} (Next {FUTURE_WEEKS} Weeks)',\n",
    "                 fontweight='bold')\n",
    "    ax.set_ylabel('Units Sold')\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f'\\n{prod} â€” Next {FUTURE_WEEKS} Week Forecast (Holt-Winters):')\n",
    "    print(future_fc.rename('Forecasted Demand').to_frame().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary\n",
    "\n",
    "| Step | What was done |\n",
    "|------|---------------|\n",
    "| EDA | Trend, seasonality, promo effects explored |\n",
    "| Decomposition | Additive decomposition + ADF test |\n",
    "| Holt-Winters | Triple exponential smoothing |\n",
    "| SARIMA | Statistical seasonal ARIMA |\n",
    "| XGBoost | Lag + rolling + calendar features |\n",
    "| Ensemble | Simple average of all three |\n",
    "| Evaluation | MAE, RMSE, MAPE per product |\n",
    "| Future Forecast | 8-week outlook with confidence interval |\n",
    "\n",
    "**Tips for production use:**\n",
    "- Replace simulated data with your real sales file\n",
    "- Use `pmdarima.auto_arima` for automatic SARIMA order selection\n",
    "- Add external regressors (weather, holidays, stock levels)\n",
    "- Implement cross-validation with `TimeSeriesSplit`\n",
    "- Consider Prophet or NeuralProphet for complex seasonality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
