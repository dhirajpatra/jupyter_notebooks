{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed5aaaa3cd3f4fc9bb11c79a439b5c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a89e037a55447818bed4f99e0fd65cb",
              "IPY_MODEL_546c0ec650f24bcf96455f177258b767",
              "IPY_MODEL_80f86674e70f44bd9dad9cd626fea1aa"
            ],
            "layout": "IPY_MODEL_f82d41ec482c45d69deaa5164736c472"
          }
        },
        "3a89e037a55447818bed4f99e0fd65cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8905dbb0c0c4a34b3d75f89bb00f40a",
            "placeholder": "​",
            "style": "IPY_MODEL_4306ea2a307c4f4d839103b89b79c425",
            "value": "Dl Completed...: 100%"
          }
        },
        "546c0ec650f24bcf96455f177258b767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_763df50b79544c82abae2a5bdbdd0fd8",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48f7bf96b4f64352be42be60bbdaf0ef",
            "value": 5
          }
        },
        "80f86674e70f44bd9dad9cd626fea1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a9f5bc4052448e5884576fc78489c0c",
            "placeholder": "​",
            "style": "IPY_MODEL_bb66dd3d298d490092e8a49ad0f37e50",
            "value": " 5/5 [00:00&lt;00:00,  8.35 file/s]"
          }
        },
        "f82d41ec482c45d69deaa5164736c472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8905dbb0c0c4a34b3d75f89bb00f40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4306ea2a307c4f4d839103b89b79c425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "763df50b79544c82abae2a5bdbdd0fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48f7bf96b4f64352be42be60bbdaf0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a9f5bc4052448e5884576fc78489c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb66dd3d298d490092e8a49ad0f37e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook will show how to use the MNIST dataset with both pyTorch as well as Tensorflow"
      ],
      "metadata": {
        "id": "WPMFXgfSIUzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pyTorch"
      ],
      "metadata": {
        "id": "1ZZc5x1CIfIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ht-wZql5INNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "elPLlYGgIPxN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "GupKNLB2synR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9reo3TAs12N",
        "outputId": "8d178340-b96a-40ab-e3d9-ab54586a75d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGgm8vvHs4rZ",
        "outputId": "b9721582-89b2-4e4d-d665-a91be4f1fcef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function cross entropy and optimize with stocastic gradient boosting algorithm\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "WTPmtm2Os8Qv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "Qx0FO_oGs_jp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "ghM8VY6xtCDm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pnro8UCDtEMT",
        "outputId": "6f76d770-fe24-4433-9a04-c93e50e0ccde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.304225  [   64/60000]\n",
            "loss: 2.288055  [ 6464/60000]\n",
            "loss: 2.267038  [12864/60000]\n",
            "loss: 2.267143  [19264/60000]\n",
            "loss: 2.248859  [25664/60000]\n",
            "loss: 2.220971  [32064/60000]\n",
            "loss: 2.231415  [38464/60000]\n",
            "loss: 2.199058  [44864/60000]\n",
            "loss: 2.198331  [51264/60000]\n",
            "loss: 2.157847  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 42.9%, Avg loss: 2.153965 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.168658  [   64/60000]\n",
            "loss: 2.156096  [ 6464/60000]\n",
            "loss: 2.094773  [12864/60000]\n",
            "loss: 2.113685  [19264/60000]\n",
            "loss: 2.064558  [25664/60000]\n",
            "loss: 2.007096  [32064/60000]\n",
            "loss: 2.040484  [38464/60000]\n",
            "loss: 1.961568  [44864/60000]\n",
            "loss: 1.965715  [51264/60000]\n",
            "loss: 1.890805  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 1.887317 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.922558  [   64/60000]\n",
            "loss: 1.889926  [ 6464/60000]\n",
            "loss: 1.769892  [12864/60000]\n",
            "loss: 1.811713  [19264/60000]\n",
            "loss: 1.710527  [25664/60000]\n",
            "loss: 1.663496  [32064/60000]\n",
            "loss: 1.690451  [38464/60000]\n",
            "loss: 1.590736  [44864/60000]\n",
            "loss: 1.612165  [51264/60000]\n",
            "loss: 1.502673  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.6%, Avg loss: 1.521226 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.591896  [   64/60000]\n",
            "loss: 1.555428  [ 6464/60000]\n",
            "loss: 1.403281  [12864/60000]\n",
            "loss: 1.471167  [19264/60000]\n",
            "loss: 1.359396  [25664/60000]\n",
            "loss: 1.361069  [32064/60000]\n",
            "loss: 1.375718  [38464/60000]\n",
            "loss: 1.301444  [44864/60000]\n",
            "loss: 1.334840  [51264/60000]\n",
            "loss: 1.226318  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.3%, Avg loss: 1.254931 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.336886  [   64/60000]\n",
            "loss: 1.319484  [ 6464/60000]\n",
            "loss: 1.150147  [12864/60000]\n",
            "loss: 1.250476  [19264/60000]\n",
            "loss: 1.127175  [25664/60000]\n",
            "loss: 1.163734  [32064/60000]\n",
            "loss: 1.184241  [38464/60000]\n",
            "loss: 1.121362  [44864/60000]\n",
            "loss: 1.161430  [51264/60000]\n",
            "loss: 1.066403  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.4%, Avg loss: 1.090029 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the torch model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kg9zq5GtGDE",
        "outputId": "bc79b22d-ac16-4b43-b203-2fa0febc45c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use the saved model\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw3R5E3xtKM3",
        "outputId": "335610ed-5cac-4a8d-fe7c-c1f7ff1ff49b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model classes\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "m9Hj0gDatMiE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model evaluation\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "\n",
        "    # Plot the image\n",
        "    plt.imshow(x[0])\n",
        "    plt.title(f\"Predicted: {predicted}, Actual: {actual}\")\n",
        "    plt.axis('off')  # Remove unnecessary axes\n",
        "    plt.show()\n",
        "\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "-zGSIR6IKFPD",
        "outputId": "e1fb3e76-ab93-4a12-9b07-8d16a237ec93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gXrtT3-tOvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now with Tensorflow"
      ],
      "metadata": {
        "id": "gxdC9IBitScK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import save_model, load_model"
      ],
      "metadata": {
        "id": "aahr7QfPtVUl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "ed5aaaa3cd3f4fc9bb11c79a439b5c6a",
            "3a89e037a55447818bed4f99e0fd65cb",
            "546c0ec650f24bcf96455f177258b767",
            "80f86674e70f44bd9dad9cd626fea1aa",
            "f82d41ec482c45d69deaa5164736c472",
            "c8905dbb0c0c4a34b3d75f89bb00f40a",
            "4306ea2a307c4f4d839103b89b79c425",
            "763df50b79544c82abae2a5bdbdd0fd8",
            "48f7bf96b4f64352be42be60bbdaf0ef",
            "2a9f5bc4052448e5884576fc78489c0c",
            "bb66dd3d298d490092e8a49ad0f37e50"
          ]
        },
        "id": "9QslceTXtlOo",
        "outputId": "e8331f47-88e7-4a14-ca5b-3a3bcc3e8831"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed5aaaa3cd3f4fc9bb11c79a439b5c6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(128)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oe0PNm29tnqq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "6ZvSOIJ0trEC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "input_shape = (28, 28, 3)\n",
        "input_layer = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# model = tf.keras.models.Sequential([\n",
        "#   tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "#   tf.keras.layers.Dense(128, activation='relu'),\n",
        "#   tf.keras.layers.Dense(10)\n",
        "# ])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    # Rescaling layer doesn't need input_tensor in Sequential models\n",
        "    tf.keras.layers.Rescaling(1./255),  # Normalize input values\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=6,\n",
        "    validation_data=ds_test,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44mPOVgXts9L",
        "outputId": "f17b15f4-04f3-4701-d1c7-8d91b4a45940"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 103ms/step - loss: 1.8131 - sparse_categorical_accuracy: 0.3358 - val_loss: 0.4075 - val_sparse_categorical_accuracy: 0.8768\n",
            "Epoch 2/6\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 95ms/step - loss: 0.3561 - sparse_categorical_accuracy: 0.8919 - val_loss: 0.2356 - val_sparse_categorical_accuracy: 0.9258\n",
            "Epoch 3/6\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 96ms/step - loss: 0.2283 - sparse_categorical_accuracy: 0.9308 - val_loss: 0.1860 - val_sparse_categorical_accuracy: 0.9415\n",
            "Epoch 4/6\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 97ms/step - loss: 0.1684 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.1302 - val_sparse_categorical_accuracy: 0.9590\n",
            "Epoch 5/6\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 101ms/step - loss: 0.1335 - sparse_categorical_accuracy: 0.9586 - val_loss: 0.1063 - val_sparse_categorical_accuracy: 0.9675\n",
            "Epoch 6/6\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 96ms/step - loss: 0.1102 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.0954 - val_sparse_categorical_accuracy: 0.9676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ed6b1b35cc0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model (replace 'my_model.h5' with your desired filename)\n",
        "save_model(model, 'my_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_892ZefLhlA",
        "outputId": "1c7e90a0-29a7-46ff-8df2-ad1a8ee8e8e1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "loaded_model = load_model('my_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqXPO0uFS5rX",
        "outputId": "2de8712a-44ab-40a8-c466-08ab255dfc6c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming test_data is a list of tuples (image, label)\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "\n",
        "# Preprocess the test image if necessary\n",
        "x = np.array(x, dtype='float32') / 255.0  # Convert to NumPy array and normalize\n"
      ],
      "metadata": {
        "id": "-ozkT2ihS8y2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `@tf.function` decorator and `jit_compile=True` flag are part of TensorFlow's optimization features, which help accelerate code execution, especially during model inference or training. Here's a breakdown of each:\n",
        "\n",
        "### **1. `@tf.function` Decorator**\n",
        "- **Purpose**: Converts a Python function into a TensorFlow computational graph.\n",
        "- **Explanation**: When you use `@tf.function`, TensorFlow traces the Python function and compiles it into a highly optimized, static computational graph. This graph runs faster than the original Python code because TensorFlow can optimize the graph for performance.\n",
        "- **Benefits**:\n",
        "  - **Speed**: Computational graphs are faster because they reduce the overhead of Python’s dynamic interpretation and allow TensorFlow to apply various optimizations.\n",
        "  - **Compatibility**: Useful for running TensorFlow code on different devices, such as GPUs or TPUs, because the graph abstracts the underlying hardware.\n",
        "  - **Batch Execution**: Graphs can optimize across batches of operations, reducing computational redundancy.\n",
        "\n",
        "### **2. `jit_compile=True` in `@tf.function`**\n",
        "- **Purpose**: Enables Just-In-Time (JIT) compilation using TensorFlow's XLA (Accelerated Linear Algebra) compiler.\n",
        "- **Explanation**: JIT compilation further optimizes the computational graph by fusing operations together, reducing memory usage, and improving execution speed.\n",
        "- **Benefits**:\n",
        "  - **Additional Performance Gains**: By using the XLA compiler, the code can achieve even faster execution times.\n",
        "  - **Operation Fusion**: JIT compilation can fuse multiple operations into a single kernel (GPU or TPU operation), reducing the number of device-to-host memory transfers.\n",
        "- **When to Use**:\n",
        "  - **Model Inference**: Often used when speed is critical during model inference.\n",
        "  - **Training**: Can also be helpful during training to speed up repeated computations.\n",
        "\n",
        "### **When to Use Them**\n",
        "- **`@tf.function`**: Use this decorator when you want to optimize the performance of TensorFlow functions, especially when they contain multiple TensorFlow operations.\n",
        "- **`jit_compile=True`**: Use this when further optimization is desired, particularly on platforms that support XLA, like certain GPUs or TPUs.\n"
      ],
      "metadata": {
        "id": "vn0HC78-WRh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enables Just-In-Time (JIT) compilation using TensorFlow's XLA (Accelerated Linear Algebra) compiler.\n",
        "@tf.function(jit_compile=True)\n",
        "def predict(model, x):\n",
        "    return model(x)\n",
        "\n",
        "# Reshape the input to ensure it has the correct shape: (batch_size, height, width, channels)\n",
        "x = tf.reshape(x, (28, 28))  # Reshape to 28x28 if necessary\n",
        "x = tf.expand_dims(x, axis=0)  # Add batch dimension, resulting in (1, 28, 28)\n",
        "x = tf.expand_dims(x, axis=-1)  # Add channel dimension, resulting in (1, 28, 28, 1)\n",
        "\n",
        "# Make the prediction\n",
        "pred = predict(loaded_model, x)\n",
        "\n",
        "# Get the predicted and actual classes\n",
        "predicted, actual = classes[tf.argmax(pred[0])], classes[y]\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(x[0, :, :, 0].numpy(), cmap='gray')  # Remove unnecessary dimensions and plot\n",
        "plt.title(f\"Predicted: {predicted}, Actual: {actual}\")\n",
        "plt.axis('off')  # Remove unnecessary axes\n",
        "plt.show()\n",
        "\n",
        "print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "UyKkqxhzUA7-",
        "outputId": "e90f72f3-88b1-47e5-c253-8606251967c4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Sandal\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XnXoNydlUjrK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}