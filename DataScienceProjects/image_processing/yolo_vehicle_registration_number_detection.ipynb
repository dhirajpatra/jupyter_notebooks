{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZINS_CMzv_LP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s a restructured and concise version of your content:\n",
        "\n",
        "---\n",
        "\n",
        "## YOLO Vehicle Registration Plate Detection\n",
        "\n",
        "**Object Detection Overview:**\n",
        "There are three primary object detection techniques:\n",
        "- **R-CNN Family:** R-CNN, Fast R-CNN, and Faster R-CNN\n",
        "- **SSDs (Single Shot Detectors)**\n",
        "- **YOLO (You Only Look Once)**\n",
        "\n",
        "### R-CNN:\n",
        "R-CNN was one of the first deep learning-based object detection techniques, introduced in the paper *[Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation](https://arxiv.org/abs/1311.2524)* in 2013. R-CNN involves two stages: selective search for bounding boxes and classification of those boxes.\n",
        "\n",
        "While accurate, it was slow, leading to the development of:\n",
        "- **Fast R-CNN**: Improved speed but still used selective search.\n",
        "- **Faster R-CNN**: Introduced the Region Proposal Network (RPN), eliminating selective search and improving both speed and accuracy.\n",
        "\n",
        "Despite its improvements, R-CNN still had limitations in speed, achieving only 5 FPS on a GPU.\n",
        "\n",
        "### One-Stage Detector:\n",
        "To improve speed, **Single Shot Detectors (SSDs)** and **YOLO** emerged, treating object detection as a regression problem. These methods detect objects and predict bounding boxes simultaneously, making them faster but less accurate than two-stage detectors like R-CNN.\n",
        "\n",
        "### YOLO:\n",
        "**YOLO (You Only Look Once)** was introduced in the paper *[You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)* in 2015. YOLO achieved 45 FPS on a GPU, significantly faster than R-CNN. Over the years, YOLO has evolved with versions like:\n",
        "- **YOLOv2**: *[YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242)*, capable of detecting over 9,000 objects.\n",
        "- **YOLOv3**: *[YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767)*, larger and more accurate than its predecessors.\n",
        "\n",
        "### YOLO Architecture:\n",
        "YOLO consists of 24 convolutional layers followed by two fully connected layers. Alternating 1×1 convolutional layers reduce the feature space from previous layers. The convolutional layers are pre-trained on ImageNet classification at a lower resolution (224×224) and then doubled for object detection.\n",
        "\n",
        "![YOLO Architecture](https://tekworld.org/wp-content/uploads/2019/01/Screen-Shot-2019-01-24-at-9.54.45-PM-1024x447.png)  \n",
        "Source: *[YOLO Paper](https://arxiv.org/pdf/1506.02640.pdf)*\n",
        "\n",
        "---\n",
        "\n",
        "Now, let's implement a simple YOLO-based vehicle registration plate detection program.\n",
        "\n"
      ],
      "metadata": {
        "id": "39mTpoBmwAss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-contrib-python\n",
        "!pip install opencv-python\n",
        "!pip install pytesseract\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "r7oW-vUOw10f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from glob import glob\n",
        "import os\n",
        "import random\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "qkqeywpgwJQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget \"https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\""
      ],
      "metadata": {
        "id": "ClVCm9biyB39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget \"https://pjreddie.com/media/files/yolov3.weights\"\n",
        "# !wget \"https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\""
      ],
      "metadata": {
        "id": "2nOkYVzbyJy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO model\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")"
      ],
      "metadata": {
        "id": "eP1UqGcswM-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image\n",
        "img = cv2.imread(\"car1.jpg\")\n"
      ],
      "metadata": {
        "id": "n-IdKnV_wRLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess image\n",
        "img = cv2.resize(img, (416, 416))\n",
        "img = img / 255.0\n"
      ],
      "metadata": {
        "id": "z3f8FKD7zLbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in video paths\n",
        "videos = glob('*.mp4')\n",
        "print(videos)"
      ],
      "metadata": {
        "id": "N07xzMlkzOj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick pre-trained model\n",
        "model_pretrained = YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "id": "ciU2juM7zTdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read video by index\n",
        "video = cv2.VideoCapture(videos[0])\n",
        "\n",
        "# get video dims\n",
        "frame_width = int(video.get(3))\n",
        "frame_height = int(video.get(4))\n",
        "size = (frame_width, frame_height)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "out = cv2.VideoWriter('./outputs/uk_dash_2.avi', fourcc, 20.0, size)\n",
        "\n",
        "# read frames\n",
        "ret = True\n",
        "\n",
        "while ret:\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    if ret:\n",
        "        # detect & track objects\n",
        "        results = model_pretrained.track(frame, persist=True)\n",
        "\n",
        "        # plot results\n",
        "        composed = results[0].plot()\n",
        "\n",
        "        # save video\n",
        "        out.write(composed)\n",
        "\n",
        "out.release()\n",
        "video.release()"
      ],
      "metadata": {
        "id": "Va6XFnYEz8l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the ZIP file\n",
        "zip_file_path = 'lpr_yolov8.zip'\n",
        "\n",
        "# Directory to extract the contents\n",
        "extract_dir = 'lpr_yolov8'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"ZIP file extracted to:\", extract_dir)"
      ],
      "metadata": {
        "id": "WtJBKEfo321y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip downloaded dataset to `./datasets`\n",
        "dataset = '/content/dataset/lpr_yolov8/data.yaml'\n",
        "\n",
        "# load a model\n",
        "# backbone = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
        "backbone = YOLO(\"yolov8n.pt\")  # load a pre-trained model (recommended for training)"
      ],
      "metadata": {
        "id": "FuTaerwpz_tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model\n",
        "# results = backbone.train(data=dataset, epochs=20)  # train the model"
      ],
      "metadata": {
        "id": "8kqnCSmh0Tk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1dIyJooVaowaNUj0R1Q-HUnu-utiGsEj8&confirm=t\""
      ],
      "metadata": {
        "id": "GsZi-3P061fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regular pre-trained yolov8 model for car recognition\n",
        "coco_model = YOLO('yolov8s.pt')\n",
        "# yolov8 model trained to detect number plates\n",
        "np_model = YOLO('best.pt')"
      ],
      "metadata": {
        "id": "UssDsHgs6Rvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # car detection\n",
        "\n",
        "# # read video by index\n",
        "# video = cv2.VideoCapture(videos[1])\n",
        "\n",
        "# ret = True\n",
        "# frame_number = -1\n",
        "# # all vehicle class IDs from the COCO dataset (car, motorbike, truck) https://docs.ultralytics.com/datasets/detect/coco/#dataset-yaml\n",
        "# vehicles = [2,3,5]\n",
        "# vehicle_bounding_boxes = []\n",
        "\n",
        "# # read the 10 first frames\n",
        "# while ret:\n",
        "#     frame_number += 1\n",
        "#     ret, frame = video.read()\n",
        "\n",
        "#     if ret and frame_number < 10:\n",
        "#         # use track() to identify instances and track them frame by frame\n",
        "#         detections = coco_model.track(frame, persist=True)[0]\n",
        "#         # save cropped detections\n",
        "#         # detections.save_crop('outputs')\n",
        "#         # print nodel predictions for debugging\n",
        "#         # print(results)\n",
        "\n",
        "#         for detection in detections.boxes.data.tolist():\n",
        "#             # print detection bounding boxes for debugging\n",
        "#             # print(detection)\n",
        "#             x1, y1, x2, y2, track_id, score, class_id = detection\n",
        "#             # I am only interested in class IDs that belong to vehicles\n",
        "#             if int(class_id) in vehicles and score > 0.5:\n",
        "#                 vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n",
        "\n",
        "# # print found bounding boxes for debugging\n",
        "# print(vehicle_bounding_boxes)\n",
        "# video.release()"
      ],
      "metadata": {
        "id": "5upFuEcr0WNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# License plate detection\n",
        "\n",
        "# read video by index\n",
        "video = cv2.VideoCapture(videos[0])\n",
        "\n",
        "ret = True\n",
        "frame_number = -1\n",
        "vehicles = [2,3,5]\n",
        "\n",
        "# read the 10 first frames\n",
        "while ret:\n",
        "    frame_number += 1\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    if ret and frame_number < 10:\n",
        "\n",
        "        # vehicle detector\n",
        "        detections = coco_model.track(frame, persist=True)[0]\n",
        "        for detection in detections.boxes.data.tolist():\n",
        "            x1, y1, x2, y2, track_id, score, class_id = detection\n",
        "            if int(class_id) in vehicles and score > 0.5:\n",
        "                vehicle_bounding_boxes = []\n",
        "                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n",
        "                for bbox in vehicle_bounding_boxes:\n",
        "                    print(bbox)\n",
        "                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n",
        "                    # debugging check if bbox lines up with detected vehicles (should be identical to save_crops() above\n",
        "                    # cv.imwrite(str(track_id) + '.jpg', roi)\n",
        "\n",
        "                    # license plate detector for region of interest\n",
        "                    license_plates = np_model(roi)[0]\n",
        "                    # check every bounding box for a license plate\n",
        "                    for license_plate in license_plates.boxes.data.tolist():\n",
        "                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n",
        "                        # verify detections\n",
        "                        print(license_plate, 'track_id: ' + str(bbox[4]))\n",
        "                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n",
        "                        cv2.imwrite(str(track_id) + '.jpg', plate)\n",
        "\n",
        "video.release()"
      ],
      "metadata": {
        "id": "n1pME-7E51uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# License plate detection\n",
        "\n",
        "# Define the video file name (ensure the MP4 file is in the same directory as the script)\n",
        "video_file = 'traffic.mp4'  # Replace with your actual MP4 file name\n",
        "\n",
        "# Get the absolute path of the video file\n",
        "# Get the absolute path of the video file\n",
        "video_path = os.path.join(os.getcwd(), video_file)\n",
        "\n",
        "# Read video from the file\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "ret = True\n",
        "frame_number = -1\n",
        "vehicles = [2, 3, 5]\n",
        "\n",
        "# Read the first 10 frames\n",
        "while ret:\n",
        "    frame_number += 1\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    if ret and frame_number < 10:\n",
        "        # Display the current video frame using cv2_imshow (for Colab)\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        # Vehicle detector\n",
        "        detections = coco_model.track(frame, persist=True)[0]\n",
        "        for detection in detections.boxes.data.tolist():\n",
        "            x1, y1, x2, y2, track_id, score, class_id = detection\n",
        "            if int(class_id) in vehicles and score > 0.5:\n",
        "                vehicle_bounding_boxes = []\n",
        "                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n",
        "                for bbox in vehicle_bounding_boxes:\n",
        "                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n",
        "\n",
        "                    # Display the vehicle region of interest (ROI)\n",
        "                    cv2_imshow(roi)\n",
        "\n",
        "                    # License plate detector for region of interest\n",
        "                    license_plates = np_model(roi)[0]\n",
        "                    for license_plate in license_plates.boxes.data.tolist():\n",
        "                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n",
        "                        # Verify detections\n",
        "                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n",
        "\n",
        "                        # Display the detected license plate\n",
        "                        cv2_imshow(plate)\n",
        "\n",
        "                        # Save the detected license plate\n",
        "                        cv2.imwrite(str(track_id) + '.jpg', plate)\n",
        "\n",
        "# Release video capture\n",
        "video.release()\n",
        "\n"
      ],
      "metadata": {
        "id": "YpRvBJNV7YUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XR2PB8xF8yc7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}