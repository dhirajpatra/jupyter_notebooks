{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ce8a29-9b43-4f94-b6b3-bd80223bf466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 11:01:42.460005: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-23 11:01:42.468464: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-23 11:01:42.560702: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-23 11:01:44.894005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50  # Replace with your pre-trained model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b4edf-5723-4760-9b27-c57be4f082bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and validation data directories\n",
    "train_data_dir = '/content/gdrive/MyDrive/Snow_Covered_Solar_Panel_Detect/Images/train'\n",
    "val_data_dir = '/content/gdrive/MyDrive/Snow_Covered_Solar_Panel_Detect/Images/validate'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e1c90-e55c-4485-9383-3fe4cd551436",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_RUN = False\n",
    "img_width=256\n",
    "img_height=256\n",
    "IMAGE_SIZE=(img_width, img_height)\n",
    "IMAGE_CHANNELS=3\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab5a1bc-008d-4c2f-a32e-2330ee4a7e75",
   "metadata": {},
   "source": [
    "### ImageDataGenerator and Reference Learning\n",
    "\n",
    "**ImageDataGenerator** is a powerful tool in Keras for image augmentation, a technique that artificially expands your dataset by creating variations of existing images. This is particularly valuable in reference learning (image classification), where a model learns to distinguish between different categories of objects in images. Here's how ImageDataGenerator aids reference learning:\n",
    "\n",
    "Reduces Overfitting: Limited training data can lead to overfitting, where a model performs well on the training set but poorly on unseen data. Image augmentation helps by generating diverse image variations, forcing the model to learn more generalizable features that are not specific to the original training images.\n",
    "Improves Model Robustness: Real-world images encounter variations in lighting, rotation, scaling, and other factors. Image augmentation helps the model learn to be robust to these variations, making it perform better on unseen images that might have different characteristics than those in the training set.\n",
    "Key ImageDataGenerator Parameters\n",
    "\n",
    "Here are some essential parameters of ImageDataGenerator to consider for image augmentation:\n",
    "\n",
    "rescale: Normalizes pixel values between 0 and 1 (commonly used for image classification models).\n",
    "\n",
    "shear_range: Randomly applies shearing transformation for rotation-like effects.\n",
    "\n",
    "zoom_range: Randomly zooms in or out of the image to simulate different viewing distances.\n",
    "\n",
    "horizontal_flip: Randomly flips images horizontally for data augmentation.\n",
    "\n",
    "rotation_range: Rotates images randomly within a specified degree range.\n",
    "\n",
    "width_shift_range, height_shift_range: Randomly shifts images horizontally or vertically within a specified range of pixel values.\n",
    "\n",
    "fill_mode: Defines how to handle pixels beyond the original image boundaries during transformations (e.g., 'nearest', 'constant')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d7b69-b130-440d-834b-ea11260dba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator objects for training and validation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f450f4b-176a-412e-9cd0-311ff133a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images using flow_from_directory with data augmentation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),  # Replace with your image dimensions\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Adjust for binary or multi-class classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c1627-670c-4d0e-a8a9-8840a1bfb678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data generator\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f63ed-6d50-463b-a9c7-6cf70c3d8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model (e.g., ResNet50)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db571888-7ef7-47c8-8ff1-dc5889487c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze pre-trained layers (adjust number of layers to freeze as needed)\n",
    "for layer in base_model.layers[:-2]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7cdc9-37fd-4ba5-be36-477faab88daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers for your specific classification task\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=1024, activation='relu')(x)  # Adjust number of units for your classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deaea81-b242-49dc-9a8e-901f6af340a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4589430b-c3c5-4f5b-aea6-c6cb4d00b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af4cfd-600f-4010-b8cd-0c01333c2c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with fit_generator for data augmentation\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=10,  # Adjust number of epochs as needed\n",
    "                    validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bf542-a4c4-4e2c-8a56-ee31e34ec0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on unseen data\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
