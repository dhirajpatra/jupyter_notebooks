{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies\n",
    "We will be using Tensorflow for the network, and Scikit-learn for the GLCM computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "import random\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are paying attention to the [Chest X-ray (Covid-19 & Pneumonia)](https://www.kaggle.com/prashant268/chest-xray-covid19-pneumonia) dataset, there are only xxx number of Covid19 training data, compared to the xxx number of the pneumonia training data. Thus, we definitely (but not mandatory) need to balance number of data between each class. The [COVID-19 Radiography Database](https://www.kaggle.com/tawsifurrahman/covid19-radiography-database) will gives us some more Covid19 x-ray data for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/kaggle/input/coffee-bean-dataset-resized-224-x-224/train/*'\n",
    "test_dir = '/kaggle/input/coffee-bean-dataset-resized-224-x-224/test/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labeling data\n",
    "categories_dict = {\n",
    "  0: \"Dark\",\n",
    "  1: \"Green\",\n",
    "  2: \"Light\",\n",
    "  3: \"Medium\"  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n",
    "TARGET_SIZE = (SIZE,SIZE)\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "label = 0 \n",
    "\n",
    "#Importing the first training dataset\n",
    "\n",
    "for directory_path in glob.glob(train_dir):\n",
    "    assert categories_dict[label] == os.path.normpath(directory_path).split(os.path.sep)[-1]\n",
    "    print(categories_dict[label])\n",
    "    counter = 1\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        if(counter%200==0): print(counter,\"images loaded\")\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        img = cv2.resize(img, TARGET_SIZE)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "        counter+=1\n",
    "        if(counter%1500==0): break\n",
    "    \n",
    "    print(counter,\"images loaded\")\n",
    "    label +=1\n",
    "    \n",
    "\n",
    "x_train = np.array(train_images)\n",
    "y_train = to_categorical(train_labels, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_labels = []\n",
    "label = 0\n",
    "\n",
    "#importing the testing dataset\n",
    "\n",
    "for directory_path in glob.glob(test_dir):\n",
    "    assert categories_dict[label] == os.path.normpath(directory_path).split(os.path.sep)[-1]\n",
    "    print(categories_dict[label])\n",
    "    counter = 1\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        if(counter%100==0): print(counter, \"images loaded\")\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        img = cv2.resize(img, TARGET_SIZE)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(label)\n",
    "        counter+=1\n",
    "    \n",
    "    print(counter,\"images loaded\")\n",
    "    label +=1\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = to_categorical(test_labels, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting data into train and test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split(train_images, train_labels)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(x_train, y_train, test_size=0.2,random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train:\",train_images.shape[0],\", test:\",test_images.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Traditional\" Feature Extraction with GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(images):\n",
    "    image_dataset = pd.DataFrame()\n",
    "    for image in images:   \n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        #greycomatrix(image, distances, angles, levels=256, symmetric=False, normed=False)\n",
    "        #distances - List of pixel pair distance offsets.\n",
    "        #angles - List of pixel pair angles in radians.\n",
    "        \n",
    "        #5 configuration for the grey-level co-occurrence matrix calculation\n",
    "        dists = [[1],[3],[5],[3],[3]]\n",
    "        angles = [[0],[45],[90],[np.pi/4],[np.pi/2]]\n",
    "        \n",
    "        for n ,(dist, angle) in enumerate(zip(dists, angles)):\n",
    "        \n",
    "            GLCM = greycomatrix(image, dist, angle)       \n",
    "            GLCM_Energy = greycoprops(GLCM, 'energy')[0]\n",
    "            df['Energy'+str(n)] = GLCM_Energy\n",
    "            GLCM_corr = greycoprops(GLCM, 'correlation')[0]\n",
    "            df['Corr'+str(n)] = GLCM_corr       \n",
    "            GLCM_diss = greycoprops(GLCM, 'dissimilarity')[0]\n",
    "            df['Diss_sim'+str(n)] = GLCM_diss       \n",
    "            GLCM_hom = greycoprops(GLCM, 'homogeneity')[0]\n",
    "            df['Homogen'+str(n)] = GLCM_hom       \n",
    "            GLCM_contr = greycoprops(GLCM, 'contrast')[0]\n",
    "            df['Contrast'+str(n)] = GLCM_contr\n",
    "\n",
    "        image_dataset = image_dataset.append(df)\n",
    "        \n",
    "    return image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_extr_features = feature_extractor(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_extr_features = feature_extractor(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_images)\n",
    "# convert from integers to floats\n",
    "train_images_norm = train_images.astype('float32')\n",
    "test_images_norm = test_images.astype('float32')\n",
    "\n",
    "#normalize to the range 0-1\n",
    "train_images_norm /= 224.0\n",
    "test_images_norm /= 224.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "train_extr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network to extract the high-level features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn():\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(224,224,1), name='Original_Images'),\n",
    "        keras.layers.Conv2D(input_shape=(140,140,1), filters=32, kernel_size=11, strides=1, activation='relu', name='Conv1'),\n",
    "        keras.layers.Conv2D(input_shape=(130,130,32), filters=32, kernel_size=11, strides=1, activation='relu', name='Conv2'),\n",
    "        keras.layers.MaxPool2D(pool_size=(5, 5), strides=2),\n",
    "        keras.layers.Conv2D(input_shape=(58,58,32), filters=64, kernel_size=9, strides=1, activation='relu', name='Conv3'),\n",
    "        keras.layers.MaxPool2D(pool_size=(5, 5), strides=2),\n",
    "        keras.layers.Conv2D(input_shape=(23,23,64), filters=128, kernel_size=8, strides=1, activation='relu', name='Conv4'),\n",
    "        keras.layers.Conv2D(input_shape=(16,16,128), filters=256, kernel_size=9, strides=1, activation='relu', name='Conv5'),\n",
    "        keras.layers.Conv2D(input_shape=(8,8,256), filters=256, kernel_size=8,  strides=1, activation='relu', name='Conv6'),    \n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(8, activation=tf.keras.activations.relu, name='Dense')\n",
    "    ])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multilayer Perceptron to learn the numerical feature data extracted from the GLCM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp():\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=25),\n",
    "        keras.layers.Dense(8, activation=tf.keras.activations.relu, name='Dense1'),\n",
    "        keras.layers.Dense(4, activation=tf.keras.activations.relu, name='Dense2')\n",
    "    ])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intertwining the 2 feature extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = build_mlp()\n",
    "cnn = build_cnn()\n",
    "\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "x = Dense(8, activation=\"relu\")(combinedInput)\n",
    "x = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version of the notebook, we are using Adam as the optimizer. Please kindly check the older version of the notebook to see how other optimizer, such as SGD and RMSprop, performs on the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce Learning Rate on Plateau**, to reduce the learning rate gradually if there is no significant improvement on the performance of the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " opt = keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt , loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptive Learning Rate(ALR)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "cb = [\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=10,\n",
    "        mode='auto',\n",
    "        min_delta=0.0002,\n",
    "        cooldown=5,\n",
    "        min_lr=10e-8,\n",
    "        verbose=1,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter\n",
    "BATCH_SIZE = 64\n",
    "EPOCH_NUM = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_inputs = tf.data.Dataset.from_tensor_slices((train_extr_features, tf.expand_dims(train_images_norm, axis=-1)))\n",
    "dataset_label = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_inputs, dataset_label)).batch(BATCH_SIZE).repeat()\n",
    "STEP_SIZE_TRAIN= train_images_norm.shape[0]//BATCH_SIZE\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# fit model\n",
    "history = model.fit(dataset, \n",
    "                    validation_data=([test_extr_features, tf.expand_dims(test_images_norm, axis=-1)], test_labels),\n",
    "                    epochs = EPOCH_NUM, steps_per_epoch=STEP_SIZE_TRAIN,callbacks=cb)\n",
    "# Calculate training time\n",
    "training_time = time.time() - start_time\n",
    "print(\"\\nTraining time: {:.2f} seconds\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('.Tingkat_RoastingKopi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = tf.data.Dataset.from_tensor_slices((test_extr_features, tf.expand_dims(test_images_norm, axis=-1)))\n",
    "test_labelz = tf.data.Dataset.from_tensor_slices(test_labels)\n",
    "\n",
    "test_dataset = tf.data.Dataset.zip((test_inputs, test_labelz)).batch(BATCH_SIZE).repeat()\n",
    "STEP_SIZE_TEST= test_images_norm.shape[0]//BATCH_SIZE\n",
    "\n",
    "score = model.evaluate(test_dataset, batch_size=BATCH_SIZE, steps=STEP_SIZE_TEST )\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "print(skimage.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.color import rgb2gray\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import cv2  # or you can use skimage.color.rgb2gray\n",
    "\n",
    "# image_name = \"Dark/dark (1).png\"\n",
    "# image_name = \"Light/light (1).png\"\n",
    "image_name = \"Green/green (1).png\"\n",
    "# image_name = \"Medium/medium (1).png\"\n",
    "test_dir = \"/kaggle/input/coffee-bean-dataset-resized-224-x-224/test/\"\n",
    "image_path = os.path.join(test_dir, image_name)  # New test image\n",
    "\n",
    "# Load image in RGB\n",
    "img = load_img(image_path, target_size=(img_height, img_width))\n",
    "img_array = img_to_array(img)\n",
    "\n",
    "# Convert to grayscale (single channel) for model input\n",
    "img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "img_gray_input = np.expand_dims(img_gray, axis=-1)  # Add channel dim\n",
    "img_gray_input = np.expand_dims(img_gray_input, axis=0)  # Add batch dim\n",
    "\n",
    "# For GLCM feature extraction - 2D uint8 grayscale image without batch dim\n",
    "img_gray_for_glcm = img_gray.astype('uint8')\n",
    "\n",
    "# print(\"feature_array shape:\", feature_array.shape)\n",
    "# print(\"img_gray_input shape:\", img_gray_input.shape)\n",
    "\n",
    "inputs = [feature_array, img_gray_input]\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# for i, input_layer in enumerate(model.input):\n",
    "#     print(f\"Input {i}: name={input_layer.name}, shape={input_layer.shape}\")\n",
    "\n",
    "# print(len(model.input))\n",
    "\n",
    "class_names = [\"Dark\", \"Green\", \"Light\", \"Medium\"] \n",
    "\n",
    "# Now use img_gray_input for model input \n",
    "# and img_gray_for_glcm for gray level co-occurrence matrix feature extraction\n",
    "\n",
    "# GLCM feature extraction helper\n",
    "def extract_glcm_features(image, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    features = []\n",
    "    glcm = greycomatrix(image, distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "    for prop in props:\n",
    "        vals = greycoprops(glcm, prop).flatten()\n",
    "        features.extend(vals)\n",
    "    return np.array(features)\n",
    "\n",
    "# Extract GLCM features (this example extracts 24 features)\n",
    "# glcm_features = extract_glcm_features(img_gray_uint8)\n",
    "glcm_features = extract_glcm_features(img_gray_for_glcm)\n",
    "# print(\"GLCM features shape:\", glcm_features.shape)  # Should be (24,)\n",
    "\n",
    "# If model expects 25 features, add one dummy or compute an extra feature\n",
    "if glcm_features.shape[0] == 24:\n",
    "    glcm_features = np.append(glcm_features, 0)  # pad to 25 features\n",
    "\n",
    "feature_array = glcm_features.reshape(1, -1)  # shape: (1, 25)\n",
    "\n",
    "# Prediction\n",
    "inputs = [feature_array, img_gray_input]\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Softmax and output\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "predicted_class = class_names[np.argmax(score)]\n",
    "confidence = 100 * np.max(score)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}, Confidence: {confidence:.2f}%\")\n",
    "\n",
    "# print(\"Original image shape:\", original_img.shape)\n",
    "\n",
    "img = load_img(image_path, target_size=(img_height, img_width))\n",
    "img_array = img_to_array(img)\n",
    "# print(\"After load_img and img_to_array:\", img_array.shape)  # Should be (224,224,3)\n",
    "\n",
    "plt.imshow(img_array.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.title(\"Original RGB Image\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2403562,
     "sourceId": 4059269,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30124,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
