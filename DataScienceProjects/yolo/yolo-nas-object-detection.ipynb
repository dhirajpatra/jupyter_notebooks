{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f14f2c1-8118-49e8-bdd2-caa446f36398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install super-gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04693bee-87d4-4d46-9858-e468d7ec6523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The console stream is logged into /Users/Admin/sg_logs/console.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-09 11:00:16] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n",
      "[2023-06-09 11:00:17] WARNING - redirects.py - NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/py38/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "[2023-06-09 11:00:30] WARNING - __init__.py - Failed to import pytorch_quantization\n",
      "[2023-06-09 11:00:30] WARNING - calibrator.py - Failed to import pytorch_quantization\n",
      "[2023-06-09 11:00:30] WARNING - export.py - Failed to import pytorch_quantization\n",
      "[2023-06-09 11:00:30] WARNING - selective_quantization_utils.py - Failed to import pytorch_quantization\n",
      "[2023-06-09 11:00:30] WARNING - env_sanity_check.py - \u001b[31mFailed to verify operating system: Deci officially supports only Linux kernels. Some features may not work as expected.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from super_gradients.training import Trainer\n",
    "from super_gradients.training import dataloaders\n",
    "from super_gradients.training.dataloaders.dataloaders import (coco_detection_yolo_format_train, coco_detection_yolo_format_val)\n",
    "from super_gradients.training import models\n",
    "from super_gradients.training.losses import PPYoloELoss\n",
    "# from super_gradients.training.metrics import (\n",
    "# DetectionMetrics_650,\n",
    "# DetectionMetrics_056_095\n",
    "# )\n",
    "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1d15f7-bc53-4920-b2cd-c66cb5543afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset.\n",
    "def download_file(url, save_name):\n",
    "\n",
    "    if not os.path.exists(save_name):\n",
    "        print(f\"Downloading file\")\n",
    "        file = requests.get(url, stream=True)\n",
    "        total_size = int(file.headers.get('content-length', 8))\n",
    "        block_size = 1024\n",
    "        progress_bar = tqdm(\n",
    "            total=total_size, \n",
    "            unit='iB',\n",
    "            unit_scale=True\n",
    "        )\n",
    "        with open(os.path.join(save_name), 'wb') as f:\n",
    "\n",
    "            for data in file.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                f.write(data)\n",
    "            progress_bar.close()\n",
    "    \n",
    "    else:\n",
    "        print(\"file not present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8680cf24-a633-485d-9c31-0586f5620452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run if the file already downloaded\n",
    "# download_file(\n",
    "# 'https://www.dropbox.com/s/xc2890eh8ujy3cu/hituav-a-highaltitude-infrared-thermal-dataset.zip?dl=1',\n",
    "# 'hituav-a-highaltitude-infrared-thermal-dataset.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c97579-a638-4f91-84bc-77897c9de00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(zip_file=None):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file) as z:\n",
    "            z.extractall(\"./\")\n",
    "    except:\n",
    "        print(\"invalid file\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e43cc267-9e88-428f-95dd-5a0cb4d284ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip('hituav-a-highaltitude-infrared-thermal-dataset.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17fe9eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = 'hit-uav'\n",
    "train_imgs_dir = 'images/train'\n",
    "train_labels_dir = 'labels/train'\n",
    "val_imgs_dir = 'images/val'\n",
    "val_labels_dir = 'labels/val'\n",
    "test_imgs_dir = 'images/test'\n",
    "test_labels_dir = 'labels/test'\n",
    "classes = ['Person', 'Car', 'Bicycle', 'OtherVechicle', 'DontCare']\n",
    " \n",
    "dataset_params = {\n",
    "    'data_dir':ROOT_DIR,\n",
    "    'train_images_dir':train_imgs_dir,\n",
    "    'train_labels_dir':train_labels_dir,\n",
    "    'val_images_dir':val_imgs_dir,\n",
    "    'val_labels_dir':val_labels_dir,\n",
    "    'test_images_dir':test_imgs_dir,\n",
    "    'test_labels_dir':test_labels_dir,\n",
    "    'classes':classes \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d473ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters.\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6576a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n",
    "def yolo2bbox(bboxes):\n",
    "    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n",
    "    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n",
    "    return xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(image, bboxes, labels):\n",
    "    # Need the image height and width to denormalize\n",
    "    # the bounding box coordinates\n",
    "    height, width, _ = image.shape\n",
    "    lw = max(round(sum(image.shape) / 2 * 0.003), 2)  # Line width.\n",
    "    tf = max(lw - 1, 1) # Font thickness.\n",
    "    for box_num, box in enumerate(bboxes):\n",
    "        x1, y1, x2, y2 = yolo2bbox(box)\n",
    "        # denormalize the coordinates\n",
    "        xmin = int(x1*width)\n",
    "        ymin = int(y1*height)\n",
    "        xmax = int(x2*width)\n",
    "        ymax = int(y2*height)\n",
    "\n",
    "        p1, p2 = (int(xmin), int(ymin)), (int(xmax), int(ymax))\n",
    "        \n",
    "        class_name = classes[int(labels[box_num])]\n",
    "\n",
    "        color=colors[classes.index(class_name)]\n",
    "        \n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            p1, p2,\n",
    "            color=color, \n",
    "            thickness=lw,\n",
    "            lineType=cv2.LINE_AA\n",
    "        ) \n",
    "\n",
    "        # For filled rectangle.\n",
    "        w, h = cv2.getTextSize(\n",
    "            class_name, \n",
    "            0, \n",
    "            fontScale=lw / 3, \n",
    "            thickness=tf\n",
    "        )[0]\n",
    "\n",
    "        outside = p1[1] - h >= 3\n",
    "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "\n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            p1, p2, \n",
    "            color=color, \n",
    "            thickness=-1, \n",
    "            lineType=cv2.LINE_AA\n",
    "        )  \n",
    "        cv2.putText(\n",
    "            image, \n",
    "            class_name, \n",
    "            (p1[0], p1[1] - 5 if outside else p1[1] + h + 2),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            fontScale=lw/3.5, \n",
    "            color=(255, 255, 255), \n",
    "            thickness=tf, \n",
    "            lineType=cv2.LINE_AA\n",
    "        )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4825d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot images with the bounding boxes.\n",
    "def plot(image_path, label_path, num_samples):\n",
    "    all_training_images = glob.glob(image_path+'/*')\n",
    "    all_training_labels = glob.glob(label_path+'/*')\n",
    "    all_training_images.sort()\n",
    "    all_training_labels.sort()\n",
    "    \n",
    "    temp = list(zip(all_training_images, all_training_labels))\n",
    "    random.shuffle(temp)\n",
    "    all_training_images, all_training_labels = zip(*temp)\n",
    "    all_training_images, all_training_labels = list(all_training_images), list(all_training_labels)\n",
    "    \n",
    "    num_images = len(all_training_images)\n",
    "    \n",
    "    if num_samples == -1:\n",
    "        num_samples = num_images\n",
    "        \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i in range(num_samples):\n",
    "        image_name = all_training_images[i].split(os.path.sep)[-1]\n",
    "        image = cv2.imread(all_training_images[i])\n",
    "        with open(all_training_labels[i], 'r') as f:\n",
    "            bboxes = []\n",
    "            labels = []\n",
    "            label_lines = f.readlines()\n",
    "            for label_line in label_lines:\n",
    "                label, x_c, y_c, w, h = label_line.split(' ')\n",
    "                x_c = float(x_c)\n",
    "                y_c = float(y_c)\n",
    "                w = float(w)\n",
    "                h = float(h)\n",
    "                bboxes.append([x_c, y_c, w, h])\n",
    "                labels.append(label)\n",
    "        result_image = plot_box(image, bboxes, labels)\n",
    "        plt.subplot(2, 2, i+1) # Visualize 2x2 grid of images.\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few training images.\n",
    "plot(\n",
    "    image_path=os.path.join(ROOT_DIR, train_imgs_dir), \n",
    "    label_path=os.path.join(ROOT_DIR, train_labels_dir),\n",
    "    num_samples=4,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7c9fb5b",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa508a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coco_detection_yolo_format_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data \u001b[39m=\u001b[39m coco_detection_yolo_format_train(\n\u001b[1;32m      2\u001b[0m     dataset_params\u001b[39m=\u001b[39m{\n\u001b[1;32m      3\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdata_dir\u001b[39m\u001b[39m'\u001b[39m: dataset_params[\u001b[39m'\u001b[39m\u001b[39mdata_dir\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mimages_dir\u001b[39m\u001b[39m'\u001b[39m: dataset_params[\u001b[39m'\u001b[39m\u001b[39mtrain_images_dir\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlabels_dir\u001b[39m\u001b[39m'\u001b[39m: dataset_params[\u001b[39m'\u001b[39m\u001b[39mtrain_labels_dir\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mclasses\u001b[39m\u001b[39m'\u001b[39m: dataset_params[\u001b[39m'\u001b[39m\u001b[39mclasses\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m     },\n\u001b[1;32m      8\u001b[0m     dataloader_params\u001b[39m=\u001b[39m{\n\u001b[1;32m      9\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m:BATCH_SIZE,\n\u001b[1;32m     10\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnum_workers\u001b[39m\u001b[39m'\u001b[39m:WORKERS\n\u001b[1;32m     11\u001b[0m     }\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m val_data \u001b[39m=\u001b[39m coco_detection_yolo_format_val(\n\u001b[1;32m     15\u001b[0m     dataset_params\u001b[39m=\u001b[39m{\n\u001b[1;32m     16\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdata_dir\u001b[39m\u001b[39m'\u001b[39m: dataset_params[\u001b[39m'\u001b[39m\u001b[39mdata_dir\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     }\n\u001b[1;32m     25\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'coco_detection_yolo_format_train' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = coco_detection_yolo_format_train(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['train_images_dir'],\n",
    "        'labels_dir': dataset_params['train_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size':BATCH_SIZE,\n",
    "        'num_workers':WORKERS\n",
    "    }\n",
    ")\n",
    " \n",
    "val_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['val_images_dir'],\n",
    "        'labels_dir': dataset_params['val_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size':BATCH_SIZE,\n",
    "        'num_workers':WORKERS\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2db926",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dataset.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65243ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dataset.transforms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ An example on how to modify augmentations ###########\n",
    "train_data.dataset.transforms.pop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615dc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "train_data.dataset.plot(plot_transformed_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0869bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'silent_mode': False,\n",
    "    \"average_best_models\":True,\n",
    "    \"warmup_mode\": \"linear_epoch_step\",\n",
    "    \"warmup_initial_lr\": 1e-6,\n",
    "    \"lr_warmup_epochs\": 3,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_mode\": \"cosine\",\n",
    "    \"cosine_final_lr_ratio\": 0.1,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
    "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
    "    \"ema\": True,\n",
    "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
    "    \"max_epochs\": EPOCHS,\n",
    "    \"mixed_precision\": True,\n",
    "    \"loss\": PPYoloELoss(\n",
    "        use_static_assigner=False,\n",
    "        num_classes=len(dataset_params['classes']),\n",
    "        reg_max=16\n",
    "    ),\n",
    "    \"valid_metrics_list\": [\n",
    "        DetectionMetrics_050(\n",
    "            score_thres=0.1,\n",
    "            top_k_predictions=300,\n",
    "            num_cls=len(dataset_params['classes']),\n",
    "            normalize_targets=True,\n",
    "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
    "                score_threshold=0.01,\n",
    "                nms_top_k=1000,\n",
    "                max_predictions=300,\n",
    "                nms_threshold=0.7\n",
    "            )\n",
    "        ),\n",
    "        DetectionMetrics_050_095(\n",
    "            score_thres=0.1,\n",
    "            top_k_predictions=300,\n",
    "            num_cls=len(dataset_params['classes']),\n",
    "            normalize_targets=True,\n",
    "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
    "                score_threshold=0.01,\n",
    "                nms_top_k=1000,\n",
    "                max_predictions=300,\n",
    "                nms_threshold=0.7\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    \"metric_to_watch\": 'mAP@0.50:0.95'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = [\n",
    "    'yolo_nas_s',\n",
    "    'yolo_nas_m',\n",
    "    'yolo_nas_l'\n",
    "]\n",
    " \n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    " \n",
    "for model_to_train in models_to_train:\n",
    "    trainer = Trainer(\n",
    "        experiment_name=model_to_train, \n",
    "        ckpt_root_dir=CHECKPOINT_DIR\n",
    "    )\n",
    " \n",
    "    model = models.get(\n",
    "        model_to_train, \n",
    "        num_classes=len(dataset_params['classes']), \n",
    "        pretrained_weights=\"coco\"\n",
    "    )\n",
    " \n",
    "    trainer.train(\n",
    "        model=model, \n",
    "        training_params=train_params, \n",
    "        train_loader=train_data, \n",
    "        valid_loader=val_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = 'checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6975af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_to_train in models_to_train:\n",
    "    trainer = Trainer(\n",
    "        experiment_name=model_to_train, \n",
    "        ckpt_root_dir=CHECKPOINT_DIR\n",
    "    )\n",
    "\n",
    "    model = models.get(\n",
    "        model_to_train, \n",
    "        num_classes=len(dataset_params['classes']), \n",
    "        pretrained_weights=\"coco\"\n",
    "    )\n",
    "\n",
    "    trainer.train(\n",
    "        model=model, \n",
    "        training_params=train_params, \n",
    "        train_loader=train_data, \n",
    "        valid_loader=val_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a6f93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40cbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889f23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
