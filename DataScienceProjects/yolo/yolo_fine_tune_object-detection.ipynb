{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One time installation.\n",
    "!pip install super-gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training import Trainer\n",
    "from super_gradients.training import dataloaders\n",
    "from super_gradients.training.dataloaders.dataloaders import (\n",
    "    coco_detection_yolo_format_train, \n",
    "    coco_detection_yolo_format_val\n",
    ")\n",
    "from super_gradients.training import models\n",
    "from super_gradients.training.losses import PPYoloELoss\n",
    "from super_gradients.training.metrics import (\n",
    "    DetectionMetrics_050,\n",
    "    DetectionMetrics_050_095\n",
    ")\n",
    "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset.\n",
    "def download_file(url, save_name):\n",
    "    if not os.path.exists(save_name):\n",
    "        print(f\"Downloading file\")\n",
    "        file = requests.get(url, stream=True)\n",
    "        total_size = int(file.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        progress_bar = tqdm(\n",
    "            total=total_size, \n",
    "            unit='iB', \n",
    "            unit_scale=True\n",
    "        )\n",
    "        with open(os.path.join(save_name), 'wb') as f:\n",
    "            for data in file.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                f.write(data)\n",
    "        progress_bar.close()\n",
    "    else:\n",
    "        print('File already present')\n",
    "        \n",
    "download_file(\n",
    "    'https://www.dropbox.com/s/xc2890eh8ujy3cu/hituav-a-highaltitude-infrared-thermal-dataset.zip?dl=1',\n",
    "    'hituav-a-highaltitude-infrared-thermal-dataset.zip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the data file\n",
    "def unzip(zip_file=None):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file) as z:\n",
    "            z.extractall(\"./\")\n",
    "            print(\"Extracted all\")\n",
    "    except:\n",
    "        print(\"Invalid file\")\n",
    "\n",
    "unzip('hituav-a-highaltitude-infrared-thermal-dataset.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = 'hit-uav'\n",
    "train_imgs_dir = 'images/train'\n",
    "train_labels_dir = 'labels/train'\n",
    "val_imgs_dir = 'images/val'\n",
    "val_labels_dir = 'labels/val'\n",
    "test_imgs_dir = 'images/test'\n",
    "test_labels_dir = 'labels/test'\n",
    "classes = ['Person', 'Car', 'Bicycle', 'OtherVechicle', 'DontCare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    'data_dir':ROOT_DIR,\n",
    "    'train_images_dir':train_imgs_dir,\n",
    "    'train_labels_dir':train_labels_dir,\n",
    "    'val_images_dir':val_imgs_dir,\n",
    "    'val_labels_dir':val_labels_dir,\n",
    "    'test_images_dir':test_imgs_dir,\n",
    "    'test_labels_dir':test_labels_dir,\n",
    "    'classes':classes \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters.\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n",
    "def yolo2bbox(bboxes):\n",
    "    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n",
    "    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n",
    "    return xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(image, bboxes, labels):\n",
    "    # Need the image height and width to denormalize\n",
    "    # the bounding box coordinates\n",
    "    height, width, _ = image.shape\n",
    "    lw = max(round(sum(image.shape) / 2 * 0.003), 2)  # Line width.\n",
    "    tf = max(lw - 1, 1) # Font thickness.\n",
    "    for box_num, box in enumerate(bboxes):\n",
    "        x1, y1, x2, y2 = yolo2bbox(box)\n",
    "        # denormalize the coordinates\n",
    "        xmin = int(x1*width)\n",
    "        ymin = int(y1*height)\n",
    "        xmax = int(x2*width)\n",
    "        ymax = int(y2*height)\n",
    "\n",
    "        p1, p2 = (int(xmin), int(ymin)), (int(xmax), int(ymax))\n",
    "        \n",
    "        class_name = classes[int(labels[box_num])]\n",
    "\n",
    "        color=colors[classes.index(class_name)]\n",
    "        \n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            p1, p2,\n",
    "            color=color, \n",
    "            thickness=lw,\n",
    "            lineType=cv2.LINE_AA\n",
    "        ) \n",
    "\n",
    "        # For filled rectangle.\n",
    "        w, h = cv2.getTextSize(\n",
    "            class_name, \n",
    "            0, \n",
    "            fontScale=lw / 3, \n",
    "            thickness=tf\n",
    "        )[0]\n",
    "\n",
    "        outside = p1[1] - h >= 3\n",
    "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "\n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            p1, p2, \n",
    "            color=color, \n",
    "            thickness=-1, \n",
    "            lineType=cv2.LINE_AA\n",
    "        )  \n",
    "        cv2.putText(\n",
    "            image, \n",
    "            class_name, \n",
    "            (p1[0], p1[1] - 5 if outside else p1[1] + h + 2),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            fontScale=lw/3.5, \n",
    "            color=(255, 255, 255), \n",
    "            thickness=tf, \n",
    "            lineType=cv2.LINE_AA\n",
    "        )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot images with the bounding boxes.\n",
    "def plot(image_path, label_path, num_samples):\n",
    "    all_training_images = glob.glob(image_path+'/*')\n",
    "    all_training_labels = glob.glob(label_path+'/*')\n",
    "    all_training_images.sort()\n",
    "    all_training_labels.sort()\n",
    "    \n",
    "    temp = list(zip(all_training_images, all_training_labels))\n",
    "    random.shuffle(temp)\n",
    "    all_training_images, all_training_labels = zip(*temp)\n",
    "    all_training_images, all_training_labels = list(all_training_images), list(all_training_labels)\n",
    "    \n",
    "    num_images = len(all_training_images)\n",
    "    \n",
    "    if num_samples == -1:\n",
    "        num_samples = num_images\n",
    "        \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i in range(num_samples):\n",
    "        image_name = all_training_images[i].split(os.path.sep)[-1]\n",
    "        image = cv2.imread(all_training_images[i])\n",
    "        with open(all_training_labels[i], 'r') as f:\n",
    "            bboxes = []\n",
    "            labels = []\n",
    "            label_lines = f.readlines()\n",
    "            for label_line in label_lines:\n",
    "                label, x_c, y_c, w, h = label_line.split(' ')\n",
    "                x_c = float(x_c)\n",
    "                y_c = float(y_c)\n",
    "                w = float(w)\n",
    "                h = float(h)\n",
    "                bboxes.append([x_c, y_c, w, h])\n",
    "                labels.append(label)\n",
    "        result_image = plot_box(image, bboxes, labels)\n",
    "        plt.subplot(2, 2, i+1) # Visualize 2x2 grid of images.\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few training images.\n",
    "plot(\n",
    "    image_path=os.path.join(ROOT_DIR, train_imgs_dir), \n",
    "    label_path=os.path.join(ROOT_DIR, train_labels_dir),\n",
    "    num_samples=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = coco_detection_yolo_format_train(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['train_images_dir'],\n",
    "        'labels_dir': dataset_params['train_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size':BATCH_SIZE,\n",
    "        'num_workers':WORKERS\n",
    "    }\n",
    ")\n",
    "\n",
    "val_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['val_images_dir'],\n",
    "        'labels_dir': dataset_params['val_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size':BATCH_SIZE,\n",
    "        'num_workers':WORKERS\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dataset.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dataset.transforms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ An example on how to modify augmentations ###########\n",
    "train_data.dataset.transforms.pop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dataset.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We visualize the images without augmentation here.\n",
    "train_data.dataset.plot(plot_transformed_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'silent_mode': False,\n",
    "    \"average_best_models\":True,\n",
    "    \"warmup_mode\": \"linear_epoch_step\",\n",
    "    \"warmup_initial_lr\": 1e-6,\n",
    "    \"lr_warmup_epochs\": 3,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_mode\": \"cosine\",\n",
    "    \"cosine_final_lr_ratio\": 0.1,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
    "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
    "    \"ema\": True,\n",
    "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
    "    \"max_epochs\": EPOCHS,\n",
    "    \"mixed_precision\": True,\n",
    "    \"loss\": PPYoloELoss(\n",
    "        use_static_assigner=False,\n",
    "        num_classes=len(dataset_params['classes']),\n",
    "        reg_max=16\n",
    "    ),\n",
    "    \"valid_metrics_list\": [\n",
    "        DetectionMetrics_050(\n",
    "            score_thres=0.1,\n",
    "            top_k_predictions=300,\n",
    "            num_cls=len(dataset_params['classes']),\n",
    "            normalize_targets=True,\n",
    "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
    "                score_threshold=0.01,\n",
    "                nms_top_k=1000,\n",
    "                max_predictions=300,\n",
    "                nms_threshold=0.7\n",
    "            )\n",
    "        ),\n",
    "        DetectionMetrics_050_095(\n",
    "            score_thres=0.1,\n",
    "            top_k_predictions=300,\n",
    "            num_cls=len(dataset_params['classes']),\n",
    "            normalize_targets=True,\n",
    "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
    "                score_threshold=0.01,\n",
    "                nms_top_k=1000,\n",
    "                max_predictions=300,\n",
    "                nms_threshold=0.7\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    \"metric_to_watch\": 'mAP@0.50:0.95'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = [\n",
    "    'yolo_nas_l'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = 'checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_to_train in models_to_train:\n",
    "    trainer = Trainer(\n",
    "        experiment_name=model_to_train+'_'+str(EPOCHS)+'e', \n",
    "        ckpt_root_dir=CHECKPOINT_DIR\n",
    "    )\n",
    "\n",
    "    model = models.get(\n",
    "        model_to_train, \n",
    "        num_classes=len(dataset_params['classes']), \n",
    "        pretrained_weights=\"coco\"\n",
    "    )\n",
    "\n",
    "    trainer.train(\n",
    "        model=model, \n",
    "        training_params=train_params, \n",
    "        train_loader=train_data, \n",
    "        valid_loader=val_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
