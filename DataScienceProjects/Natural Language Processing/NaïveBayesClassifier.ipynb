{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55fc0950",
   "metadata": {},
   "source": [
    "Constructing a Naive Bayes Classifier\n",
    " \n",
    "Combine all the preprocessing techniques and create a dictionary of words and each wordâ€™s count in training data.\n",
    "\n",
    "Calculate probability for each word in a text and filter the words which have a probability less than threshold probability. Words with probability less than threshold probability are irrelevant.\n",
    "Then for each word in the dictionary, create a probability of that word being in insincere questions and its probability insincere questions. Then finding the conditional probability to use in naive Bayes classifier.\n",
    "Prediction using conditional probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c06d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72d78ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74559bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train  (1306122, 3)\n",
      "Shape of test  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "print ('Shape of train ',train.shape)\n",
    "print ('Shape of test ',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f727bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking a look at Sincere Questions\n",
      "Taking a look at Insincere Questions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "471755    Why is America so racist compared to western E...\n",
       "748477      What kind of moron designed the flag of Cyprus?\n",
       "104709    Why do feminists oppose men's rights groups be...\n",
       "651101          Do black people hate white people nowadays?\n",
       "432337    Can Indian Muslims with support of neighbourin...\n",
       "Name: question_text, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Taking a look at Sincere Questions')\n",
    "train.loc[train['target'] == 0].sample(5)['question_text']\n",
    "\n",
    "print ('Taking a look at Insincere Questions')\n",
    "train.loc[train['target'] == 1].sample(5)['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6115697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the limitations of private security? Do they have the ability to pull people over on a public road?\n"
     ]
    }
   ],
   "source": [
    "samp = train.sample(1)\n",
    "sentence = samp.iloc[0]['question_text']\n",
    "print (sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fde5b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence After removing numbers\n",
      " What are the limitations of private security? Do they have the ability to pull people over on a public road?\n",
      "Sentence After Removing Punctuations\n",
      " What are the limitations of private security Do they have the ability to pull people over on a public road\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sentence = re.sub(r'\\d+','',sentence)\n",
    "print ('Sentence After removing numbers\\n',sentence)\n",
    "\n",
    "#Removing Punctuations in a string.\n",
    "\n",
    "import string\n",
    "sentence = sentence.translate(sentence.maketrans(\"\",\"\",string.punctuation))\n",
    "print ('Sentence After Removing Punctuations\\n',sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fec21e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['road', 'security', 'private', 'public', 'limitations', 'people', 'ability', 'Do', 'pull', 'What']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Admin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/Admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "words_in_sentence = list(set(sentence.split(' ')) - stop_words)\n",
    "print (words_in_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5d65d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['road', 'secur', 'privat', 'public', 'limit', 'peopl', 'abil', 'do', 'pull', 'what']\n",
      "['road', 'secur', 'privat', 'public', 'limit', 'peopl', 'abil', 'do', 'pull', 'what']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Admin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "stemmer= PorterStemmer()\n",
    "for i,word in enumerate(words_in_sentence):\n",
    "    words_in_sentence[i] = stemmer.stem(word)\n",
    "print (words_in_sentence)    \n",
    "\n",
    "#Lemmatization of Words\n",
    "#Lemmatisation is the process of grouping together the different inflected forms of a word so they can be analysed as a single item. Ex: dogs -> dog. I am not clear with difference between lemmatization and stemming. In most of the tutorials, I found them both and I could not understand the clear difference between the two.\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "words = []\n",
    "for i,word in enumerate(words_in_sentence):\n",
    "    words_in_sentence[i] = lemmatizer.lemmatize(word)\n",
    "print (words_in_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50a6d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "79c89391",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = {}\n",
    "word_count_sincere = {}\n",
    "word_count_insincere = {}\n",
    "sincere  = 0\n",
    "insincere = 0 \n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer= PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a623a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "row_count = train.shape[0]\n",
    "for row in range(0,row_count):\n",
    "    insincere += train.iloc[row]['target']\n",
    "    sincere += (1 - train.iloc[row]['target'])\n",
    "    sentence = train.iloc[row]['question_text']\n",
    "    sentence = re.sub(r'\\d+','',sentence)\n",
    "    sentence = sentence.translate(sentence.maketrans(\"\",\"\",string.punctuation))\n",
    "    words_in_sentence = list(set(sentence.split(' ')) - stop_words)\n",
    "    for index,word in enumerate(words_in_sentence):\n",
    "        word = stemmer.stem(word)\n",
    "        words_in_sentence[index] = lemmatizer.lemmatize(word)\n",
    "    for word in words_in_sentence:\n",
    "        if train.iloc[row]['target'] == 0:   #Sincere Words\n",
    "            if word in word_count_sincere.keys():\n",
    "                word_count_sincere[word]+=1\n",
    "            else:\n",
    "                word_count_sincere[word] = 1\n",
    "        elif train.iloc[row]['target'] == 1: #Insincere Words\n",
    "            if word in word_count_insincere.keys():\n",
    "                word_count_insincere[word]+=1\n",
    "            else:\n",
    "                word_count_insincere[word] = 1\n",
    "        if word in word_count.keys():        #For all words. I use this to compute probability.\n",
    "            word_count[word]+=1\n",
    "        else:\n",
    "            word_count[word]=1\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "760a4175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words  163880\n",
      "Minimum probability  1.2684068024149451e-07\n",
      "Total words  1583\n"
     ]
    }
   ],
   "source": [
    "word_probability = {}\n",
    "total_words = 0\n",
    "for i in word_count:\n",
    "    total_words += word_count[i]\n",
    "for i in word_count:\n",
    "    word_probability[i] = word_count[i] / total_words\n",
    "\n",
    "#Eliminating words which are insignificant. Insignificant words are words which have a probability of occurence less than 0.0001.\n",
    "print ('Total words ',len(word_probability))\n",
    "print ('Minimum probability ',min (word_probability.values()))\n",
    "threshold_p = 0.0001\n",
    "for i in list(word_probability):\n",
    "    if word_probability[i] < threshold_p:\n",
    "        del word_probability[i]\n",
    "        if i in list(word_count_sincere):   #list(dict) return it;s key elements\n",
    "            del word_count_sincere[i]\n",
    "        if i in list(word_count_insincere):  \n",
    "            del word_count_insincere[i]\n",
    "print ('Total words ',len(word_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "079e299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sincere_words = sum(word_count_sincere.values())\n",
    "cp_sincere = {}  #Conditional Probability\n",
    "for i in list(word_count_sincere):\n",
    "    cp_sincere[i] = word_count_sincere[i] / total_sincere_words\n",
    "\n",
    "total_insincere_words = sum(word_count_insincere.values())\n",
    "cp_insincere = {}  #Conditional Probability\n",
    "for i in list(word_count_insincere):\n",
    "    cp_insincere[i] = word_count_insincere[i] / total_insincere_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6b10f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  94.16020671834625\n"
     ]
    }
   ],
   "source": [
    "row_count = test.shape[0]\n",
    "\n",
    "p_insincere = insincere / (sincere + insincere)\n",
    "p_sincere = sincere / (sincere + insincere)\n",
    "accuracy = 0\n",
    "\n",
    "for row in range(0,row_count):\n",
    "    sentence = test.iloc[row]['question_text']\n",
    "    target = test.iloc[row]['target']\n",
    "    sentence = re.sub(r'\\d+','',sentence)\n",
    "    sentence = sentence.translate(sentence.maketrans(\"\",\"\",string.punctuation))\n",
    "    words_in_sentence = list(set(sentence.split(' ')) - stop_words)\n",
    "    for index,word in enumerate(words_in_sentence):\n",
    "        word = stemmer.stem(word)\n",
    "        words_in_sentence[index] = lemmatizer.lemmatize(word)\n",
    "    insincere_term = p_insincere\n",
    "    sincere_term = p_sincere\n",
    "    \n",
    "    sincere_M = len(cp_sincere.keys())\n",
    "    insincere_M = len(cp_insincere.keys())\n",
    "    for word in words_in_sentence:\n",
    "        if word not in cp_insincere.keys():\n",
    "            insincere_M +=1\n",
    "        if word not in cp_sincere.keys():\n",
    "            sincere_M += 1\n",
    "         \n",
    "    for word in words_in_sentence:\n",
    "        if word in cp_insincere.keys():\n",
    "            insincere_term *= (cp_insincere[word] + (1/insincere_M))\n",
    "        else:\n",
    "            insincere_term *= (1/insincere_M)\n",
    "        if word in cp_sincere.keys():\n",
    "            sincere_term *= (cp_sincere[word] + (1/sincere_M))\n",
    "        else:\n",
    "            sincere_term *= (1/sincere_M)\n",
    "        \n",
    "    if insincere_term/(insincere_term + sincere_term) > 0.5:\n",
    "        response = 1\n",
    "    else:\n",
    "        response = 0\n",
    "    if target == response:\n",
    "        accuracy += 1\n",
    "    \n",
    "print ('Accuracy is ',accuracy/row_count*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738c15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
